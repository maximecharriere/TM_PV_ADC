{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup & Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pvlib\n",
    "import json\n",
    "import os\n",
    "from pvlib.pvsystem import PVSystem, Array, FixedMount\n",
    "from pvlib.location import Location\n",
    "from pvlib.modelchain import ModelChain\n",
    "from pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import forestci as fci\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import threading\n",
    "from sklearn.metrics import make_scorer\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "import plotly.graph_objects as go\n",
    "from dash.dependencies import Input, Output\n",
    "import webbrowser\n",
    "from threading import Timer\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils.parallel import Parallel, delayed\n",
    "from sklearn.utils.validation import (\n",
    "    check_is_fitted,\n",
    ")\n",
    "from sklearn.ensemble._base import _partition_estimators\n",
    "\n",
    "pio.renderers.default = \"browser\"  # render plotly figures in browser\n",
    "\n",
    "PARENT_DATA_DIR = os.getenv('PARENT_DATA_DIR')\n",
    "if PARENT_DATA_DIR is None:\n",
    "    raise ValueError(\"PARENT_DATA_DIR environment variable is not set\")\n",
    "\n",
    "\n",
    "dataDirpath = PARENT_DATA_DIR + r\"\\PRiOT\\dataExport_3400_daily\"  # \"/Applications/Documents/TM Maxime/dataExport_3400_daily\"#\n",
    "dataCacheDirpath = os.path.join(dataDirpath, \"cache\")\n",
    "logsDirpath = \"../logs\"\n",
    "useCached = False\n",
    "forceTrain = True\n",
    "tuneMaxProductionEstimators = True\n",
    "random_state = 42\n",
    "\n",
    "if not os.path.exists(logsDirpath):\n",
    "    os.makedirs(logsDirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/model_persistence.html\n",
    "import pickle\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "class ModelSerializer:\n",
    "    def _save_model(self, model, serial_type, save_params):\n",
    "        serial_type.dump(model, save_params)\n",
    "\n",
    "    def _retrieve_model(self, serial_type, retrieve_params):\n",
    "        return serial_type.load(retrieve_params)\n",
    "\n",
    "\n",
    "# save_model_path = \"Serialized_models\\\\\"\n",
    "\n",
    "\n",
    "class JoblibSerializer(ModelSerializer):\n",
    "    def save_model(self, model, save_model_path, filename):\n",
    "        super()._save_model(model, joblib, os.path.join(save_model_path, filename + \".joblib\"))\n",
    "\n",
    "    def retrieve_model(self, save_model_path, filename):\n",
    "        return super()._retrieve_model(joblib, os.path.join(save_model_path, filename + '.joblib'))\n",
    "\n",
    "\n",
    "class PickleSerializer(ModelSerializer):\n",
    "    def save_model(self, model, save_model_path, filename):\n",
    "        with open(os.path.join(save_model_path, filename + \".pkl\"), 'wb') as f:\n",
    "            super()._save_model(model, pickle, f)\n",
    "\n",
    "    def retrieve_model(self, save_model_path, filename):\n",
    "        with open(os.path.join(save_model_path, filename + \".pkl\"), 'rb') as f:\n",
    "            return super()._retrieve_model(pickle, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_altitude_from_wgs84(longitude, latitude):\n",
    "    # Convert WGS84 to LV95\n",
    "    lv95_url = \"https://geodesy.geo.admin.ch/reframe/wgs84tolv95\"\n",
    "    params_lv95 = {\n",
    "        \"easting\": longitude,\n",
    "        \"northing\": latitude,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    \n",
    "    response_lv95 = requests.get(lv95_url, params=params_lv95)\n",
    "    if response_lv95.status_code != 200:\n",
    "        raise Exception(\"Error converting WGS84 to LV95: \" + response_lv95.text)\n",
    "    \n",
    "    lv95_data = response_lv95.json()\n",
    "    lv95_easting = lv95_data[\"easting\"]\n",
    "    lv95_northing = lv95_data[\"northing\"]\n",
    "    \n",
    "    # Get altitude from LV95 coordinates\n",
    "    altitude_url = \"https://api3.geo.admin.ch/rest/services/height\"\n",
    "    params_altitude = {\n",
    "        \"easting\": lv95_easting,\n",
    "        \"northing\": lv95_northing\n",
    "    }\n",
    "    \n",
    "    response_altitude = requests.get(altitude_url, params=params_altitude)\n",
    "    if response_altitude.status_code != 200:\n",
    "        raise Exception(\"Error retrieving altitude: \" + response_altitude.text)\n",
    "    \n",
    "    altitude_data = response_altitude.json()\n",
    "    altitude = altitude_data[\"height\"]\n",
    "    \n",
    "    return float(altitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataFilepath = os.path.join(dataDirpath, \"metadata.json\")\n",
    "\n",
    "with open(metadataFilepath, 'r') as f:\n",
    "    systemsMetadata = json.load(f)\n",
    "\n",
    "# Add altitude to metadata, if not already present (TODO : imporove with multi threading)\n",
    "\n",
    "for systemId, systemMetadata in tqdm(systemsMetadata.items()):\n",
    "    if \"loc_altitude\" not in systemMetadata['metadata']:\n",
    "        if \"loc_longitude\" in systemMetadata['metadata'] and \"loc_latitude\" in systemMetadata['metadata']:\n",
    "            systemMetadata['metadata'][\"loc_altitude\"] = get_altitude_from_wgs84(systemMetadata['metadata'][\"loc_longitude\"], systemMetadata['metadata'][\"loc_latitude\"])\n",
    "\n",
    "# Save metadata with altitude\n",
    "with open(metadataFilepath, 'w') as f:\n",
    "    json.dump(systemsMetadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "cacheFilename_systemsData_MeasuredDailyEnergy = os.path.join(dataCacheDirpath, 'systemsData_MeasuredDailyEnergy.pkl')\n",
    "if useCached and os.path.exists(cacheFilename_systemsData_MeasuredDailyEnergy):\n",
    "    print(f\"Loading cached data in {cacheFilename_systemsData_MeasuredDailyEnergy}\")\n",
    "    systemsData_MeasuredDailyEnergy = pd.read_pickle(cacheFilename_systemsData_MeasuredDailyEnergy)\n",
    "    systemsName_Valid = systemsData_MeasuredDailyEnergy.columns\n",
    "else:\n",
    "    # Load all csv files from the data directory\n",
    "    systemsData = {}\n",
    "    for file in os.listdir(dataDirpath):\n",
    "        if file.endswith(\".csv\"):\n",
    "            systemName = file.split(\"_\")[0]\n",
    "            systemsData[systemName] = pd.read_csv(os.path.join(dataDirpath, file))\n",
    "            systemsData[systemName]['Datetime'] = pd.to_datetime(systemsData[systemName]['Timestamp'], unit='ms', utc=True).dt.tz_convert('Europe/Zurich')\n",
    "            systemsData[systemName]['Date'] = (systemsData[systemName]['Datetime'] + pd.Timedelta(hours=1)).dt.date  # Convert the datetime to only the date, as the production is the daily production. The +1h is to manage the saving time. Normally PRiOT exports the data at midnight (local time) for the day after (e.g. the energy for the July 1st is saved at July 1st 00:00 Europe/Zurich). However it seams that the saving time is not always correctly handled, and sometime the export is done at 23:00 the day before (e.g. the energy for the July 1st is saved at June 30th 23:00 Europe/Zurich). This is why we add 1h to the datetime to be sure to have the correct date.\n",
    "\n",
    "    systemsName = list(systemsData.keys())\n",
    "\n",
    "    df_duplicate_list = list()\n",
    "    for systemName, systemData in systemsData.items():\n",
    "        # Save duplicate dates to log list, and the in a log file\n",
    "        duplicates = systemData[systemData['Date'].duplicated(keep=False)]\n",
    "        if len(duplicates) > 0:\n",
    "            df_duplicate_list.append(duplicates)\n",
    "\n",
    "            # Remove duplicate date where tt_forward_active_energy_total_toDay is the smallest\n",
    "            # TODO maybe we should sum the energy of the duplicates instead of removing the smallest one. However, when looking in PRiOT Portal, it seams that in the daily energy, only the biggest value is represented. We do the same here.\n",
    "            systemData.sort_values('tt_forward_active_energy_total_toDay', ascending=True, inplace=True)\n",
    "            systemsData[systemName].drop_duplicates(subset='Date', keep='last', inplace=True)\n",
    "\n",
    "        # Set date as the index and sort the data by date\n",
    "        systemsData[systemName].set_index('Date', inplace=True)\n",
    "        systemData.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "    # Save duplicate dates to log file\n",
    "    df_duplicate = pd.concat(df_duplicate_list)\n",
    "    print(f\"Number of duplicate dates found: {len(df_duplicate)} (see log file for more details)\")\n",
    "    df_duplicate.to_csv(os.path.join(logsDirpath, 'duplicateDates.csv'), index=True)\n",
    "\n",
    "    ## ----------------------------------------------- ##\n",
    "    ## Convert data & Filter out invalid PRiOT systems ##\n",
    "    ## ----------------------------------------------- ##\n",
    "\n",
    "    systemsName_Valid = systemsName.copy()\n",
    "    for systemName in systemsName:\n",
    "        missingData = False\n",
    "        # Check if the system has measures\n",
    "        if len(systemsData[systemName]) == 0:\n",
    "            missingData = True\n",
    "            print(f\"System {systemName} : No measures found\")\n",
    "        # Check if the system has metadata\n",
    "        if systemName not in systemsMetadata:\n",
    "            missingData = True\n",
    "            print(f\"System {systemName} : No metadata found\")\n",
    "        \n",
    "        else:\n",
    "            # Check metadata for the system\n",
    "            for key in ['loc_latitude', 'loc_longitude', 'loc_altitude', 'pv_kwp']:\n",
    "                # test that the key is present\n",
    "                if key not in systemMetadata['metadata']:\n",
    "                    missingData = True\n",
    "                    print(f\"System {systemName} : No '{key}' found\")\n",
    "                # if present, convert the value to a number, if possible\n",
    "                elif not isinstance(systemsMetadata[systemName]['metadata'][key], (int, float)):\n",
    "                    try:\n",
    "                        systemsMetadata[systemName]['metadata'][key] = int(systemsMetadata[systemName]['metadata'][key])\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            systemsMetadata[systemName]['metadata'][key] = float(systemsMetadata[systemName]['metadata'][key])\n",
    "                        except ValueError:\n",
    "                            missingData = True\n",
    "                            print(f\"System {systemName} : The key-value '{key}:{systemsMetadata[systemName]['metadata'][key]}' is not a number\")\n",
    "\n",
    "            # Check metadata for the arrays\n",
    "            if (len(systemsMetadata[systemName]['arrays']) == 0):\n",
    "                print(f\"System {systemName} : No PV arrays found\")\n",
    "                missingData = True\n",
    "            else:\n",
    "                for array_num, arrayData in systemsMetadata[systemName]['arrays'].items():\n",
    "                    for key in ['pv_tilt', 'pv_azimut', 'pv_wp', 'pv_number']:\n",
    "                        if key not in arrayData:\n",
    "                            missingData = True\n",
    "                            print(f\"System {systemName} : No '{key}' found for array {array_num}\")\n",
    "                        # test that the value is a number\n",
    "                        elif not isinstance(arrayData[key], (int, float)):\n",
    "                            try:\n",
    "                                arrayData[key] = int(arrayData[key])\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    arrayData[key] = float(arrayData[key])\n",
    "                                except ValueError:\n",
    "                                    missingData = True\n",
    "                                    print(f\"System {systemName} : The key-value '{key}:{arrayData[key]}' is not a number for array {array_num}\")\n",
    "            \n",
    "            # add the loss metadata if not present\n",
    "            if 'loss' not in systemsMetadata[systemName]['metadata']:\n",
    "                systemsMetadata[systemName]['metadata']['loss'] = 0\n",
    "\n",
    "        if missingData:\n",
    "            systemsName_Valid.remove(systemName)\n",
    "            print(f\"-> Removing system {systemName} from the list of systems\")\n",
    "\n",
    "    print(f\"Number of systems with all the necessary data: {len(systemsName_Valid)}/{len(systemsName)}\")\n",
    "\n",
    "    # Filter out systems with less than 100 days of data\n",
    "    minimumDays = 7\n",
    "    for systemName in systemsName_Valid[:]:  # Create a copy of the list using slicing [:] to avoid removing elements while iterating over the list itself\n",
    "        if len(systemsData[systemName]) < minimumDays:\n",
    "            systemsName_Valid.remove(systemName)\n",
    "            print(f\"-> Removing system {systemName} from the list of systems because it has less than {minimumDays} days of data\")\n",
    "\n",
    "    print(f\"Number of systems with at least {minimumDays} days of data: {len(systemsName_Valid)}/{len(systemsName)}\")\n",
    "\n",
    "    ## ---------------------------------------------------------------------------- ##\n",
    "    ## Create one 2D DataFrame with the daily production of every remaining systems ##\n",
    "    ## ---------------------------------------------------------------------------- ##\n",
    "\n",
    "    # Create an empty list to store all measured data for each systems\n",
    "    systemsData_MeasuredDailyEnergy_List = []\n",
    "\n",
    "    # Iterate over each key-value pair in the systemsData dictionary\n",
    "    for systemName in systemsName_Valid:\n",
    "        # Extract the 'tt_forward_active_energy_total_toDay' column from the current dataframe\n",
    "        measuredDailyEnergy = systemsData[systemName]['tt_forward_active_energy_total_toDay']\n",
    "\n",
    "        # Rename the column with the system name\n",
    "        measuredDailyEnergy.rename(systemName, inplace=True)\n",
    "\n",
    "        systemsData_MeasuredDailyEnergy_List.append(measuredDailyEnergy)\n",
    "        # Concatenate the column to the new_dataframe\n",
    "\n",
    "    # Concatenate all the columns in the list to create one dataframe\n",
    "    systemsData_MeasuredDailyEnergy = pd.concat(systemsData_MeasuredDailyEnergy_List, axis=1)\n",
    "    systemsData_MeasuredDailyEnergy.index = pd.to_datetime(systemsData_MeasuredDailyEnergy.index)\n",
    "    systemsData_MeasuredDailyEnergy.sort_index(inplace=True)\n",
    "\n",
    "    ## ------------------ ##\n",
    "    ## Save the dataframe ##\n",
    "    ## ------------------ ##\n",
    "    # Save the dataframe for later use\n",
    "    systemsData_MeasuredDailyEnergy.to_pickle(cacheFilename_systemsData_MeasuredDailyEnergy)\n",
    "\n",
    "# Print the dataframe\n",
    "systemsData_MeasuredDailyEnergy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show missing value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import missingno as msno\n",
    "\n",
    "msno.matrix(systemsData_dailyEnergyTotal, filter='bottom', labels=True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Plot the number of available values per day. On the X axis is the day, and on the Y axis is the number of available values for this day.\n",
    "\n",
    "# Count the number of available values per day (number of value per index)\n",
    "availableValuesPerDay = systemsData_dailyEnergyTotal.count(axis=1)\n",
    "\n",
    "# Plot the number of available values per day\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=availableValuesPerDay.index, y=availableValuesPerDay.values, mode='lines'))\n",
    "fig.update_layout(title='Number of available system\\'s values per day', yaxis_title='Number of available values')\n",
    "fig.update_layout(width=1000, height=666)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose system to train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemsName_Target = systemsName_Valid.copy()\n",
    "# systemsName_Target = [\"a001035\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max production estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the power production with a given frequency to the total daily energy\n",
    "def daily_energy(df_power):\n",
    "    # Get the frequency in minutes\n",
    "    freq_in_minutes = pd.Timedelta(df_power.index.freq).seconds / 60\n",
    "    # Convert power from kW to kWh\n",
    "    df_energy = df_power * (freq_in_minutes / 60)\n",
    "    # Resample to daily frequency and sum the values\n",
    "    daily_energy = df_energy.resample('D').sum()\n",
    "    # daily_energy.index = daily_energy.index.date\n",
    "\n",
    "    return daily_energy\n",
    "\n",
    "# Simulate the daily production of a system from a start date to an end date using the given PVLib ModelChain\n",
    "\n",
    "\n",
    "def generate_max_production_estimate(startDate, endDate, estimator: ModelChain, samplingFreq='1h'):\n",
    "    # The end date is included in the simulation (end date at 23:59).\n",
    "    # So we add 1 day to the end date to include the entire end date in the date_range(), and then we exclude the last value (end date +1 at 00:00) in the date_range().\n",
    "    # TODO It is possible to take into account the horizon, using this method: https://pvlib-python.readthedocs.io/en/stable/gallery/shading/plot_simple_irradiance_adjustment_for_horizon_shading.html\n",
    "    endDate = endDate + pd.Timedelta(days=1)\n",
    "\n",
    "    times = pd.date_range(start=startDate, end=endDate, freq=samplingFreq, tz=estimator.location.tz, inclusive='left')\n",
    "    weatherClearSky = estimator.location.get_clearsky(times)  # In W/m2\n",
    "    estimator.run_model(weatherClearSky)\n",
    "    production = estimator.results.ac / 1000  # Convert W to kW\n",
    "    dailyProduction = daily_energy(production)\n",
    "    dailyProduction.index = pd.to_datetime(dailyProduction.index.date)\n",
    "    return dailyProduction\n",
    "\n",
    "def generate_max_production_estimator(systemMetadata):\n",
    "    latitude = systemMetadata['metadata']['loc_latitude']\n",
    "    longitude = systemMetadata['metadata']['loc_longitude']\n",
    "    altitude = systemMetadata['metadata']['loc_altitude']\n",
    "    Wp_Tot = systemMetadata['metadata']['pv_kwp'] * 1000\n",
    "    loss = systemMetadata['metadata']['loss'] * 100\n",
    "\n",
    "    arrays = []\n",
    "    for array_num, arrayData in systemMetadata['arrays'].items():\n",
    "        array = Array(\n",
    "            mount=FixedMount(surface_tilt=arrayData['pv_tilt'], surface_azimuth=arrayData['pv_azimut'], racking_model='open_rack'),\n",
    "            module_parameters={'pdc0': arrayData['pv_wp'], 'gamma_pdc': -0.004},\n",
    "            module_type='glass_polymer',\n",
    "            modules_per_string=arrayData['pv_number'],\n",
    "            strings=1,\n",
    "            temperature_model_parameters=TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_polymer'],\n",
    "        )\n",
    "        arrays.append(array)\n",
    "\n",
    "    location = Location(latitude=latitude, longitude=longitude, altitude=altitude, tz='Europe/Zurich')\n",
    "    system = PVSystem(arrays=arrays, \n",
    "                        inverter_parameters={'pdc0': Wp_Tot, 'eta_inv_nom': 0.96},\n",
    "                        losses_parameters = {'nameplate_rating': loss, 'soiling': 0, 'shading': 0, 'snow': 0, 'mismatch': 0, 'wiring': 0, 'connections': 0, 'lid': 0, 'age': 0, 'availability': 0})\n",
    "    modelChain = ModelChain(system, location, clearsky_model='ineichen', aoi_model='no_loss', spectral_model=\"no_loss\", losses_model='pvwatts')\n",
    "\n",
    "    return modelChain\n",
    "\n",
    "\n",
    "def remove_obvious_outliers(measured_series, max_estimated_series):   \n",
    "    # Remove stong outilers from the measured series, by removing all value that are greater than 2 time the expected value, and less than 0.\n",
    "    measured_series = measured_series[(measured_series < 3*max_estimated_series.max()) & (measured_series >= 0)]\n",
    "    return measured_series\n",
    "\n",
    "def tune_max_production_estimator(measured_series, max_estimated_series, window=7): \n",
    "    # Remove the obvious outliers. It's important before calculating the std, which can be strongly impacted by the strong outliers.\n",
    "    measured_series = remove_obvious_outliers(measured_series, max_estimated_series)\n",
    "\n",
    "    # Keep only the max measured value\n",
    "    max_measured_series = pd.Series(index=measured_series.index, dtype=float)\n",
    "    # Iterate over windows of a given size, and keep only the maximum value in each window\n",
    "    for i in range(0, len(measured_series), window):\n",
    "        window_data = measured_series.iloc[i:i+window]\n",
    "        if not window_data.empty and not window_data.isna().all():\n",
    "            max_value = window_data.max()\n",
    "            max_index = window_data.idxmax(skipna=True)\n",
    "            max_measured_series[max_index] = max_value\n",
    "    \n",
    "    # Calculate the relative difference between the maximum measured and maximum estimated value\n",
    "    realtive_difference = max_measured_series / max_estimated_series\n",
    "\n",
    "    # Compute statistics\n",
    "    std = realtive_difference.std()\n",
    "    mean = realtive_difference.mean()\n",
    "\n",
    "    # Remove the outilers that have a z-score greater than 1\n",
    "    z_scores = np.abs(realtive_difference - mean) / std\n",
    "    realtive_difference = realtive_difference[z_scores < 1]\n",
    "\n",
    "    # Get the loss that overestimate the estimate maximum daily energy\n",
    "    loss = 1-realtive_difference.max()\n",
    "    \n",
    "    return loss, std\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacheFilename_systemsData_EstimatedMaxDailyEnergy = os.path.join(dataCacheDirpath, 'systemsData_EstimatedMaxDailyEnergy.pkl')\n",
    "\n",
    "if useCached and os.path.exists(cacheFilename_systemsData_EstimatedMaxDailyEnergy):\n",
    "    # TODO how to deal if the cached data is not up to date and some systems have been added or removed?\n",
    "    print(f\"Loading cached data in {cacheFilename_systemsData_EstimatedMaxDailyEnergy}\")\n",
    "    systemsData_EstimatedMaxDailyEnergy = pd.read_pickle(cacheFilename_systemsData_EstimatedMaxDailyEnergy)\n",
    "else:\n",
    "    systemsData_EstimatedMaxDailyEnergy_dic = {}\n",
    "    for systemName in systemsName_Target:\n",
    "        tuned  = not tuneMaxProductionEstimators # If we don't want to tune the estimators, we say that the estimator is already tuned\n",
    "        # reset the loss in the metadata if we want to tune the estimators\n",
    "        if tuneMaxProductionEstimators:\n",
    "            systemsMetadata[systemName]['metadata']['loss'] = 0\n",
    "\n",
    "        while True: # emulate do while loop\n",
    "            ## ------------------ ##\n",
    "            ## Create ModelChains ##\n",
    "            ## ------------------ ##\n",
    "            estimator = generate_max_production_estimator(systemsMetadata[systemName])\n",
    "\n",
    "            ## ------------------- ##\n",
    "            ## Simulate production ##\n",
    "            ## ------------------- ##\n",
    "            measured_series = systemsData_MeasuredDailyEnergy[systemName]\n",
    "            startDate = measured_series[~measured_series.isna()].index.min()\n",
    "            endDate = measured_series[~measured_series.isna()].index.max()\n",
    "            estimatedMaxDailyEnergy = generate_max_production_estimate(startDate, endDate, estimator, samplingFreq='1h')\n",
    "\n",
    "            # add the series to the dictionary\n",
    "            systemsData_EstimatedMaxDailyEnergy_dic[systemName] = estimatedMaxDailyEnergy\n",
    "\n",
    "            ## --------------- ##\n",
    "            ## Tune estimators ##\n",
    "            ## --------------- ##\n",
    "            if tuned:\n",
    "                break\n",
    "\n",
    "            loss, std = tune_max_production_estimator(measured_series, estimatedMaxDailyEnergy)\n",
    "\n",
    "            # write the loss in systemsMetadata\n",
    "            systemsMetadata[systemName]['metadata']['loss'] = loss\n",
    "\n",
    "            if std > 1:\n",
    "                systemsName_Valid.remove(systemName)\n",
    "                systemsName_Target.remove(systemName)\n",
    "                print(f\"System {systemName} : We can't find the model corresponding to the measured data. This system is removed from the list of systems to be processed.\")\n",
    "\n",
    "            tuned = True\n",
    "\n",
    "\n",
    "\n",
    "    # Concatenate all the columns in the list to create one dataframe\n",
    "    systemsData_EstimatedMaxDailyEnergy = pd.concat(systemsData_EstimatedMaxDailyEnergy_dic, axis=1)\n",
    "    systemsData_EstimatedMaxDailyEnergy.index = pd.to_datetime(systemsData_EstimatedMaxDailyEnergy.index)\n",
    "    systemsData_EstimatedMaxDailyEnergy.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "    # Save the dataframe to a CSV file\n",
    "    systemsData_EstimatedMaxDailyEnergy.to_pickle(cacheFilename_systemsData_EstimatedMaxDailyEnergy)\n",
    "\n",
    "    # Save metadata with tuned parameters\n",
    "    if tuneMaxProductionEstimators:\n",
    "        with open(metadataFilepath, 'w') as f:\n",
    "            json.dump(systemsMetadata, f, indent=4)\n",
    "\n",
    "# Print the dataframe\n",
    "systemsData_EstimatedMaxDailyEnergy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative production\n",
    "\n",
    "True production scaled by the maximum production from the simulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the relative energy for each system\n",
    "systemsData_RelativeMeasuredDailyEnergy = systemsData_MeasuredDailyEnergy / systemsData_EstimatedMaxDailyEnergy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the difference between simulation with hourly and 10min sampling rate\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Simulate the daily production for each system with 1h and 10min sampling rate\n",
    "dailyProductions = {}\n",
    "\n",
    "for systemName, modelChain in modelChains.items():\n",
    "    try:\n",
    "        dailyProduction_hour = simulateDailyProduction(systemName, systemsData, modelChains, samplingFreq='1h')\n",
    "        dailyProduction_min = simulateDailyProduction(systemName, systemsData, modelChains, samplingFreq='10min')\n",
    "        dailyProductions[systemName] = pd.DataFrame({'Simulator hour': dailyProduction_hour, 'Simulator 10min': dailyProduction_min})\n",
    "    except Exception as e:\n",
    "        print(f\"Error for system {systemName}: {e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "# Compute the descriptive statistics of the difference between the 1h and 10min simulations on all systems\n",
    "allSimulations = pd.concat(dailyProductions.values())\n",
    "\n",
    "allSimulations['Difference'] = allSimulations['Simulator hour'] - allSimulations['Simulator 10min']\n",
    "allSimulations['Percentage'] = allSimulations['Difference'] / allSimulations['Simulator 10min'] * 100\n",
    "\n",
    "descriptiveStat = allSimulations[['Difference', 'Percentage']].describe()\n",
    "print(descriptiveStat)\n",
    "\n",
    "\n",
    "# Plot the histogram of the percentage of the difference\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=allSimulations['Percentage'], nbinsx=1000))\n",
    "fig.add_vline(x=descriptiveStat.loc['mean','Percentage'], line_color='red', line_width=2, annotation_text='mean')\n",
    "fig.add_vline(x=descriptiveStat.loc['25%','Percentage'], line_color='green', line_width=2, annotation_text='25%')\n",
    "fig.add_vline(x=descriptiveStat.loc['75%','Percentage'], line_color='green', line_width=2, annotation_text='75%')\n",
    "fig.update_xaxes(dtick=0.1)\n",
    "fig.update_xaxes(range=[-1, 1])\n",
    "fig.update_layout(width=1000, height=666)\n",
    "fig.update_layout(xaxis_title='Percentage of the difference (%)')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Plot the daily production of a system with 1h and 10min sampling rate\n",
    "systemName = 'a001096'\n",
    "dailyProduction_hour = simulateDailyProduction(systemName, systemsData, modelChains, samplingFreq='1h')\n",
    "dailyProduction_min = simulateDailyProduction(systemName, systemsData, modelChains, samplingFreq='10min')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=dailyProduction_min.index, y=dailyProduction_min, mode='markers', name='10min sampling rate'))\n",
    "fig.add_trace(go.Scatter(x=dailyProduction_hour.index, y=dailyProduction_hour, mode='markers', name='Hourly sampling rate'))\n",
    "\n",
    "fig.update_layout(title=f'Simulated daily max AC energy of system {systemName}', xaxis_title='Time', yaxis_title='Energy (kWh)')\n",
    "fig.update_layout(width=1000, height=666)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Half-Sibling Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_system_data(targetName):\n",
    "    # Create the feature matrix X and the target vector y\n",
    "    X = systemsData_RelativeMeasuredDailyEnergy.drop(columns=targetName)\n",
    "    y = systemsData_RelativeMeasuredDailyEnergy[targetName]\n",
    "    # remove the observations where their is no target value\n",
    "    X = X[~y.isna()]\n",
    "    y = y[~y.isna()]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error_mean_denominator(\n",
    "    y_true, y_pred, *, sample_weight=None, multioutput=\"uniform_average\"\n",
    "):\n",
    "    # Copy of the function mean_absolute_percentage_error from sklearn.metrics._regression, with the denominator of the MAPE changed to the mean of the true values\n",
    "    import sklearn\n",
    "\n",
    "    y_type, y_true, y_pred, multioutput = sklearn.metrics._regression._check_reg_targets(\n",
    "        y_true, y_pred, multioutput\n",
    "    )\n",
    "    sklearn.utils.validation.check_consistent_length(y_true, y_pred, sample_weight)\n",
    "    epsilon = np.finfo(np.float64).eps\n",
    "    mape = np.abs(y_pred - y_true) / np.maximum(np.mean(np.abs(y_true)), epsilon)\n",
    "    output_errors = np.average(mape, weights=sample_weight, axis=0)\n",
    "    if isinstance(multioutput, str):\n",
    "        if multioutput == \"raw_values\":\n",
    "            return output_errors\n",
    "        elif multioutput == \"uniform_average\":\n",
    "            # pass None as weights to np.average: uniform mean\n",
    "            multioutput = None\n",
    "\n",
    "    return np.average(output_errors, weights=multioutput)\n",
    "\n",
    "\n",
    "def mad(arr):\n",
    "    return abs(arr - arr.median()).median()\n",
    "\n",
    "\n",
    "def modified_z_score(arr):\n",
    "    # based on https://www.ibm.com/docs/en/cognos-analytics/11.1.0?topic=terms-modified-z-score\n",
    "    mad_value = mad(arr)\n",
    "    if mad_value == 0:\n",
    "        MeanAD = np.mean(np.abs(arr - np.mean(arr)))\n",
    "        denominator = 1.253314 * MeanAD\n",
    "    else:\n",
    "        denominator = 1.486 * mad_value\n",
    "\n",
    "    return (arr - np.median(arr)) / denominator\n",
    "\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'MAPE': mean_absolute_percentage_error(y_true, y_pred),\n",
    "        'MAPE-MD': mean_absolute_percentage_error_mean_denominator(y_true, y_pred),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'RMSE': root_mean_squared_error(y_true, y_pred),\n",
    "        'R2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# Return the metrics for a RFR model trained on the given data.\n",
    "# The entire dataset is used for training, and the OOB prediction is used to compute the metrics.\n",
    "\n",
    "\n",
    "def obb_metrics(X, y, metricFct, rf_parames={}):\n",
    "    model = RandomForestRegressor(oob_score=True, **rf_parames)\n",
    "    y_pred = model.fit(X, y).oob_prediction_\n",
    "    return metricFct(y, y_pred)\n",
    "\n",
    "# Return the metrics for a RFR model trained on the given data.\n",
    "# KFold cross-validation is used train the model and to compute the metrics.\n",
    "\n",
    "\n",
    "def kfold_metrics(X, y, metricFct, rf_parames={}, n_folds=5):\n",
    "    model = RandomForestRegressor(**rf_parames)\n",
    "    metrics_list = []\n",
    "\n",
    "    for train_index, test_index in KFold(n_splits=n_folds).split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "        metrics_list.append(metricFct(y_test, y_pred))\n",
    "\n",
    "    if isinstance(metrics_list[0], dict):\n",
    "        # Convert list of dictionaries to a DataFrame\n",
    "        metrics_df = pd.DataFrame(metrics_list)\n",
    "        # Compute mean for each column\n",
    "        aggregated_metrics = metrics_df.mean().to_dict()\n",
    "        return aggregated_metrics\n",
    "    else:\n",
    "        # Compute mean of the list for numerical metrics\n",
    "        return np.mean(metrics_list)\n",
    "\n",
    "\n",
    "def _accumulate_prediction(predict, X, out, lock):\n",
    "    \"\"\"\n",
    "    This is a utility function for joblib's Parallel.\n",
    "\n",
    "    It can't go locally in ForestClassifier or ForestRegressor, because joblib\n",
    "    complains that it cannot pickle it when placed there.\n",
    "    \"\"\"\n",
    "    prediction = predict(X, check_input=False)\n",
    "    with lock:\n",
    "        out.append(prediction)\n",
    "\n",
    "\n",
    "def predict_w_std(self, X):\n",
    "    \"\"\"\n",
    "    Predict regression target and standard deviation for X.\n",
    "\n",
    "    The predicted regression target of an input sample is computed as the\n",
    "    mean predicted regression targets of the trees in the forest. The standard\n",
    "    deviation of the predicted regression targets of the trees in the forest\n",
    "    is also computed to provide an estimate of the prediction uncertainty.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "        The input samples. Internally, its dtype will be converted to\n",
    "        ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
    "        converted into a sparse ``csr_matrix``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mean_predictions : ndarray of shape (n_samples,)\n",
    "        The predicted values (mean of the predictions from all estimators).\n",
    "    std_predictions : ndarray of shape (n_samples,)\n",
    "        The standard deviation of the predicted values (standard deviation of the\n",
    "        predictions from all estimators).\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        If the model was trained for multi-output regression.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function does not support multi-output regression. If the model was\n",
    "    trained for multi-output regression, an exception will be raised.\n",
    "    \"\"\"\n",
    "\n",
    "    if self.n_outputs_ > 1:\n",
    "        raise NotImplementedError(\"Variance for multi-output regression is not supported now\")\n",
    "\n",
    "    check_is_fitted(self)\n",
    "    # Check data\n",
    "    X = self._validate_X_predict(X)\n",
    "\n",
    "    # Assign chunk of trees to jobs\n",
    "    n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n",
    "\n",
    "    # avoid storing the output of every estimator by summing them here\n",
    "\n",
    "    # Initialize a list to collect predictions from each estimator\n",
    "    all_predictions = []\n",
    "\n",
    "    # Parallel loop\n",
    "    lock = threading.Lock()\n",
    "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n",
    "        delayed(_accumulate_prediction)(e.predict, X, all_predictions, lock)\n",
    "        for e in self.estimators_\n",
    "    )\n",
    "\n",
    "    # Convert list to numpy array for easier manipulation\n",
    "    all_predictions = np.array(all_predictions)\n",
    "\n",
    "    # Compute mean and variance across predictions from all estimators\n",
    "    mean_predictions = np.mean(all_predictions, axis=0)\n",
    "    std_predictions = np.std(all_predictions, axis=0)\n",
    "\n",
    "    return mean_predictions, std_predictions\n",
    "\n",
    "\n",
    "RandomForestRegressor.predict_w_std = predict_w_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters tuning\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Number of trees in random forest. from 1 to 200, with 20 steps\n",
    "n_estimators = [int(x) for x in np.linspace(start=1, stop=100, num=10)]\n",
    "# # Number of features to consider at every split\n",
    "max_features = ['log2']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [None]\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1]\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               # 'max_features': max_features,\n",
    "               # 'max_depth': max_depth,\n",
    "               # 'min_samples_split': min_samples_split,\n",
    "               # 'min_samples_leaf': min_samples_leaf\n",
    "            }"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# GRID SEARCH\n",
    "\n",
    "gs_results = {}\n",
    "\n",
    "for systemName in tqdm(systemsName_Target):\n",
    "    # remove the target column from the features\n",
    "    X, y = get_system_data(systemName)\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestRegressor(random_state=random_state, max_features='log2')\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_grid = GridSearchCV(estimator = rf, param_grid = random_grid, cv = 5, n_jobs=-1, refit=False, verbose=2, return_train_score=True, scoring=mae_scorer)\n",
    "    # Fit the random search model\n",
    "    gs_results.update({systemName:rf_grid.fit(X, y).cv_results_})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# PLOT RESULTS AND TIME\n",
    "\n",
    "fig = go.Figure()\n",
    "for systemName in systemsName_Target:\n",
    "    fig.add_trace(go.Scatter(x=gs_results[systemName]['param_n_estimators'], y=gs_results[systemName]['mean_test_score']*(-100), mode='lines+markers', name=systemName))\n",
    "# fig.add_trace(go.Scatter(x=gs_results['param_min_samples_leaf'], y=gs_results['mean_test_score']*(-100), mode='lines+markers'))\n",
    "fig.update_layout(\n",
    "    yaxis_title=\"Mean Absolute Error (%)\",\n",
    "    xaxis_title=\"Number of trees\",\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=666\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=gs_results['param_min_samples_leaf'], y=gs_results['mean_fit_time'], mode='lines+markers'))\n",
    "# fig.update_layout(\n",
    "#     yaxis_title=\"Fit time (s)\",\n",
    "#     xaxis_title=\"Min samples to create a node\",\n",
    "#     autosize=False,\n",
    "#     width=1000,\n",
    "#     height=666\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train regressors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "serializer = PickleSerializer()\n",
    "\n",
    "rf_regressors = {}\n",
    "\n",
    "# Random Forest Regressor hyperparameters\n",
    "n_estimators = 100  # Number of trees in random forest\n",
    "max_features = 'log2'  # Number of features to consider at every split\n",
    "max_depth = None  # Maximum number of levels in tree\n",
    "min_samples_split = 2  # Minimum number of samples required to split a node\n",
    "min_samples_leaf = 1  # Minimum number of samples required at each leaf node\n",
    "\n",
    "\n",
    "if useCached and not forceTrain:\n",
    "    # load the models in dataCacheDirpath/rf_regressors. The file name is the system name.\n",
    "    for systemName in systemsName_Target:\n",
    "        try:\n",
    "            rf_regressors[systemName] = serializer.retrieve_model(os.path.join(dataCacheDirpath, 'rf_regressors'), systemName)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    print(f\"Loaded {len(rf_regressors)}/{len(systemsName_Target)} models. {len(systemsName_Target) - len(rf_regressors)} models to train.\")\n",
    "\n",
    "\n",
    "for targetName in tqdm(set(systemsName_Target) - set(rf_regressors), desc='Training regressors'):\n",
    "    rf_regressor = RandomForestRegressor(oob_score=True, random_state=random_state, n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "    X, y = get_system_data(targetName)\n",
    "    # split the data into training and testing sets\n",
    "    rf_regressor.fit(X, y)\n",
    "    rf_regressors[targetName] = rf_regressor\n",
    "    # save the model in dataCacheDirpath/rf_regressors. The file name is the system name.\n",
    "    serializer.save_model(rf_regressor, os.path.join(dataCacheDirpath, 'rf_regressors'), targetName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetName = 'a001286'\n",
    "# Create the feature matrix X and the target vector y\n",
    "X = systemsData_RelativeMeasuredDailyEnergy.drop(columns=targetName)\n",
    "y = systemsData_RelativeMeasuredDailyEnergy[targetName]\n",
    "# remove the observations where their is no target value\n",
    "X = X[~y.isna()]\n",
    "y = y[~y.isna()]\n",
    "\n",
    "# split the data into training and testing sets. data after the 1st June 2023 are used for training\n",
    "X_test, X_train  = X.loc[X.index < pd.Timestamp('2023-06-01')], X.loc[X.index >= pd.Timestamp('2023-06-01')]\n",
    "y_test, y_train = y.loc[y.index < pd.Timestamp('2023-06-01')], y.loc[y.index >= pd.Timestamp('2023-06-01')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rf_regressor = RandomForestRegressor(oob_score=True, random_state=random_state, n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "y_pred, y_std = rf_regressor.predict_w_std(X_test)\n",
    "\n",
    "# plot y_test, y_train, and y_pred with error bar y_std with two colors\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=y_test.index, y=y_test, mode='markers', name='y_test'))\n",
    "fig.add_trace(go.Scatter(x=y_train.index, y=y_train, mode='markers', name='y_train'))\n",
    "fig.add_trace(go.Scatter(x=y_test.index, y=y_pred, mode='markers', name='y_pred'))\n",
    "# fig.add_trace(go.Scatter(x=y_test.index, y=y_pred + y_std, mode='lines', line=dict(width=0), showlegend=False))\n",
    "# fig.add_trace(go.Scatter(x=y_test.index, y=y_pred - y_std, mode='lines', fill='tonexty', fillcolor='rgba(0,100,80,0.2)', line=dict(width=0), showlegend=False))\n",
    "fig.update_layout(title=f'{targetName} prediction with error bars', xaxis_title='Date', yaxis_title='Relative energy')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelChains[targetName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compupte metrics of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacheFilename_regressorsMetrics = os.path.join(dataCacheDirpath, 'metrics.csv')\n",
    "\n",
    "if useCached and os.path.exists(cacheFilename_regressorsMetrics):\n",
    "    # TODO how to deal if the cached data is not up to date and some systems have been added or removed?\n",
    "    print(f\"Loading cached data in {cacheFilename_regressorsMetrics}\")\n",
    "    regressorsMetrics = pd.read_csv(cacheFilename_regressorsMetrics, index_col=0).squeeze()\n",
    "else:\n",
    "\n",
    "    regressorsMetrics = pd.Series(index=systemsName_Target, name='MAE')\n",
    "\n",
    "    for targetName in systemsName_Target:\n",
    "\n",
    "        X, y = get_system_data(targetName)\n",
    "\n",
    "        rf_regressor = rf_regressors[targetName]\n",
    "\n",
    "        regressorsMetrics.loc[targetName] = mean_absolute_error(y, rf_regressor.oob_prediction_)\n",
    "\n",
    "    # save the metrics\n",
    "\n",
    "    regressorsMetrics.to_csv(cacheFilename_regressorsMetrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_permutation_importance = False\n",
    "\n",
    "cacheFilename_features_importance = os.path.join(dataCacheDirpath, 'features_importance.csv')\n",
    "cacheFilename_permutation_importance_mean = os.path.join(dataCacheDirpath, 'permutation_importance_mean.csv')\n",
    "cacheFilename_permutation_importance_std = os.path.join(dataCacheDirpath, 'permutation_importance_std.csv')\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "if useCached and os.path.exists(cacheFilename_features_importance):\n",
    "    print(f\"Loading cached data in {cacheFilename_features_importance}\")\n",
    "    features_importance_df = pd.read_csv(cacheFilename_features_importance, index_col=0)\n",
    "else:\n",
    "    features_importance_df = pd.DataFrame(index=systemsName_Target, columns=systemsName_Valid)\n",
    "    for targetName in systemsName_Target:\n",
    "        X, y = get_system_data(targetName)\n",
    "        rf_regressor = rf_regressors[targetName]\n",
    "        features_importance_df.loc[targetName, X.columns] = rf_regressor.feature_importances_\n",
    "    # save the feature importances\n",
    "    features_importance_df.to_csv(cacheFilename_features_importance)\n",
    "\n",
    "\n",
    "if compute_permutation_importance:\n",
    "    if useCached and os.path.exists(cacheFilename_permutation_importance_mean) and os.path.exists(cacheFilename_permutation_importance_std):\n",
    "        print(f\"Loading cached data in {cacheFilename_permutation_importance_mean}\")\n",
    "        permutation_importance_mean_df = pd.read_csv(cacheFilename_permutation_importance_mean, index_col=0)\n",
    "        print(f\"Loading cached data in {cacheFilename_permutation_importance_std}\")\n",
    "        permutation_importance_std_df = pd.read_csv(cacheFilename_permutation_importance_std, index_col=0)\n",
    "    else:\n",
    "        permutation_importance_mean_df = pd.DataFrame(index=systemsName_Target, columns=systemsName_Valid)\n",
    "        permutation_importance_std_df = pd.DataFrame(index=systemsName_Target, columns=systemsName_Valid)\n",
    "        for targetName in tqdm(systemsName_Target):\n",
    "            X, y = get_system_data(targetName)\n",
    "            rf_regressor = rf_regressors[targetName]\n",
    "            permutation_importance_results = permutation_importance(rf_regressor, X, y, n_repeats=5, random_state=random_state, n_jobs=-1, scoring=mae_scorer)\n",
    "            permutation_importance_mean_df.loc[targetName, X.columns] = permutation_importance_results.importances_mean\n",
    "            permutation_importance_std_df.loc[targetName, X.columns] = permutation_importance_results.importances_std\n",
    "        # save the permutation importances\n",
    "        permutation_importance_mean_df.to_csv(cacheFilename_permutation_importance_mean)\n",
    "        permutation_importance_std_df.to_csv(cacheFilename_permutation_importance_std)\n",
    "\n",
    "\n",
    "# print(f\"Time elapsed: {time.time() - start} - Time per system: {(time.time() - start) / len(systemsName_Target)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "serializer = PickleSerializer()\n",
    "\n",
    "rf_regressors = {}\n",
    "forceTrain = True\n",
    "if not forceTrain:\n",
    "    # load the models in dataCacheDirpath/rf_regressors. The file name is the system name.\n",
    "    for systemName in systemsName_Target:\n",
    "        try:\n",
    "            rf_regressors[systemName] = serializer.retrieve_model(os.path.join(dataCacheDirpath, 'rf_regressors'), systemName)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    print(f\"Loaded {len(rf_regressors)}/{len(systemsName_Target)} models. {len(systemsName_Target) - len(rf_regressors)} models to train.\")\n",
    "\n",
    "# Train a Random Forest Regressor model to predict the daily energy production of a system based on the daily energy production of the other systems\n",
    "metrics_df = pd.DataFrame(index=systemsName_Target, columns=['MAPE', 'MAPE-MD', 'MAE', 'RMSE', 'R2'])\n",
    "features_importance_df = pd.DataFrame(index=systemsName_Target, columns=systemsName_Valid)\n",
    "permutation_importance_df = pd.DataFrame(index=systemsName_Target, columns=systemsName_Valid)\n",
    "\n",
    "for targetName in tqdm(set(systemsName_Target) - set(rf_regressors), desc='Training regressors'):\n",
    "    rf_regressor = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=random_state)\n",
    "    # remove the target column from the features\n",
    "    X = systemsData_MeasuredRelativeDailyEnergy.drop(columns=targetName)\n",
    "    y = systemsData_MeasuredRelativeDailyEnergy[targetName]\n",
    "    # remove the observations where their is no target value\n",
    "    X = X[~systemsData_MeasuredRelativeDailyEnergy[targetName].isna()]\n",
    "    y = y[~systemsData_MeasuredRelativeDailyEnergy[targetName].isna()]\n",
    "    # split the data into training and testing sets\n",
    "    # TODo utiliser OOB\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_state) # Not necessary to split the data, as the OOB can be used to estimate the error\n",
    "    # train the regressor\n",
    "    y_oob_pred = rf_regressor.fit(X, y).oob_prediction_\n",
    "    # save the feature importances\n",
    "    features_importance_df.loc[targetName, X.columns] = rf_regressor.feature_importances_\n",
    "    # permutation_importance_df.loc[targetName, X.columns] = permutation_importance(rf_regressor, X_test, y_test, n_repeats=10, random_state=random_state, n_jobs=-1).importances_mean\n",
    "\n",
    "    # test the regressor\n",
    "    # y_mean = rf_regressor.predict(X_test)\n",
    "\n",
    "    # y_pred_V_IJ_unbiased = fci.random_forest_error(rf_regressor, X_train, X_test)\n",
    "\n",
    "    # compute the metrics\n",
    "    metrics_df.loc[targetName] = metrics(y, y_oob_pred)\n",
    "\n",
    "    # save the model\n",
    "    # serializer.save_model(rf_regressor, os.path.join(dataCacheDirpath, 'rf_regressors'), targetName)\n",
    "    rf_regressors[targetName] = rf_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate expected value for each systems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacheFilename_systemsData_RelativeExpectedDailyEnergy_mean = os.path.join(dataCacheDirpath, 'systemsData_RelativeExpectedDailyEnergy_mean.pkl')\n",
    "cacheFilename_systemsData_RelativeExpectedDailyEnergy_std = os.path.join(dataCacheDirpath, 'systemsData_RelativeExpectedDailyEnergy_std.pkl')\n",
    "\n",
    "if useCached and os.path.exists(cacheFilename_systemsData_RelativeExpectedDailyEnergy_mean) and os.path.exists(cacheFilename_systemsData_RelativeExpectedDailyEnergy_std):\n",
    "\n",
    "    print(f\"Loading cached data in {cacheFilename_systemsData_RelativeExpectedDailyEnergy_mean}\")\n",
    "    systemsData_RelativeExpectedDailyEnergy_mean = pd.read_pickle(cacheFilename_systemsData_RelativeExpectedDailyEnergy_mean)\n",
    "    print(f\"Loading cached data in {cacheFilename_systemsData_RelativeExpectedDailyEnergy_std}\")\n",
    "    systemsData_RelativeExpectedDailyEnergy_std = pd.read_pickle(cacheFilename_systemsData_RelativeExpectedDailyEnergy_std)\n",
    "\n",
    "else:\n",
    "\n",
    "    # Create an empty list to store all expected data for each systems\n",
    "\n",
    "    systemsData_RelativeExpectedDailyEnergy_mean_List = []\n",
    "    systemsData_RelativeExpectedDailyEnergy_std_List = []\n",
    "\n",
    "    for systemName in tqdm(systemsName_Target, desc='Generating expected daily energy'):\n",
    "        # Comute the expected daily energy for the target system for all the dates\n",
    "        X, _ = get_system_data(systemName)\n",
    "        y_mean, y_std = rf_regressors[systemName].predict_w_std(X)\n",
    "        y_mean = pd.Series(y_mean, index=X.index, name=systemName)\n",
    "        y_std = pd.Series(y_std, index=X.index, name=systemName)\n",
    "        systemsData_RelativeExpectedDailyEnergy_mean_List.append(y_mean)\n",
    "        systemsData_RelativeExpectedDailyEnergy_std_List.append(y_std)\n",
    "\n",
    "    # Concatenate all the columns in the list to create one dataframe\n",
    "    systemsData_RelativeExpectedDailyEnergy_mean = pd.concat(systemsData_RelativeExpectedDailyEnergy_mean_List, axis=1).sort_index()\n",
    "    systemsData_RelativeExpectedDailyEnergy_std = pd.concat(systemsData_RelativeExpectedDailyEnergy_std_List, axis=1).sort_index()\n",
    "\n",
    "    # Save the dataframe to a CSV file\n",
    "    systemsData_RelativeExpectedDailyEnergy_mean.to_pickle(cacheFilename_systemsData_RelativeExpectedDailyEnergy_mean)\n",
    "    systemsData_RelativeExpectedDailyEnergy_std.to_pickle(cacheFilename_systemsData_RelativeExpectedDailyEnergy_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute absolute expected daily energy\n",
    "systemsData_ExpectedDailyEnergy_mean = systemsData_RelativeExpectedDailyEnergy_mean * systemsData_EstimatedMaxDailyEnergy\n",
    "systemsData_ExpectedDailyEnergy_std = systemsData_RelativeExpectedDailyEnergy_std * systemsData_EstimatedMaxDailyEnergy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling technics & Outliers removal\n",
    "\n",
    "Compute the:\n",
    "\n",
    "- Global mean\n",
    "- Global median\n",
    "- Global standard deviation\n",
    "- Rolling mean\n",
    "- Rolling median\n",
    "- Rolling standard deviation\n",
    "- Simulate max production without info\n",
    "- SImulated max production with info\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "targetName = \"a001395\"\n",
    "\n",
    "X = systemsData_MeasuredDailyEnergy.drop(columns=targetName)\n",
    "y = systemsData_MeasuredDailyEnergy[targetName]\n",
    "y.index = pd.to_datetime(y.index)\n",
    "# Global mean of the daily energy production of the target system\n",
    "globalMean = y.mean()\n",
    "\n",
    "# Global std of the daily energy production of the target system\n",
    "globalStd = y.std()\n",
    "\n",
    "# Gloabl median of the daily energy production of the target system\n",
    "globalMedian = y.median()\n",
    "\n",
    "roll = y.rolling(window='30D', min_periods=1, center=True)\n",
    "# Rolling mean of the daily energy production of the target system. The window is 1 month\n",
    "rollingMean = roll.mean()\n",
    "\n",
    "# Rolling std of the daily energy production of the target system. The window is 7 days.\n",
    "rollingStd = roll.std()\n",
    "\n",
    "# Rolling Mean Absolute Deviation of the daily energy production of the target system. the function is mad with the arguments how='median' and center='median'\n",
    "rollingMAD = roll.apply(mad)\n",
    "# Rolling median of the daily energy production of the target system. The window is 7 days.\n",
    "rollingMedian = roll.median()\n",
    "\n",
    "# Rolling z score of the daily energy production of the target system. The function is modified_z_score\n",
    "# modifiedZScore = 0.673 * (y - rollingMedian) / rollingMAD\n",
    "\n",
    "# Plot the global and rolling mean, std, and median of the daily energy production of the target system\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=y.index, y=y, mode='markers', name='Daily energy production'))\n",
    "# fig.add_trace(go.Scatter(x=y.index, y=[globalMean]*len(y), mode='lines', name='Global mean'))\n",
    "# fig.add_trace(go.Scatter(x=y.index, y=[globalMean+globalStd]*len(y), mode='lines', name='Global mean + std'))\n",
    "# fig.add_trace(go.Scatter(x=y.index, y=[globalMean-globalStd]*len(y), mode='lines', name='Global mean - std'))\n",
    "# fig.add_trace(go.Scatter(x=y.index, y=[globalMedian]*len(y), mode='lines', name='Global median'))\n",
    "fig.add_trace(go.Scatter(x=rollingMean.index, y=rollingMean, mode='lines', name='Rolling mean'))\n",
    "# fig.add_trace(go.Scatter(x=rollingMean.index, y=rollingMean+rollingStd, mode='lines', name='Rolling mean + std'))\n",
    "# fig.add_trace(go.Scatter(x=rollingMean.index, y=rollingMean-rollingStd, mode='lines', name='Rolling mean - std'))\n",
    "fig.add_trace(go.Scatter(x=rollingMedian.index, y=rollingMedian, mode='lines', name='Rolling median'))\n",
    "fig.add_trace(go.Scatter(x=rollingMAD.index, y=rollingMedian + 4 * rollingMAD, mode='lines', name='Rolling Median + 4*Rolling MAD'))\n",
    "fig.add_trace(go.Scatter(x=rollingMAD.index, y=rollingMAD, mode='lines', name='Rolling MAD'))\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=modifiedZScore.index, y=rollingMedian+modifiedZScore, mode='lines', name='Rolling Median + Rolling Z score'))\n",
    "\n",
    "fig.update_layout(title=f'Global and rolling mean, std, and median of the daily energy production of system {targetName}', yaxis_title='Daily energy production (kWh)')\n",
    "# fig.update_layout(width=1000, height=666)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def zscore(s, window, thresh=3, return_all=False):\n",
    "    roll = s.rolling(window=window, min_periods=1, center=True)\n",
    "    avg = roll.mean()\n",
    "    std = roll.std(ddof=0)\n",
    "    z = s.sub(avg).div(std)\n",
    "    m = z.between(-thresh, thresh)\n",
    "\n",
    "    if return_all:\n",
    "        return z, avg, std, m\n",
    "    return s.where(m, avg)\n",
    "\n",
    "\n",
    "z, avg, std, m = zscore(y, window=50, return_all=True)\n",
    "\n",
    "ax = plt.subplot()\n",
    "\n",
    "y.plot(label='data')\n",
    "avg.plot(label='mean')\n",
    "y.loc[~m].plot(label='outliers', marker='o', ls='')\n",
    "# avg[~m].plot(label='replacement', marker='o', ls='')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "tab_height = '2em'\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        dcc.Dropdown(\n",
    "            id='system-dropdown',\n",
    "            options=[{'label': name, 'value': name} for name in systemsName_Target],\n",
    "            value=systemsName_Target[0],\n",
    "            style={'width': '50%'}  # Adjust width and font size\n",
    "        ),\n",
    "        html.Div(id='metric-text', style={'display': 'inline-block', 'margin-left': '20px', 'fontSize': 16})  # Container for the metric text\n",
    "    ], style={'display': 'flex', 'align-items': 'center'}),  # Align items horizontally\n",
    "    dcc.Tabs(id='plot-tabs', value='tab-energy', children=[\n",
    "        dcc.Tab(label='Energy', value='tab-energy', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
    "        dcc.Tab(label='Relative Energy', value='tab-rel-energy', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
    "        dcc.Tab(label='Similar neighboring systems', value='tab-neighbors', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
    "    ]),  # Adjust height for tabs\n",
    "    html.Div(id='tabs-content', style={'flex': '1 1 auto'})  # Allow the tabs-content div to grow\n",
    "], style={'display': 'flex', 'flexDirection': 'column', 'height': '100vh'})  # Make the outer container fill the screen height\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [Output('tabs-content', 'children'),\n",
    "     Output('metric-text', 'children')],\n",
    "    [Input('plot-tabs', 'value'),\n",
    "     Input('system-dropdown', 'value')]\n",
    ")\n",
    "def render_content(tab, selected_system):\n",
    "    #test if the regressorsMetrics variable exist\n",
    "    try:\n",
    "        # Mean Absolute Error: {regressorsMetrics.loc[selected_system] * 100:.2f}\\n\n",
    "        metric_text = f\"Loss: {systemsMetadata[selected_system]['metadata']['loss']*100:.2f}%\"\n",
    "    except:\n",
    "        metric_text = \"No metric available for this system\"\n",
    "\n",
    "    if tab == 'tab-energy':\n",
    "        fig1 = go.Figure(layout_yaxis_title=\"Daily Energy (kWh)\")\n",
    "\n",
    "        try:\n",
    "            fig1.add_trace(go.Scatter(\n",
    "                x=systemsData_EstimatedMaxDailyEnergy[selected_system].index,\n",
    "                y=systemsData_EstimatedMaxDailyEnergy[selected_system],\n",
    "                mode='markers',\n",
    "                name='Simulated Max Daily Energy'\n",
    "            ))\n",
    "        except: pass\n",
    "        \n",
    "        # try:\n",
    "        #     fig1.add_trace(go.Scatter(\n",
    "        #         x=systemsData_EstimatedMaxDailyEnergy2[selected_system].index,\n",
    "        #         y=systemsData_EstimatedMaxDailyEnergy2[selected_system],\n",
    "        #         mode='markers',\n",
    "        #         name='Simulated Max Daily Energy TUNED'\n",
    "        #     ))\n",
    "        # except: pass\n",
    "\n",
    "        try:\n",
    "            fig1.add_trace(go.Scatter(\n",
    "                x=systemsData_MeasuredDailyEnergy[selected_system].index,\n",
    "                y=systemsData_MeasuredDailyEnergy[selected_system],\n",
    "                mode='markers',\n",
    "                name='Measured Daily Energy'\n",
    "            ))\n",
    "        except: pass\n",
    "\n",
    "        try:\n",
    "            fig1.add_trace(go.Scatter(\n",
    "                x=systemsData_ExpectedDailyEnergy_mean[selected_system].index,\n",
    "                y=systemsData_ExpectedDailyEnergy_mean[selected_system],\n",
    "                mode='markers',\n",
    "                name='Expected Daily Energy'\n",
    "            ))\n",
    "        except: pass\n",
    "\n",
    "        # Update layout for legend position\n",
    "        fig1.update_layout(\n",
    "            legend=dict(\n",
    "                x=0.99,\n",
    "                y=0.99,\n",
    "                xanchor='right',\n",
    "                yanchor='top',\n",
    "                orientation='h'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return dcc.Graph(figure=fig1, style={'height': '100%', 'width': '100%'}), metric_text  # Adjust height and width of the figure\n",
    "\n",
    "    elif tab == 'tab-rel-energy':\n",
    "        fig1 = go.Figure(layout_yaxis_title=\"Proportional Daily Energy (%)\")\n",
    "        try:\n",
    "            fig1.add_trace(go.Scatter(\n",
    "                x=systemsData_RelativeMeasuredDailyEnergy[selected_system].index,\n",
    "                y=systemsData_RelativeMeasuredDailyEnergy[selected_system],\n",
    "                mode='markers',\n",
    "                name='Measured Daily Energy'\n",
    "            ))\n",
    "        except: pass\n",
    "        try:\n",
    "            fig1.add_trace(go.Scatter(\n",
    "                x=systemsData_RelativeExpectedDailyEnergy_mean[selected_system].index,\n",
    "                y=systemsData_RelativeExpectedDailyEnergy_mean[selected_system],\n",
    "                mode='markers',\n",
    "                name='Expected Daily Energy'\n",
    "            ))\n",
    "        except: pass\n",
    "\n",
    "        return dcc.Graph(figure=fig1, style={'height': '100%', 'width': '100%'}), metric_text  # Adjust height and width of the figure\n",
    "\n",
    "    elif tab == 'tab-neighbors':\n",
    "        fig2 = go.Figure()\n",
    "\n",
    "        # Add initial traces with secondary y-axis\n",
    "        try:\n",
    "            fig2.add_trace(go.Bar(\n",
    "                x=features_importance_df.columns,\n",
    "                y=features_importance_df.loc[selected_system],\n",
    "                name='Impurity-based Importance',\n",
    "                yaxis='y1',\n",
    "                offsetgroup=1\n",
    "            ))\n",
    "        except: pass\n",
    "        try:\n",
    "            fig2.add_trace(go.Bar(\n",
    "                x=permutation_importance_mean_df.columns,\n",
    "                y=permutation_importance_mean_df.loc[selected_system],\n",
    "                name='Permutation Importance',\n",
    "                yaxis='y2',\n",
    "                offsetgroup=2\n",
    "            ))\n",
    "        except: pass\n",
    "        try:\n",
    "            fig2.update_layout(\n",
    "                yaxis1=dict(\n",
    "                    title='Impurity-based Importance',\n",
    "                    range=[0, features_importance_df.loc[selected_system].max()],\n",
    "                )\n",
    "            )\n",
    "        except: pass\n",
    "        try:\n",
    "            fig2.update_layout(\n",
    "                yaxis2=dict(\n",
    "                    title='Permutation Importance',\n",
    "                    overlaying='y',\n",
    "                    side='right',\n",
    "                    range=[0, permutation_importance_mean_df.loc[selected_system].max()],\n",
    "                )\n",
    "            )\n",
    "        except: pass\n",
    "\n",
    "        return dcc.Graph(figure=fig2, style={'height': '100%', 'width': '100%'}), metric_text  # Adjust height and width of the figure\n",
    "\n",
    "\n",
    "def open_browser():\n",
    "    webbrowser.open(\"http://127.0.0.1:8050/\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Open the Dash app in a new browser window\n",
    "    Timer(1, open_browser).start()\n",
    "    app.run_server(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting result from a prediction\n",
    "\n",
    "https://towardsdatascience.com/interpreting-random-forests-638bca8b49ea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemsMetadata['a001464']['arrays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
