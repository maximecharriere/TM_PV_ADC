{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup & Import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pvlib\n",
        "import json\n",
        "import os\n",
        "from pvlib.pvsystem import PVSystem, Array, FixedMount\n",
        "from pvlib.location import Location\n",
        "from pvlib.modelchain import ModelChain\n",
        "from pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, root_mean_squared_error, r2_score\n",
        "from sklearn.inspection import permutation_importance\n",
        "import forestci as fci\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import threading\n",
        "from sklearn.metrics import make_scorer\n",
        "import dash\n",
        "from dash import dcc, html\n",
        "import plotly.graph_objects as go\n",
        "from dash.dependencies import Input, Output\n",
        "import webbrowser\n",
        "from threading import Timer\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "from sklearn.utils.parallel import Parallel, delayed\n",
        "from sklearn.utils.validation import (\n",
        "    check_is_fitted,\n",
        ")\n",
        "from sklearn.ensemble._base import _partition_estimators\n",
        "\n",
        "pio.renderers.default = \"browser\"  # render plotly figures in browser\n",
        "\n",
        "PARENT_DATA_DIR = os.getenv('PARENT_DATA_DIR')\n",
        "if PARENT_DATA_DIR is None:\n",
        "    raise ValueError(\"PARENT_DATA_DIR environment variable is not set\")\n",
        "\n",
        "\n",
        "dataDirpath = PARENT_DATA_DIR + r\"\\PRiOT\\dataExport_2\"  # \"/Applications/Documents/TM Maxime/dataExport_3400_daily\"#\n",
        "dataCacheDirpath = os.path.join(dataDirpath, \"cache\")\n",
        "logsDirpath = \"../logs\"\n",
        "useCached = True\n",
        "forceTrain = False\n",
        "tuneMaxProductionEstimators = True\n",
        "random_state = 42\n",
        "\n",
        "\n",
        "testingDays = 100\n",
        "minTestingDays = 30\n",
        "minTrainingDays = 7\n",
        "\n",
        "if not os.path.exists(logsDirpath):\n",
        "    os.makedirs(logsDirpath)\n",
        "\n",
        "if not os.path.exists(dataCacheDirpath):\n",
        "    os.makedirs(dataCacheDirpath)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# create 15 random value between 0.0 and 20.0\n",
        "expected = np.random.uniform(0.0, 20.0, 15)\n",
        "expectedRelative = expected/20.0\n",
        "# create 10 value linearly spaced between 100 and 95\n",
        "linear_values = np.linspace(1.0, 0.90, num=10)\n",
        "#create 5 value at 50\n",
        "constant_values = np.repeat(0.60, 5)\n",
        "#concatenate the three arrays\n",
        "factors = np.concatenate([linear_values, constant_values])\n",
        "measure =  factors*expected\n",
        "measureRelative = measure/20.0\n",
        "\n",
        "mape = (expected-measure)/expected*100\n",
        "mapeRelative = (expectedRelative-measureRelative)/expectedRelative*100\n",
        "\n",
        "# plot expected values and measure in two trace. y axis is kWh, x axis is the date from June 1st 2024 to June 15th 2024\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=pd.date_range(start='2024-06-01', periods=15, freq='D'), y=expected, mode='lines+markers', name='Expected'))\n",
        "fig.add_trace(go.Scatter(x=pd.date_range(start='2024-06-01', periods=15, freq='D'), y=measure, mode='lines+markers', name='Measure'))\n",
        "fig.update_layout(xaxis_title='Date', yaxis_title='Production [kWh]')\n",
        "\n",
        "# set the fig to 1000x666\n",
        "fig.update_layout(width=1000, height=666)\n",
        "fig.show()\n",
        "# plot factors\n",
        "# set the y axis to % between 0 and 100\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=pd.date_range(start='2024-06-01', periods=15, freq='D'), y=mape, mode='markers', name='Relative Error'))\n",
        "fig.add_trace(go.Scatter(x=pd.date_range(start='2024-06-01', periods=15, freq='D'), y=mapeRelative, mode='markers', name='Relative Error RELATIVE'))\n",
        "fig.update_layout(xaxis_title='Date', yaxis_title='Relative Difference [%]')\n",
        "fig.update_yaxes(range=[0, 100])\n",
        "fig.update_layout(width=1000, height=666)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Serializer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/model_persistence.html\n",
        "\n",
        "\n",
        "class ModelSerializer:\n",
        "    def _save_model(self, model, serial_type, save_params):\n",
        "        serial_type.dump(model, save_params)\n",
        "\n",
        "    def _retrieve_model(self, serial_type, retrieve_params):\n",
        "        return serial_type.load(retrieve_params)\n",
        "\n",
        "\n",
        "# save_model_path = \"Serialized_models\\\\\"\n",
        "\n",
        "\n",
        "class JoblibSerializer(ModelSerializer):\n",
        "    def save_model(self, model, save_model_path, filename):\n",
        "        super()._save_model(model, joblib, os.path.join(save_model_path, filename + \".joblib\"))\n",
        "\n",
        "    def retrieve_model(self, save_model_path, filename):\n",
        "        return super()._retrieve_model(joblib, os.path.join(save_model_path, filename + '.joblib'))\n",
        "\n",
        "\n",
        "class PickleSerializer(ModelSerializer):\n",
        "    def save_model(self, model, save_model_path, filename):\n",
        "        # create folder if not exists\n",
        "        if not os.path.exists(save_model_path):\n",
        "            os.makedirs(save_model_path)\n",
        "        with open(os.path.join(save_model_path, filename + \".pkl\"), 'wb') as f:\n",
        "            super()._save_model(model, pickle, f)\n",
        "\n",
        "    def retrieve_model(self, save_model_path, filename):\n",
        "        with open(os.path.join(save_model_path, filename + \".pkl\"), 'rb') as f:\n",
        "            return super()._retrieve_model(pickle, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_altitude_from_wgs84(longitude, latitude):\n",
        "    # Convert WGS84 to LV95\n",
        "    lv95_url = \"https://geodesy.geo.admin.ch/reframe/wgs84tolv95\"\n",
        "    params_lv95 = {\n",
        "        \"easting\": longitude,\n",
        "        \"northing\": latitude,\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    response_lv95 = requests.get(lv95_url, params=params_lv95)\n",
        "    if response_lv95.status_code != 200:\n",
        "        raise Exception(\"Error converting WGS84 to LV95: \" + response_lv95.text)\n",
        "\n",
        "    lv95_data = response_lv95.json()\n",
        "    lv95_easting = lv95_data[\"easting\"]\n",
        "    lv95_northing = lv95_data[\"northing\"]\n",
        "\n",
        "    # Get altitude from LV95 coordinates\n",
        "    altitude_url = \"https://api3.geo.admin.ch/rest/services/height\"\n",
        "    params_altitude = {\n",
        "        \"easting\": lv95_easting,\n",
        "        \"northing\": lv95_northing\n",
        "    }\n",
        "\n",
        "    response_altitude = requests.get(altitude_url, params=params_altitude)\n",
        "    if response_altitude.status_code != 200:\n",
        "        raise Exception(\"Error retrieving altitude: \" + response_altitude.text)\n",
        "\n",
        "    altitude_data = response_altitude.json()\n",
        "    altitude = altitude_data[\"height\"]\n",
        "\n",
        "    return float(altitude)\n",
        "\n",
        "\n",
        "def remove_system(systemName, message):\n",
        "    if 'systemsName_Valid' in globals() and systemName in systemsName_Valid:\n",
        "        systemsName_Valid.remove(systemName)\n",
        "    if 'systemsName_Valid' in globals() and systemName in systemsName_Valid:\n",
        "        systemsName_Valid.remove(systemName)\n",
        "    if 'systemsData_EstimatedMaxDailyEnergy' in globals() and systemName in systemsData_EstimatedMaxDailyEnergy.columns:\n",
        "        systemsData_EstimatedMaxDailyEnergy.drop(columns=systemName, inplace=True)\n",
        "    if 'systemsData_MeasuredDailyEnergy_train' in globals() and systemName in systemsData_MeasuredDailyEnergy_train.columns:\n",
        "        systemsData_MeasuredDailyEnergy_train.drop(columns=systemName, inplace=True)\n",
        "    if 'systemsData_MeasuredDailyEnergy_test' in globals() and systemName in systemsData_MeasuredDailyEnergy_test.columns:\n",
        "        systemsData_MeasuredDailyEnergy_test.drop(columns=systemName, inplace=True)\n",
        "    if 'systemsData_MeasuredDailyEnergy' in globals() and systemName in systemsData_MeasuredDailyEnergy.columns:\n",
        "        systemsData_MeasuredDailyEnergy.drop(columns=systemName, inplace=True)\n",
        "    if 'normalizer_estimated_max_daily_energy' in globals() and systemName in normalizer_estimated_max_daily_energy:\n",
        "        normalizer_estimated_max_daily_energy.pop(systemName)\n",
        "    print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadataFilepath = os.path.join(dataDirpath, \"metadata.json\")\n",
        "\n",
        "with open(metadataFilepath, 'r') as f:\n",
        "    systemsMetadata = json.load(f)\n",
        "\n",
        "# Add altitude to metadata, if not already present (TODO : imporove with multi threading)\n",
        "\n",
        "for systemId, systemMetadata in tqdm(systemsMetadata.items()):\n",
        "    if \"loc_altitude\" not in systemMetadata['metadata']:\n",
        "        if \"loc_longitude\" in systemMetadata['metadata'] and \"loc_latitude\" in systemMetadata['metadata']:\n",
        "            systemMetadata['metadata'][\"loc_altitude\"] = get_altitude_from_wgs84(systemMetadata['metadata'][\"loc_longitude\"], systemMetadata['metadata'][\"loc_latitude\"])\n",
        "\n",
        "# Split arrays in dictionaries by module number\n",
        "for systemId, systemMetadata in systemsMetadata.items():\n",
        "    arrays = {}\n",
        "    keys_to_delete = []\n",
        "    for key, value in systemMetadata['metadata'].items():\n",
        "        if 'mod' in key:\n",
        "            # Extract the module number\n",
        "            array_num = key.split('_')[1][-1]\n",
        "            # Remove the module number from the key\n",
        "            new_key = '_'.join(key.split('_')[:1] + key.split('_')[2:])\n",
        "            # Add the key-value pair to the appropriate module dictionary\n",
        "            if 'arrays' not in systemMetadata:\n",
        "                systemMetadata['arrays'] = {}\n",
        "            if array_num not in systemMetadata['arrays']:\n",
        "                systemMetadata['arrays'][array_num] = {}\n",
        "            systemMetadata['arrays'][array_num][new_key] = value\n",
        "            keys_to_delete.append(key)\n",
        "    for key in keys_to_delete:\n",
        "        del systemMetadata['metadata'][key]\n",
        "\n",
        "# Save metadata with altitude\n",
        "with open(metadataFilepath, 'w') as f:\n",
        "    json.dump(systemsMetadata, f, indent=4)\n",
        "\n",
        "print(\"Number of systems in metadata: \", len(systemsMetadata))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import measures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "cacheFilename_systemsData_MeasuredDailyEnergy = os.path.join(dataCacheDirpath, 'systemsData_MeasuredDailyEnergy.pkl')\n",
        "if True and os.path.exists(cacheFilename_systemsData_MeasuredDailyEnergy):\n",
        "    print(f\"Loading cached data in {cacheFilename_systemsData_MeasuredDailyEnergy}\")\n",
        "    systemsData_MeasuredDailyEnergy = pd.read_pickle(cacheFilename_systemsData_MeasuredDailyEnergy)\n",
        "    systemsName_Valid = list(systemsData_MeasuredDailyEnergy.columns)\n",
        "else:\n",
        "    # Load all csv files from the data directory\n",
        "    systemsData = {}\n",
        "    for file in os.listdir(dataDirpath):\n",
        "        if file.endswith(\".csv\"):\n",
        "            systemName = file.split(\"_\")[0]\n",
        "            systemsData[systemName] = pd.read_csv(os.path.join(dataDirpath, file))\n",
        "            systemsData[systemName]['Datetime'] = pd.to_datetime(systemsData[systemName]['Timestamp'], unit='ms', utc=True).dt.tz_convert('Europe/Zurich')\n",
        "            systemsData[systemName]['Date'] = (systemsData[systemName]['Datetime'] + pd.Timedelta(hours=1)).dt.date  # Convert the datetime to only the date, as the production is the daily production. The +1h is to manage the saving time. Normally PRiOT exports the data at midnight (local time) for the day after (e.g. the energy for the July 1st is saved at July 1st 00:00 Europe/Zurich). However it seams that the saving time is not always correctly handled, and sometime the export is done at 23:00 the day before (e.g. the energy for the July 1st is saved at June 30th 23:00 Europe/Zurich). This is why we add 1h to the datetime to be sure to have the correct date.\n",
        "\n",
        "    systemsName = list(systemsData.keys())\n",
        "\n",
        "    df_duplicate_list = list()\n",
        "    for systemName, systemData in systemsData.items():\n",
        "        # Save duplicate dates to log list, and the in a log file\n",
        "        duplicates = systemData[systemData['Date'].duplicated(keep=False)]\n",
        "        if len(duplicates) > 0:\n",
        "            df_duplicate_list.append(duplicates)\n",
        "\n",
        "            # Remove duplicate date where tt_forward_active_energy_total_toDay is the smallest\n",
        "            # TODO maybe we should sum the energy of the duplicates instead of removing the smallest one. However, when looking in PRiOT Portal, it seams that in the daily energy, only the biggest value is represented. We do the same here.\n",
        "            systemData.sort_values('tt_forward_active_energy_total_toDay', ascending=True, inplace=True)\n",
        "            systemsData[systemName].drop_duplicates(subset='Date', keep='last', inplace=True)\n",
        "\n",
        "        # Set date as the index and sort the data by date\n",
        "        systemsData[systemName].set_index('Date', inplace=True)\n",
        "        systemData.sort_index(ascending=True, inplace=True)\n",
        "\n",
        "    # Save duplicate dates to log file\n",
        "    df_duplicate = pd.concat(df_duplicate_list)\n",
        "    print(f\"Number of duplicate dates found: {len(df_duplicate)} (see log file for more details)\")\n",
        "    df_duplicate.to_csv(os.path.join(logsDirpath, 'duplicateDates.csv'), index=True)\n",
        "\n",
        "    ## ----------------------------------------------- ##\n",
        "    ## Convert data & Filter out invalid PRiOT systems ##\n",
        "    ## ----------------------------------------------- ##\n",
        "\n",
        "    systemsName_Valid = systemsName.copy()\n",
        "    for systemName in systemsName:\n",
        "        missingData = False\n",
        "        # Check if the system has measures\n",
        "        if len(systemsData[systemName]) == 0:\n",
        "            missingData = True\n",
        "            print(f\"System {systemName} : No measures found\")\n",
        "        # Check if the system has metadata\n",
        "        if systemName not in systemsMetadata:\n",
        "            missingData = True\n",
        "            print(f\"System {systemName} : No metadata found\")\n",
        "\n",
        "        else:\n",
        "            # Check metadata for the system\n",
        "            for key in ['loc_latitude', 'loc_longitude', 'loc_altitude', 'pv_kwp']:\n",
        "                # test that the key is present\n",
        "                if key not in systemsMetadata[systemName]['metadata']:\n",
        "                    missingData = True\n",
        "                    print(f\"System {systemName} : No '{key}' found\")\n",
        "                # if present, convert the value to a number, if possible\n",
        "                elif not isinstance(systemsMetadata[systemName]['metadata'][key], (int, float)):\n",
        "                    try:\n",
        "                        systemsMetadata[systemName]['metadata'][key] = int(systemsMetadata[systemName]['metadata'][key])\n",
        "                    except ValueError:\n",
        "                        try:\n",
        "                            systemsMetadata[systemName]['metadata'][key] = float(systemsMetadata[systemName]['metadata'][key])\n",
        "                        except ValueError:\n",
        "                            missingData = True\n",
        "                            print(f\"System {systemName} : The key-value '{key}:{systemsMetadata[systemName]['metadata'][key]}' is not a number\")\n",
        "\n",
        "            # Check metadata for the arrays\n",
        "            if 'arrays' not in systemsMetadata[systemName] or len(systemsMetadata[systemName]['arrays']) == 0:\n",
        "                print(f\"System {systemName} : No PV arrays found\")\n",
        "                missingData = True\n",
        "            else:\n",
        "                for array_num, arrayData in systemsMetadata[systemName]['arrays'].items():\n",
        "                    for key in ['pv_tilt', 'pv_azimut', 'pv_wp', 'pv_number']:\n",
        "                        if key not in arrayData:\n",
        "                            missingData = True\n",
        "                            print(f\"System {systemName} : No '{key}' found for array {array_num}\")\n",
        "                        # test that the value is a number\n",
        "                        elif not isinstance(arrayData[key], (int, float)):\n",
        "                            try:\n",
        "                                arrayData[key] = int(arrayData[key])\n",
        "                            except ValueError:\n",
        "                                try:\n",
        "                                    arrayData[key] = float(arrayData[key])\n",
        "                                except ValueError:\n",
        "                                    missingData = True\n",
        "                                    print(f\"System {systemName} : The key-value '{key}:{arrayData[key]}' is not a number for array {array_num}\")\n",
        "\n",
        "            # add the loss metadata if not present\n",
        "            if 'loss' not in systemsMetadata[systemName]['metadata']:\n",
        "                systemsMetadata[systemName]['metadata']['loss'] = 0\n",
        "\n",
        "        if missingData:\n",
        "            systemsName_Valid.remove(systemName)\n",
        "            print(f\"-> Removing system {systemName} from the list of systems\")\n",
        "\n",
        "    print(f\"\\nNumber of systems with all the necessary data: {len(systemsName_Valid)}/{len(systemsName)}\")\n",
        "\n",
        "    # # Filter out systems with less than X days of data\n",
        "    # for systemName in systemsName_Valid[:]:  # Create a copy of the list using slicing [:] to avoid removing elements while iterating over the list itself\n",
        "    #     if len(systemsData[systemName]) < minMeasurements:\n",
        "    #         systemsName_Valid.remove(systemName)\n",
        "    #         print(f\"-> Removing system {systemName} from the list of systems because it has less than {minMeasurements} days of data\")\n",
        "\n",
        "    # print(f\"Number of systems with at least {minMeasurements} days of data: {len(systemsName_Valid)}/{len(systemsName)}\")\n",
        "\n",
        "    ## ---------------------------------------------------------------------------- ##\n",
        "    ## Create one 2D DataFrame with the daily production of every remaining systems ##\n",
        "    ## ---------------------------------------------------------------------------- ##\n",
        "\n",
        "    # Create an empty list to store all measured data for each systems\n",
        "    systemsData_MeasuredDailyEnergy_List = []\n",
        "\n",
        "    # Iterate over each key-value pair in the systemsData dictionary\n",
        "    for systemName in systemsName_Valid:\n",
        "        # Extract the 'tt_forward_active_energy_total_toDay' column from the current dataframe\n",
        "        measuredDailyEnergy = systemsData[systemName]['tt_forward_active_energy_total_toDay']\n",
        "\n",
        "        # Rename the column with the system name\n",
        "        measuredDailyEnergy.rename(systemName, inplace=True)\n",
        "\n",
        "        systemsData_MeasuredDailyEnergy_List.append(measuredDailyEnergy)\n",
        "        # Concatenate the column to the new_dataframe\n",
        "\n",
        "    # Concatenate all the columns in the list to create one dataframe\n",
        "    systemsData_MeasuredDailyEnergy = pd.concat(systemsData_MeasuredDailyEnergy_List, axis=1)\n",
        "    systemsData_MeasuredDailyEnergy.index = pd.to_datetime(systemsData_MeasuredDailyEnergy.index)\n",
        "    systemsData_MeasuredDailyEnergy.sort_index(inplace=True)\n",
        "\n",
        "    ## ------------------ ##\n",
        "    ## Save the dataframe ##\n",
        "    ## ------------------ ##\n",
        "    # Save the dataframe for later use\n",
        "    # create cache directory if it does not exist\n",
        "\n",
        "    systemsData_MeasuredDailyEnergy.to_pickle(cacheFilename_systemsData_MeasuredDailyEnergy)\n",
        "\n",
        "# Print the dataframe\n",
        "systemsData_MeasuredDailyEnergy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create train & test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a validation set with the last 100 days\n",
        "# if testingDays == 0:\n",
        "#     systemsData_MeasuredDailyEnergy_train = systemsData_MeasuredDailyEnergy\n",
        "#     systemsData_MeasuredDailyEnergy_test = pd.DataFrame()\n",
        "# else:\n",
        "if testingDays > len(systemsData_MeasuredDailyEnergy):\n",
        "    raise ValueError(f\"testingDays ({testingDays}) is greater than the number of days in the dataset ({len(systemsData_MeasuredDailyEnergy)})\")\n",
        "systemsData_MeasuredDailyEnergy_train, systemsData_MeasuredDailyEnergy_test = train_test_split(systemsData_MeasuredDailyEnergy, test_size=testingDays, random_state=42, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove systems with not enough days that are not null for training or testing\n",
        "nbr_valid_systems = len(systemsName_Valid)\n",
        "under_min_training_days_systems = systemsData_MeasuredDailyEnergy_train.loc[:, systemsData_MeasuredDailyEnergy_train.notnull().sum() < minTrainingDays].columns\n",
        "for systemName in under_min_training_days_systems:\n",
        "    remove_system(systemName, f\"System {systemName} : Not enough days for training (min {minTrainingDays} days required)\")\n",
        "\n",
        "under_min_testing_days_systems = systemsData_MeasuredDailyEnergy_test.loc[:, systemsData_MeasuredDailyEnergy_test.notnull().sum() < minTestingDays].columns\n",
        "for systemName in under_min_testing_days_systems:\n",
        "    remove_system(systemName, f\"System {systemName} : Not enough days for testing (min {minTestingDays} days required)\")\n",
        "\n",
        "print(f\"Number of valid systems: {len(systemsName_Valid)}/{nbr_valid_systems}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Max production estimator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the power production with a given frequency to the total daily energy\n",
        "def daily_energy(df_power):\n",
        "    # Get the frequency in minutes\n",
        "    freq_in_minutes = pd.Timedelta(df_power.index.freq).seconds / 60\n",
        "    # Convert power from kW to kWh\n",
        "    df_energy = df_power * (freq_in_minutes / 60)\n",
        "    # Resample to daily frequency and sum the values\n",
        "    daily_energy = df_energy.resample('D').sum()\n",
        "    # daily_energy.index = daily_energy.index.date\n",
        "\n",
        "    return daily_energy\n",
        "\n",
        "# Simulate the daily production of a system from a start date to an end date using the given PVLib ModelChain\n",
        "\n",
        "\n",
        "def generate_max_production_estimate(startDate, endDate, estimator: ModelChain, samplingFreq='1h'):\n",
        "    # The end date needs to be estimated completly(end date at 23:59). But \"endDate\" is considered as 00:00 by pd.date_range().\n",
        "    # So we add 1 day to the end date to include the entire end date in the date_range(), and then we exclude the last value with the inclusive='left' proprety, to remove \"endDate+1\" at 00:00) in the date_range().\n",
        "    endDate = endDate + pd.Timedelta(days=1)\n",
        "\n",
        "    times = pd.date_range(start=startDate, end=endDate, freq=samplingFreq, tz=estimator.location.tz, inclusive='left')\n",
        "    weatherClearSky = estimator.location.get_clearsky(times)  # In W/m2\n",
        "    # TODO adjust the clear sky model to take into account the horizon https://pvlib-python.readthedocs.io/en/stable/gallery/shading/plot_simple_irradiance_adjustment_for_horizon_shading.html\n",
        "    estimator.run_model(weatherClearSky)\n",
        "    production = estimator.results.ac / 1000  # Convert W to kW\n",
        "    dailyProduction = daily_energy(production)\n",
        "    dailyProduction.index = pd.to_datetime(dailyProduction.index.date)\n",
        "    return dailyProduction\n",
        "\n",
        "\n",
        "def generate_max_production_estimator(systemMetadata):\n",
        "    latitude = systemMetadata['metadata']['loc_latitude']\n",
        "    longitude = systemMetadata['metadata']['loc_longitude']\n",
        "    altitude = systemMetadata['metadata']['loc_altitude']\n",
        "    Wp_Tot = systemMetadata['metadata']['pv_kwp'] * 1000\n",
        "    loss = systemMetadata['metadata']['loss'] * 100\n",
        "\n",
        "    arrays = []\n",
        "    for array_num, arrayData in systemMetadata['arrays'].items():\n",
        "        array = Array(\n",
        "            mount=FixedMount(surface_tilt=arrayData['pv_tilt'], surface_azimuth=arrayData['pv_azimut'], racking_model='open_rack'),\n",
        "            module_parameters={'pdc0': arrayData['pv_wp'], 'gamma_pdc': -0.004},\n",
        "            module_type='glass_polymer',\n",
        "            modules_per_string=arrayData['pv_number'],\n",
        "            strings=1,\n",
        "            temperature_model_parameters=TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_polymer'],\n",
        "        )\n",
        "        arrays.append(array)\n",
        "\n",
        "    location = Location(latitude=latitude, longitude=longitude, altitude=altitude, tz='Europe/Zurich')\n",
        "    system = PVSystem(arrays=arrays,\n",
        "                      inverter_parameters={'pdc0': Wp_Tot, 'eta_inv_nom': 0.96},\n",
        "                      losses_parameters={'nameplate_rating': loss, 'soiling': 0, 'shading': 0, 'snow': 0, 'mismatch': 0, 'wiring': 0, 'connections': 0, 'lid': 0, 'age': 0, 'availability': 0})\n",
        "    modelChain = ModelChain(system, location, clearsky_model='ineichen', aoi_model='no_loss', spectral_model=\"no_loss\", losses_model='pvwatts')\n",
        "\n",
        "    return modelChain\n",
        "\n",
        "\n",
        "def tune_max_production_estimator(measured_series, max_estimated_series, window=7):\n",
        "    # Remove the obvious outliers. It's important before calculating the std, which can be strongly impacted by the strong outliers.\n",
        "    outliers_mask = measured_series > 2 * max_estimated_series\n",
        "    measured_no_outliers_series = measured_series[~outliers_mask]\n",
        "    # if 10% of the data is removed as outliers, we consider that the system is not valid\n",
        "    if outliers_mask.sum().sum() / outliers_mask.size > 0.1:\n",
        "        return None, None, None, None\n",
        "    # Keep only the max measured value\n",
        "    max_measured_series = pd.Series(index=measured_series.index, dtype=float)\n",
        "    # Iterate over windows of a given size, and keep only the maximum value in each window\n",
        "    for i in range(0, len(measured_series), window):\n",
        "        window_data = measured_no_outliers_series.iloc[i:i + window]\n",
        "        if not window_data.empty and not window_data.isna().all():\n",
        "            max_value = window_data.max()\n",
        "            max_index = window_data.idxmax(skipna=True)\n",
        "            max_measured_series[max_index] = max_value\n",
        "\n",
        "    # Calculate the relative difference between the maximum measured and maximum estimated value\n",
        "    realtive_difference = max_measured_series / max_estimated_series\n",
        "\n",
        "    # Compute statistics\n",
        "    std = realtive_difference.std()\n",
        "    mean = realtive_difference.mean()\n",
        "\n",
        "    # Remove the outilers that have a z-score greater than 1\n",
        "    z_scores = np.abs(realtive_difference - mean) / std\n",
        "\n",
        "    # Add the measure with a z-score greater than 1 to the previous outliers (AND operation)\n",
        "    outliers_mask = outliers_mask | (z_scores > 1)\n",
        "\n",
        "    # Get the loss that overestimate the estimate maximum daily energy\n",
        "    loss = 1 - realtive_difference[~outliers_mask].max()\n",
        "\n",
        "    return loss, std, max_measured_series, outliers_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create estimator\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "\n",
        "systemsData_EstimatedMaxDailyEnergy_dic = {}\n",
        "unfitted_systems = []\n",
        "for systemName in tqdm(systemsName_Valid):\n",
        "\n",
        "    systemsMetadata[systemName]['metadata']['loss'] = 0\n",
        "\n",
        "    estimator = generate_max_production_estimator(systemsMetadata[systemName])\n",
        "\n",
        "    ## ------------------- ##\n",
        "    ## Simulate production ##\n",
        "    ## ------------------- ##\n",
        "    measured_series = systemsData_MeasuredDailyEnergy[systemName]\n",
        "    startDate = measured_series[~measured_series.isna()].index.min()\n",
        "    endDate = measured_series[~measured_series.isna()].index.max()\n",
        "    estimatedMaxDailyEnergy = generate_max_production_estimate(startDate, endDate, estimator, samplingFreq='1h')\n",
        "\n",
        "        # fill remaining days with NaN\n",
        "    estimatedMaxDailyEnergy = estimatedMaxDailyEnergy.reindex(measured_series.index, fill_value=np.nan)\n",
        "\n",
        "        # add the series to the dictionary\n",
        "    systemsData_EstimatedMaxDailyEnergy_dic[systemName] = estimatedMaxDailyEnergy\n",
        "\n",
        "    # loss, std = tune_max_production_estimator(measured_series, estimatedMaxDailyEnergy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Concatenate all the columns in the list to create one dataframe\n",
        "systemsData_EstimatedMaxDailyEnergy = pd.concat(systemsData_EstimatedMaxDailyEnergy_dic, axis=1)\n",
        "systemsData_EstimatedMaxDailyEnergy.index = pd.to_datetime(systemsData_EstimatedMaxDailyEnergy.index)\n",
        "systemsData_EstimatedMaxDailyEnergy.sort_index(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cacheFilename_normalizer_estimated_max_daily_energy = os.path.join(dataCacheDirpath, 'normalizer_estimated_max_daily_energy.pkl')\n",
        "cacheFilename_normalizer_tuning_estimated_max_daily_energy_untuned = os.path.join(dataCacheDirpath, 'normalizer_tuning_estimated_max_daily_energy_untuned.pkl')\n",
        "cacheFilename_normalizer_tuning_measure_max = os.path.join(dataCacheDirpath, 'normalizer_tuning_measure_max.pkl')\n",
        "cacheFilename_normalizer_tuning_outliers = os.path.join(dataCacheDirpath, 'normalizer_tuning_outliers.pkl')\n",
        "cacheFilename_normalizer_tuning_unfitted_systems = os.path.join(dataCacheDirpath, 'normalizer_tuning_unfitted_systems.pkl')\n",
        "\n",
        "if useCached and os.path.exists(cacheFilename_normalizer_estimated_max_daily_energy) and os.path.exists(cacheFilename_normalizer_tuning_estimated_max_daily_energy_untuned) and os.path.exists(cacheFilename_normalizer_tuning_measure_max) and os.path.exists(cacheFilename_normalizer_tuning_outliers):\n",
        "    # TODO how to deal if the cached data is not up to date and some systems have been added or removed?\n",
        "    print(f\"Loading cached data in {cacheFilename_normalizer_estimated_max_daily_energy}\")\n",
        "    normalizer_estimated_max_daily_energy = pd.read_pickle(cacheFilename_normalizer_estimated_max_daily_energy)\n",
        "    normalizer_tuning_estimated_max_daily_energy_untuned = pd.read_pickle(cacheFilename_normalizer_tuning_estimated_max_daily_energy_untuned)\n",
        "    normalizer_tuning_measure_max = pd.read_pickle(cacheFilename_normalizer_tuning_measure_max)\n",
        "    normalizer_tuning_outliers = pd.read_pickle(cacheFilename_normalizer_tuning_outliers)\n",
        "    normalizer_tuning_unfitted_systems = pd.read_pickle(cacheFilename_normalizer_tuning_unfitted_systems)\n",
        "\n",
        "else:\n",
        "    normalizer_estimated_max_daily_energy_dic = {}\n",
        "    normalizer_tuning_estimated_max_daily_energy_untuned_dic = {}\n",
        "    normalizer_tuning_measure_max_dic = {}\n",
        "    normalizer_tuning_outliers_dic = {}\n",
        "    normalizer_tuning_unfitted_systems_list = []\n",
        "\n",
        "    iteration_times_normalizer = []\n",
        "    for systemName in tqdm(systemsName_Valid):\n",
        "        start_time = time.time()  # Start timing\n",
        "        \n",
        "        tuned = not tuneMaxProductionEstimators  # If we don't want to tune the estimators, we say that the estimator is already tuned\n",
        "        # reset the loss in the metadata if we want to tune the estimators\n",
        "        if tuneMaxProductionEstimators:\n",
        "            systemsMetadata[systemName]['metadata']['loss'] = 0\n",
        "\n",
        "        while True:  # emulate do while loop\n",
        "\n",
        "            ## ------------------ ##\n",
        "            ## Create ModelChains ##\n",
        "            ## ------------------ ##\n",
        "            estimator = generate_max_production_estimator(systemsMetadata[systemName])\n",
        "\n",
        "            ## ------------------- ##\n",
        "            ## Simulate production ##\n",
        "            ## ------------------- ##\n",
        "            measured_series = systemsData_MeasuredDailyEnergy[systemName]\n",
        "            startDate = measured_series[~measured_series.isna()].index.min()\n",
        "            endDate = measured_series[~measured_series.isna()].index.max()\n",
        "            estimatedMaxDailyEnergy = generate_max_production_estimate(startDate, endDate, estimator, samplingFreq='1h')\n",
        "\n",
        "            # fill remaining days with NaN\n",
        "            estimatedMaxDailyEnergy = estimatedMaxDailyEnergy.reindex(measured_series.index, fill_value=np.nan)\n",
        "\n",
        "            # add the series to the dictionary\n",
        "            normalizer_estimated_max_daily_energy_dic[systemName] = estimatedMaxDailyEnergy\n",
        "\n",
        "            ## --------------- ##\n",
        "            ## Tune estimators ##\n",
        "            ## --------------- ##\n",
        "            if tuned:\n",
        "                break\n",
        "\n",
        "            loss, std, measuredMax, outliersMask = tune_max_production_estimator(measured_series, estimatedMaxDailyEnergy)\n",
        "\n",
        "            if loss is None:\n",
        "                normalizer_tuning_unfitted_systems_list.append(systemName)\n",
        "                break\n",
        "\n",
        "            normalizer_tuning_estimated_max_daily_energy_untuned_dic[systemName] = estimatedMaxDailyEnergy\n",
        "            normalizer_tuning_measure_max_dic[systemName] = measuredMax\n",
        "            normalizer_tuning_outliers_dic[systemName] = measured_series[outliersMask]\n",
        "\n",
        "            # If the std is greater than 1, we remove the system from the list of systems to be processed.\n",
        "            # This is to avoid to have a system that is not well fitted by the maximum energy estimator model, and that could impact the training of the RF model.\n",
        "            if std is None or std > 1 or measured_series.count() == 0:\n",
        "                normalizer_tuning_unfitted_systems_list.append(systemName)\n",
        "                break\n",
        "\n",
        "            # write the loss in systemsMetadata\n",
        "            systemsMetadata[systemName]['metadata']['loss'] = loss\n",
        "\n",
        "            tuned = True\n",
        "\n",
        "            iteration_duration = time.time() - start_time\n",
        "            iteration_times_normalizer.append(iteration_duration)\n",
        "\n",
        "\n",
        "    normalizer_estimated_max_daily_energy = pd.concat(normalizer_estimated_max_daily_energy_dic, axis=1)\n",
        "    normalizer_estimated_max_daily_energy.index = pd.to_datetime(normalizer_estimated_max_daily_energy.index)\n",
        "    normalizer_estimated_max_daily_energy.sort_index(inplace=True)\n",
        "\n",
        "    normalizer_tuning_estimated_max_daily_energy_untuned = pd.concat(normalizer_tuning_estimated_max_daily_energy_untuned_dic, axis=1)\n",
        "    normalizer_tuning_estimated_max_daily_energy_untuned.index = pd.to_datetime(normalizer_tuning_estimated_max_daily_energy_untuned.index)\n",
        "    normalizer_tuning_estimated_max_daily_energy_untuned.sort_index(inplace=True)\n",
        "\n",
        "    normalizer_tuning_measure_max = pd.concat(normalizer_tuning_measure_max_dic, axis=1)\n",
        "    normalizer_tuning_measure_max.index = pd.to_datetime(normalizer_tuning_measure_max.index)\n",
        "    normalizer_tuning_measure_max.sort_index(inplace=True)\n",
        "\n",
        "    normalizer_tuning_outliers = pd.concat(normalizer_tuning_outliers_dic, axis=1)\n",
        "    normalizer_tuning_outliers.index = pd.to_datetime(normalizer_tuning_outliers.index)\n",
        "    normalizer_tuning_outliers.sort_index(inplace=True)\n",
        "\n",
        "    normalizer_tuning_unfitted_systems = pd.Series(normalizer_tuning_unfitted_systems_list)\n",
        "\n",
        "    # Save metadata with tuned parameters\n",
        "    if tuneMaxProductionEstimators:\n",
        "        with open(metadataFilepath, 'w') as f:\n",
        "            json.dump(systemsMetadata, f, indent=4)\n",
        "\n",
        "    # save systemsData_EstimatedMaxDailyEnergy in cacheFilename_systemsData_EstimatedMaxDailyEnergy\n",
        "    normalizer_estimated_max_daily_energy.to_pickle(cacheFilename_normalizer_estimated_max_daily_energy)\n",
        "    normalizer_tuning_estimated_max_daily_energy_untuned.to_pickle(cacheFilename_normalizer_tuning_estimated_max_daily_energy_untuned)\n",
        "    normalizer_tuning_measure_max.to_pickle(cacheFilename_normalizer_tuning_measure_max)\n",
        "    normalizer_tuning_outliers.to_pickle(cacheFilename_normalizer_tuning_outliers)\n",
        "    normalizer_tuning_unfitted_systems.to_pickle(cacheFilename_normalizer_tuning_unfitted_systems)\n",
        "\n",
        "# Remove unfitted systems from systemsName_Valid, systemsName_Valid, systemsData_EstimatedMaxDailyEnergy, systemsData_MeasuredDailyEnergy\n",
        "nbr_valid_systems = len(systemsName_Valid)\n",
        "for systemName in normalizer_tuning_unfitted_systems:\n",
        "    remove_system(systemName, f\"System {systemName} : We can't find the model corresponding to the measured data. This system is removed from the list of systems to be processed.\")\n",
        "print(f\"Number of valid systems: {len(systemsName_Valid)}/{nbr_valid_systems}\")\n",
        "# Print the dataframe\n",
        "normalizer_estimated_max_daily_energy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remove outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rel_mesasured_series = systemsData_MeasuredDailyEnergy_train / normalizer_estimated_max_daily_energy\n",
        "\n",
        "# remove the outliers in measured data that are greater than 1.1 times (+10%) the maximum estimated value, or less than 1% of the maximum estimated value\n",
        "inliers = (rel_mesasured_series < 1.1) & (rel_mesasured_series > 0.01)\n",
        "systemsData_MeasuredDailyEnergy_train_outliers = systemsData_MeasuredDailyEnergy_train[~inliers]\n",
        "systemsData_MeasuredDailyEnergy_train = systemsData_MeasuredDailyEnergy_train[inliers]\n",
        "\n",
        "# remove the systems that have less than 7 days\n",
        "nbr_valid_systems = len(systemsName_Valid)\n",
        "for systemName in systemsData_MeasuredDailyEnergy_train.loc[:, systemsData_MeasuredDailyEnergy_train.count() < minTrainingDays].columns:\n",
        "    remove_system(systemName, f\"System {systemName} : The system has less than {minTrainingDays} days of data. This system is removed from the list of systems to be processed.\")\n",
        "print(f\"Number of valid systems: {len(systemsName_Valid)}/{nbr_valid_systems}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Relative production\n",
        "\n",
        "True production scaled by the maximum production from the simulator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the relative energy for each system\n",
        "systemsData_RelativeMeasuredDailyEnergy_train = systemsData_MeasuredDailyEnergy_train / normalizer_estimated_max_daily_energy\n",
        "systemsData_RelativeMeasuredDailyEnergy = systemsData_MeasuredDailyEnergy / normalizer_estimated_max_daily_energy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare the difference between simulation with hourly and 10min sampling rate\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Simulate the daily production for each system with 1h and 10min sampling rate\n",
        "dailyProductions = {}\n",
        "\n",
        "for systemName, modelChain in modelChains.items():\n",
        "    try:\n",
        "        dailyProduction_hour = simulateDailyProduction(systemName, systemsData, modelChains, samplingFreq='1h')\n",
        "        dailyProduction_min = simulateDailyProduction(systemName, systemsData, modelChains, samplingFreq='10min')\n",
        "        dailyProductions[systemName] = pd.DataFrame({'Simulator hour': dailyProduction_hour, 'Simulator 10min': dailyProduction_min})\n",
        "    except Exception as e:\n",
        "        print(f\"Error for system {systemName}: {e}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "# Compute the descriptive statistics of the difference between the 1h and 10min simulations on all systems\n",
        "allSimulations = pd.concat(dailyProductions.values())\n",
        "\n",
        "allSimulations['Difference'] = allSimulations['Simulator hour'] - allSimulations['Simulator 10min']\n",
        "allSimulations['Percentage'] = allSimulations['Difference'] / allSimulations['Simulator 10min'] * 100\n",
        "\n",
        "descriptiveStat = allSimulations[['Difference', 'Percentage']].describe()\n",
        "print(descriptiveStat)\n",
        "\n",
        "\n",
        "# Plot the histogram of the percentage of the difference\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Histogram(x=allSimulations['Percentage'], nbinsx=1000))\n",
        "fig.add_vline(x=descriptiveStat.loc['mean','Percentage'], line_color='red', line_width=2, annotation_text='mean')\n",
        "fig.add_vline(x=descriptiveStat.loc['25%','Percentage'], line_color='green', line_width=2, annotation_text='25%')\n",
        "fig.add_vline(x=descriptiveStat.loc['75%','Percentage'], line_color='green', line_width=2, annotation_text='75%')\n",
        "fig.update_xaxes(dtick=0.1)\n",
        "fig.update_xaxes(range=[-1, 1])\n",
        "fig.update_layout(width=1000, height=666)\n",
        "fig.update_layout(xaxis_title='Percentage of the difference (%)')\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# Plot the daily production of a system with 1h and 10min sampling rate\n",
        "systemName = 'a001096'\n",
        "dailyProduction_hour = simulateDailyProduction(systemName, systemsData, modelChains, samplingFreq='1h')\n",
        "dailyProduction_min = simulateDailyProduction(systemName, systemsData, modelChains, samplingFreq='10min')\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=dailyProduction_min.index, y=dailyProduction_min, mode='markers', name='10min sampling rate'))\n",
        "fig.add_trace(go.Scatter(x=dailyProduction_hour.index, y=dailyProduction_hour, mode='markers', name='Hourly sampling rate'))\n",
        "\n",
        "fig.update_layout(title=f'Simulated daily max AC energy of system {systemName}', xaxis_title='Time', yaxis_title='Energy (kWh)')\n",
        "fig.update_layout(width=1000, height=666)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "test"
        ]
      },
      "source": [
        "## Correlation between Systems\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "correlation_matrix = systemsData_MeasuredDailyEnergy.corr(method='pearson', min_periods=minTrainingDays)\n",
        "# set all negative value (therefore when the value of one system increasse, the other systme decrease) to 0\n",
        "correlation_matrix[correlation_matrix < 0] = 0"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Plot correlation matrix\n",
        "\n",
        "# Set the size of the figure\n",
        "plt.figure(figsize=(100, 80))\n",
        "\n",
        "# Creating the heatmap without modifying the default behavior of axis labels\n",
        "sns.heatmap(correlation_matrix, cmap='coolwarm', xticklabels=True, yticklabels=True)\n",
        "\n",
        "# Rotating the tick labels for readability\n",
        "plt.xticks(rotation=90,)\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot linear regression between 2 systems\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.linear_model import RANSACRegressor, LinearRegression\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Remove observation where a001266 and a001036 dataframes have NA value\n",
        "system1 = 'a001236'\n",
        "system2 = 'a001097'\n",
        "\n",
        "df = pd.concat([systemsData_RelativeMeasuredDailyEnergy_train[system1], systemsData_RelativeMeasuredDailyEnergy_train[system2]], axis=1).dropna()\n",
        "\n",
        "x_values = np.linspace(df[system1].min(), df[system1].max(), 100)\n",
        "\n",
        "# Fit line using RANSAC\n",
        "ransac = RANSACRegressor(LinearRegression(), min_samples=20, residual_threshold=None, random_state=42)\n",
        "ransac.fit(df[[system1]], df[system2] )\n",
        "y_values_ransac = ransac.predict(x_values.reshape(-1, 1))\n",
        "\n",
        "# Plot the data\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df[system1], y=df[system2], mode='markers', name='Data'))\n",
        "fig.add_trace(go.Scatter(x=x_values, y=y_values_ransac, mode='lines', name='RANSAC Regression'))\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Half-Sibling Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_system_data(targetName, set='train', relative=True, max_neighbors=None, max_days=None):\n",
        "    # take the max_neighbors best neighbours from the correlation matrix\n",
        "    # if none, take all the neighbours\n",
        "    if max_neighbors == None or max_neighbors > len(systemsName_Valid) - 1:\n",
        "        max_neighbors = len(systemsName_Valid) - 1\n",
        "    best_neighbours = correlation_matrix.loc[targetName, systemsName_Valid].sort_values(ascending=False).index[1:max_neighbors + 1]\n",
        "    # Create the feature matrix X and the target vector y\n",
        "    if set == 'train' and relative:\n",
        "        X = systemsData_RelativeMeasuredDailyEnergy_train[best_neighbours]\n",
        "        y = systemsData_RelativeMeasuredDailyEnergy_train[targetName]\n",
        "    elif set == 'train' and not relative:\n",
        "        X = systemsData_MeasuredDailyEnergy_train[best_neighbours]\n",
        "        y = systemsData_MeasuredDailyEnergy_train[targetName]\n",
        "    elif set == 'test' and relative:\n",
        "        X = systemsData_RelativeMeasuredDailyEnergy_test[best_neighbours]\n",
        "        y = systemsData_RelativeMeasuredDailyEnergy_test[targetName]\n",
        "    elif set == 'test' and not relative:\n",
        "        X = systemsData_MeasuredDailyEnergy_test[best_neighbours]\n",
        "        y = systemsData_MeasuredDailyEnergy_test[targetName]\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid set value: {set}\")\n",
        "    # remove the observations where their is no target value\n",
        "    X = X[~y.isna()]\n",
        "    y = y[~y.isna()]\n",
        "\n",
        "    if max_days and max_days > 0 and max_days < len(y) :\n",
        "        X = X.iloc[-max_days:]\n",
        "        y = y.iloc[-max_days:]\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def mean_absolute_percentage_error_mean_denominator(\n",
        "        y_true, y_pred, *, sample_weight=None, multioutput=\"uniform_average\"):\n",
        "    # Copy of the function mean_absolute_percentage_error from sklearn.metrics._regression, with the denominator of the MAPE changed to the mean of the true values\n",
        "    import sklearn\n",
        "    y_type, y_true, y_pred, multioutput = sklearn.metrics._regression._check_reg_targets(\n",
        "        y_true, y_pred, multioutput)\n",
        "    sklearn.utils.validation.check_consistent_length(y_true, y_pred, sample_weight)\n",
        "    epsilon = np.finfo(np.float64).eps\n",
        "    mape = np.abs(y_pred - y_true) / np.maximum(np.mean(np.abs(y_true)), epsilon)\n",
        "    output_errors = np.average(mape, weights=sample_weight, axis=0)\n",
        "    if isinstance(multioutput, str):\n",
        "        if multioutput == \"raw_values\":\n",
        "            return output_errors\n",
        "        elif multioutput == \"uniform_average\":\n",
        "            # pass None as weights to np.average: uniform mean\n",
        "            multioutput = None\n",
        "    return np.average(output_errors, weights=multioutput)\n",
        "\n",
        "\n",
        "def mean_absolute_percentage_error_epsilon(y_true, y_pred, epsilon=np.finfo(np.float64).eps, *, sample_weight=None, multioutput=\"uniform_average\"):\n",
        "    # Copy of the function mean_absolute_percentage_error from sklearn.metrics._regression, with epsilon as a parameter\n",
        "    import sklearn\n",
        "    y_type, y_true, y_pred, multioutput = sklearn.metrics._regression._check_reg_targets(\n",
        "        y_true, y_pred, multioutput)\n",
        "    sklearn.utils.validation.check_consistent_length(y_true, y_pred, sample_weight)\n",
        "    mape = np.abs(y_pred - y_true) / np.maximum(np.abs(y_true), epsilon)\n",
        "    output_errors = np.average(mape, weights=sample_weight, axis=0)\n",
        "    if isinstance(multioutput, str):\n",
        "        if multioutput == \"raw_values\":\n",
        "            return output_errors\n",
        "        elif multioutput == \"uniform_average\":\n",
        "            # pass None as weights to np.average: uniform mean\n",
        "            multioutput = None\n",
        "    return np.average(output_errors, weights=multioutput)\n",
        "\n",
        "\n",
        "def mad(arr):\n",
        "    return abs(arr - arr.median()).median()\n",
        "\n",
        "\n",
        "def modified_z_score(arr):\n",
        "    # based on https://www.ibm.com/docs/en/cognos-analytics/11.1.0?topic=terms-modified-z-score\n",
        "    mad_value = mad(arr)\n",
        "    if mad_value == 0:\n",
        "        MeanAD = np.mean(np.abs(arr - np.mean(arr)))\n",
        "        denominator = 1.253314 * MeanAD\n",
        "    else:\n",
        "        denominator = 1.486 * mad_value\n",
        "    return (arr - np.median(arr)) / denominator\n",
        "\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "    return {'MAPE': mean_absolute_percentage_error(y_true, y_pred), 'MAPE-MD': mean_absolute_percentage_error_mean_denominator(y_true, y_pred), 'MAE': mean_absolute_error(y_true, y_pred), 'RMSE': root_mean_squared_error(y_true, y_pred), 'R2': r2_score(y_true, y_pred)}\n",
        "\n",
        "\n",
        "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
        "mape_eps_scorer = make_scorer(mean_absolute_percentage_error_epsilon, greater_is_better=False)\n",
        "# Return the metrics for a RFR model trained on the given data.\n",
        "# The entire dataset is used for training, and the OOB prediction is used to compute the metrics.\n",
        "\n",
        "\n",
        "def oob_metrics(X, y, metricFct, rf_parames={}):\n",
        "    model = RandomForestRegressor(oob_score=True, **rf_parames)\n",
        "    y_pred = model.fit(X, y).oob_prediction_\n",
        "    return metricFct(y, y_pred)\n",
        "# Return the metrics for a RFR model trained on the given data.\n",
        "# KFold cross-validation is used train the model and to compute the metrics.\n",
        "\n",
        "\n",
        "def kfold_metrics(X, y, metricFct, rf_parames={}, n_folds=5):\n",
        "    model = RandomForestRegressor(**rf_parames)\n",
        "    metrics_list = []\n",
        "    for train_index, test_index in KFold(n_splits=n_folds).split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        y_pred = model.fit(X_train, y_train).predict(X_test)\n",
        "        metrics_list.append(metricFct(y_test, y_pred))\n",
        "    if isinstance(metrics_list[0], dict):\n",
        "        # Convert list of dictionaries to a DataFrame\n",
        "        metrics_df = pd.DataFrame(metrics_list)\n",
        "        # Compute mean for each column\n",
        "        aggregated_metrics = metrics_df.mean().to_dict()\n",
        "        return aggregated_metrics\n",
        "    else:\n",
        "        # Compute mean of the list for numerical metrics\n",
        "        return np.mean(metrics_list)\n",
        "\n",
        "\n",
        "def _accumulate_prediction(predict, X, out, lock):\n",
        "    \"\"\"    This is a utility function for joblib's Parallel.    It can't go locally in ForestClassifier or ForestRegressor, because joblib    complains that it cannot pickle it when placed there.    \"\"\"\n",
        "    prediction = predict(X, check_input=False)\n",
        "    with lock:\n",
        "        out.append(prediction)\n",
        "\n",
        "\n",
        "def predict_w_std(self, X):\n",
        "    \"\"\"    Predict regression target and standard deviation for X.    The predicted regression target of an input sample is computed as the    mean predicted regression targets of the trees in the forest. The standard    deviation of the predicted regression targets of the trees in the forest    is also computed to provide an estimate of the prediction uncertainty.    Parameters    ----------    X : {array-like, sparse matrix} of shape (n_samples, n_features)        The input samples. Internally, its dtype will be converted to        ``dtype=np.float32``. If a sparse matrix is provided, it will be        converted into a sparse ``csr_matrix``.    Returns    -------    mean_predictions : ndarray of shape (n_samples,)        The predicted values (mean of the predictions from all estimators).    std_predictions : ndarray of shape (n_samples,)        The standard deviation of the predicted values (standard deviation of the        predictions from all estimators).    Raises    ------    NotImplementedError        If the model was trained for multi-output regression.    Notes    -----    This function does not support multi-output regression. If the model was    trained for multi-output regression, an exception will be raised.    \"\"\"\n",
        "    if self.n_outputs_ > 1:\n",
        "        raise NotImplementedError(\"Variance for multi-output regression is not supported now\")\n",
        "    check_is_fitted(self)\n",
        "    # Check data\n",
        "    X = self._validate_X_predict(X)\n",
        "    # Assign chunk of trees to jobs\n",
        "    n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n",
        "    # avoid storing the output of every estimator by summing them here\n",
        "    # Initialize a list to collect predictions from each estimator\n",
        "    all_predictions = []\n",
        "    # Parallel loop\n",
        "    lock = threading.Lock()\n",
        "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(delayed(_accumulate_prediction)(e.predict, X, all_predictions, lock)\n",
        "                                                                       for e in self.estimators_)\n",
        "    # Convert list to numpy array for easier manipulation\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    # Compute mean and variance across predictions from all estimators\n",
        "    mean_predictions = np.mean(all_predictions, axis=0)\n",
        "    std_predictions = np.std(all_predictions, axis=0)\n",
        "    return mean_predictions, std_predictions\n",
        "\n",
        "\n",
        "RandomForestRegressor.predict_w_std = predict_w_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameters tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parameters\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Number of trees in random forest. from 1 to 200, with 20 steps\n",
        "n_estimators = [50]\n",
        "# n_estimators = np.unique(np.append(\n",
        "#     [int(x) for x in np.linspace(start=1, stop=400, num=5)],\n",
        "#     [int(x) for x in np.linspace(start=1, stop=100, num=10)]\n",
        "# ))\n",
        "# # Number of features to consider at every split\n",
        "max_features = [50]\n",
        "# # Maximum number of levels in tree\n",
        "max_depth = [None]\n",
        "# # Minimum number of samples required to split a node\n",
        "min_samples_split = [2]\n",
        "# # Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1,2,7,14,30]\n",
        "\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf\n",
        "               }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Grid search\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# GRID SEARCH\n",
        "from tqdm import trange\n",
        "\n",
        "gs_results = {}\n",
        "\n",
        "# for systemName in tqdm(systemsName_Valid):\n",
        "for systemName_i in tqdm(np.random.randint(1, 300, 30)):\n",
        "    systemName = systemsName_Valid[systemName_i]\n",
        "    # remove the target column from the features\n",
        "    X, y = get_system_data(systemName, set='train', relative=True, max_neighbors=None)\n",
        "    # Use the random grid to search for best hyperparameters\n",
        "    # First create the base model to tune\n",
        "    rf = RandomForestRegressor(random_state=random_state)\n",
        "    # Random search of parameters, using 5 fold cross validation,\n",
        "    # search across 100 different combinations, and use all available cores\n",
        "    rf_grid = GridSearchCV(estimator=rf, param_grid=random_grid, cv=5, n_jobs=-1, refit=False, verbose=2, return_train_score=True, scoring=mae_scorer)\n",
        "    # Fit the random search model\n",
        "    gs_results.update({systemName: rf_grid.fit(X, y).cv_results_})\n",
        "\n",
        "\n",
        "# save gs_results in a pickle file named grid_search_cv_max_features_n_estimators.pkl\n",
        "with open(os.path.join(dataCacheDirpath, 'grid_search_cv_max_depth.pkl'), 'wb') as f:\n",
        "    pickle.dump(gs_results, f)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# load gs_results from the pickle file named grid_search_cv_max_features_n_estimators.pkl\n",
        "with open(os.path.join(dataCacheDirpath, 'grid_search_cv_max_features_n_estimators.pkl'), 'rb') as f:\n",
        "    gs_results = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compute hyperparameter tuning stats\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "param_name = 'min_samples_leaf'\n",
        "param_description = 'Min nbr of observations in a leaf node'\n",
        "\n",
        "param_list = random_grid[param_name]\n",
        "param_name_in_data = f'param_{param_name}'\n",
        "\n",
        "mean_test_scores = pd.DataFrame(columns=gs_results.keys(), index=param_list)\n",
        "mean_train_scores = pd.DataFrame(columns=gs_results.keys(), index=param_list)\n",
        "mean_fit_times = pd.DataFrame(columns=gs_results.keys(), index=param_list)\n",
        "\n",
        "for systemName in gs_results:\n",
        "    data = pd.DataFrame(gs_results[systemName]).dropna(how='all')\n",
        "    data[param_name_in_data] = data[param_name_in_data].astype(int)\n",
        "    data.set_index(param_name_in_data, inplace=True)\n",
        "    mean_fit_times[systemName] = data['mean_fit_time']\n",
        "    mean_test_scores[systemName] = data['mean_test_score']\n",
        "    mean_train_scores[systemName] = data['mean_train_score']\n",
        "\n",
        "# Compute stats\n",
        "mean_test_scores_mean = mean_test_scores.mean(axis=1)\n",
        "mean_test_scores_std = mean_test_scores.std(axis=1)\n",
        "\n",
        "mean_train_scores_mean = mean_train_scores.mean(axis=1)\n",
        "mean_train_scores_std = mean_train_scores.std(axis=1)\n",
        "\n",
        "mean_fit_times_mean = mean_fit_times.mean(axis=1)\n",
        "mean_fit_times_std = mean_fit_times.std(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Plot hyperparameter tuning\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "\n",
        "# Add the Test MAPE trace\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=param_list,\n",
        "    y=mean_test_scores_mean * (-100),\n",
        "    mode='lines+markers',\n",
        "    name='Test MAPE',\n",
        "    error_y=dict(type='data', array=mean_test_scores_std * 100, visible=True),\n",
        "    yaxis=\"y1\"\n",
        "))\n",
        "\n",
        "# Add the Train MAPE trace\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=param_list,\n",
        "    y=mean_train_scores_mean * (-100),\n",
        "    mode='lines+markers',\n",
        "    name='Train MAPE',\n",
        "    error_y=dict(type='data', array=mean_train_scores_std * 100, visible=True),\n",
        "    yaxis=\"y1\"\n",
        "))\n",
        "\n",
        "# Add the Training Time trace with secondary y-axis\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=param_list,\n",
        "    y=mean_fit_times_mean,\n",
        "    mode='lines+markers',\n",
        "    name='Training time',\n",
        "    error_y=dict(type='data', array=mean_fit_times_std, visible=True),\n",
        "    yaxis=\"y2\"\n",
        "))\n",
        "\n",
        "# Update layout to include the secondary y-axis\n",
        "fig.update_layout(\n",
        "    yaxis_title=\"MAPE [%]\",\n",
        "    xaxis_title=f\"{param_description} ({param_name})\",\n",
        "    autosize=False,\n",
        "    width=1000,\n",
        "    height=666,\n",
        "    yaxis2=dict(\n",
        "        title=\"Training time [s]\",\n",
        "        overlaying=\"y\",\n",
        "        side=\"right\"\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train regressors\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Random Forest Regressor hyperparameters\n",
        "n_estimators = 100  # Number of trees in random forest\n",
        "max_features = 'log2'  # Number of features to consider at every split\n",
        "max_depth = None  # Maximum number of levels in tree\n",
        "min_samples_split = 2  # Minimum number of samples required to split a node\n",
        "min_samples_leaf = 1  # Minimum number of samples required at each leaf node\n",
        "\n",
        "targetName = systemsName_Valid[0]\n",
        "\n",
        "\n",
        "X, y = get_system_data(targetName, set='train')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "rf_regressor = RandomForestRegressor(oob_score=True, random_state=random_state, n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "y_pred, y_pred_std = rf_regressor.predict_w_std(X_test)\n",
        "\n",
        "# plot with squater poot the prediction y_pred with the standard deviation y_pred_std, as well as the measured values y_val\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=X_test.index, y=y_test, mode='markers', name='Measured'))\n",
        "fig.add_trace(go.Scatter(x=X_test.index, y=y_pred, mode='markers', name='Predicted'))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "serializer = PickleSerializer()\n",
        "\n",
        "rf_regressors = {}\n",
        "\n",
        "# Random Forest Regressor hyperparameters\n",
        "n_estimators = 50  # Number of trees in random forest\n",
        "max_features = None  # Number of features to consider at every split\n",
        "max_depth = None  # Maximum number of levels in tree\n",
        "min_samples_split = 2  # Minimum number of samples required to split a node\n",
        "min_samples_leaf = 1  # Minimum number of samples required at each leaf node\n",
        "max_neighbors = 50\n",
        "    \n",
        "# load from cache the already trained models\n",
        "if useCached and not forceTrain:\n",
        "    # load the models in dataCacheDirpath/rf_regressors. The file name is the system name.\n",
        "    for systemName in systemsName_Valid:\n",
        "        try:\n",
        "            rf_regressors[systemName] = serializer.retrieve_model(os.path.join(dataCacheDirpath, 'rf_regressors'), systemName)\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "    print(f\"Loaded {len(rf_regressors)}/{len(systemsName_Valid)} models. {len(systemsName_Valid) - len(rf_regressors)} models to train.\")\n",
        "\n",
        "# train the models for the systems that are not already trained\n",
        "iteration_times_rf_training = []\n",
        "for targetName in tqdm(set(systemsName_Valid) - set(rf_regressors), desc='Training regressors'):\n",
        "    start_time = time.time()\n",
        "\n",
        "    rf_regressor = RandomForestRegressor(oob_score=True, random_state=random_state, n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "    X_train, y_train = get_system_data(targetName, set='train', relative=True, max_neighbors=max_neighbors)\n",
        "\n",
        "    # split the data into training and testing sets\n",
        "    rf_regressor.fit(X_train, y_train)\n",
        "    rf_regressors[targetName] = rf_regressor\n",
        "    # save the model in dataCacheDirpath/rf_regressors. The file name is the system name.\n",
        "    serializer.save_model(rf_regressor, os.path.join(dataCacheDirpath, 'rf_regressors'), targetName)\n",
        "\n",
        "    iteration_duration = time.time() - start_time\n",
        "    iteration_times_rf_training.append(iteration_duration)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### OOB train prediction and metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "systemsData_RelativeExpectedDailyEnergy_train_List = []\n",
        "regressorsMetrics_mape_scaled_train = pd.Series(index=systemsName_Valid, name='Train MAPE Normalized')\n",
        "# extract all oob predictions for each system and add them to the list\n",
        "for targetName, rf_regressor in rf_regressors.items():\n",
        "    y_train = systemsData_RelativeMeasuredDailyEnergy_train[targetName].dropna()\n",
        "    y_pred = pd.Series(rf_regressor.oob_prediction_, index=y_train.index, name=targetName).dropna()\n",
        "    regressorsMetrics_mape_scaled_train.loc[targetName] = mean_absolute_error(y_train, y_pred)\n",
        "    systemsData_RelativeExpectedDailyEnergy_train_List.append(y_pred)\n",
        "# Concatenate all the columns in the list to create one dataframe\n",
        "systemsData_RelativeExpectedDailyEnergy_train = pd.concat(systemsData_RelativeExpectedDailyEnergy_train_List, axis=1)\n",
        "systemsData_RelativeExpectedDailyEnergy_train.index = pd.to_datetime(systemsData_RelativeExpectedDailyEnergy_train.index)\n",
        "systemsData_RelativeExpectedDailyEnergy_train.sort_index(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute absolute expected daily energy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "systemsData_ExpectedDailyEnergy_train = systemsData_RelativeExpectedDailyEnergy_train * normalizer_estimated_max_daily_energy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute feature importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "compute_permutation_importance = False\n",
        "\n",
        "cacheFilename_permutation_importance_mean = os.path.join(dataCacheDirpath, 'permutation_importance_mean.csv')\n",
        "cacheFilename_permutation_importance_std = os.path.join(dataCacheDirpath, 'permutation_importance_std.csv')\n",
        "\n",
        "# start = time.time()\n",
        "\n",
        "features_importance_df = pd.DataFrame(index=systemsName_Valid, columns=systemsName_Valid)\n",
        "for targetName in systemsName_Valid:\n",
        "    rf_regressor = rf_regressors[targetName]\n",
        "    features_importance_df.loc[targetName, rf_regressor.feature_names_in_] = rf_regressor.feature_importances_\n",
        "\n",
        "\n",
        "if compute_permutation_importance:\n",
        "    if useCached and os.path.exists(cacheFilename_permutation_importance_mean) and os.path.exists(cacheFilename_permutation_importance_std):\n",
        "        print(f\"Loading cached data in {cacheFilename_permutation_importance_mean}\")\n",
        "        permutation_importance_mean_df = pd.read_csv(cacheFilename_permutation_importance_mean, index_col=0)\n",
        "        print(f\"Loading cached data in {cacheFilename_permutation_importance_std}\")\n",
        "        permutation_importance_std_df = pd.read_csv(cacheFilename_permutation_importance_std, index_col=0)\n",
        "    else:\n",
        "        permutation_importance_mean_df = pd.DataFrame(index=systemsName_Valid, columns=systemsName_Valid)\n",
        "        permutation_importance_std_df = pd.DataFrame(index=systemsName_Valid, columns=systemsName_Valid)\n",
        "        for targetName in tqdm(systemsName_Valid):\n",
        "            X, y = get_system_data(targetName)\n",
        "            rf_regressor = rf_regressors[targetName]\n",
        "            permutation_importance_results = permutation_importance(rf_regressor, X, y, n_repeats=5, random_state=random_state, n_jobs=-1, scoring=mae_scorer)\n",
        "            permutation_importance_mean_df.loc[targetName, X.columns] = permutation_importance_results.importances_mean\n",
        "            permutation_importance_std_df.loc[targetName, X.columns] = permutation_importance_results.importances_std\n",
        "        # save the permutation importances\n",
        "        permutation_importance_mean_df.to_csv(cacheFilename_permutation_importance_mean)\n",
        "        permutation_importance_std_df.to_csv(cacheFilename_permutation_importance_std)\n",
        "\n",
        "\n",
        "# print(f\"Time elapsed: {time.time() - start} - Time per system: {(time.time() - start) / len(systemsName_Valid)}\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "serializer = PickleSerializer()\n",
        "\n",
        "rf_regressors = {}\n",
        "forceTrain = True\n",
        "if not forceTrain:\n",
        "    # load the models in dataCacheDirpath/rf_regressors. The file name is the system name.\n",
        "    for systemName in systemsName_Valid:\n",
        "        try:\n",
        "            rf_regressors[systemName] = serializer.retrieve_model(os.path.join(dataCacheDirpath, 'rf_regressors'), systemName)\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "    print(f\"Loaded {len(rf_regressors)}/{len(systemsName_Valid)} models. {len(systemsName_Valid) - len(rf_regressors)} models to train.\")\n",
        "\n",
        "# Train a Random Forest Regressor model to predict the daily energy production of a system based on the daily energy production of the other systems\n",
        "metrics_df = pd.DataFrame(index=systemsName_Valid, columns=['MAPE', 'MAPE-MD', 'MAE', 'RMSE', 'R2'])\n",
        "features_importance_df = pd.DataFrame(index=systemsName_Valid, columns=systemsName_Valid)\n",
        "permutation_importance_df = pd.DataFrame(index=systemsName_Valid, columns=systemsName_Valid)\n",
        "\n",
        "for targetName in tqdm(set(systemsName_Valid) - set(rf_regressors), desc='Training regressors'):\n",
        "    rf_regressor = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=random_state)\n",
        "    # remove the target column from the features\n",
        "    X = systemsData_MeasuredRelativeDailyEnergy.drop(columns=targetName)\n",
        "    y = systemsData_MeasuredRelativeDailyEnergy[targetName]\n",
        "    # remove the observations where their is no target value\n",
        "    X = X[~systemsData_MeasuredRelativeDailyEnergy[targetName].isna()]\n",
        "    y = y[~systemsData_MeasuredRelativeDailyEnergy[targetName].isna()]\n",
        "    # split the data into training and testing sets\n",
        "    # TODo utiliser OOB\n",
        "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_state) # Not necessary to split the data, as the OOB can be used to estimate the error\n",
        "    # train the regressor\n",
        "    y_oob_pred = rf_regressor.fit(X, y).oob_prediction_\n",
        "    # save the feature importances\n",
        "    features_importance_df.loc[targetName, X.columns] = rf_regressor.feature_importances_\n",
        "    # permutation_importance_df.loc[targetName, X.columns] = permutation_importance(rf_regressor, X_test, y_test, n_repeats=10, random_state=random_state, n_jobs=-1).importances_mean\n",
        "\n",
        "    # test the regressor\n",
        "    # y_mean = rf_regressor.predict(X_test)\n",
        "\n",
        "    # y_pred_V_IJ_unbiased = fci.random_forest_error(rf_regressor, X_train, X_test)\n",
        "\n",
        "    # compute the metrics\n",
        "    metrics_df.loc[targetName] = metrics(y, y_oob_pred)\n",
        "\n",
        "    # save the model\n",
        "    # serializer.save_model(rf_regressor, os.path.join(dataCacheDirpath, 'rf_regressors'), targetName)\n",
        "    rf_regressors[targetName] = rf_regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Expected daily energy on TEST set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# valid system that have been trained\n",
        "systems_trained = [systemName for systemName in systemsName_Valid if systemName in rf_regressors]\n",
        "\n",
        "print(\"Systems not trained:\", [systemName for systemName in systemsName_Valid if systemName not in rf_regressors])\n",
        "\n",
        "\n",
        "# check that all the index in systemsData_MeasuredDailyEnergy_test are in systemsData_EstimatedMaxDailyEnergy\n",
        "if not systemsData_MeasuredDailyEnergy_test.index.isin(normalizer_estimated_max_daily_energy.index).all():\n",
        "    raise ValueError(\"Some index in systemsData_MeasuredDailyEnergy_test are not in systemsData_EstimatedMaxDailyEnergy\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# generate max value\n",
        "\n",
        "systemsData_EstimatedMaxDailyEnergy_test_dic = {}\n",
        "for systemName in tqdm(systemsName_Valid):\n",
        "    estimator = generate_max_production_estimator(systemsMetadata[systemName])\n",
        "    measured_series = systemsData_MeasuredDailyEnergy_test[systemName]\n",
        "    if measured_series.count() == 0:\n",
        "        continue\n",
        "    startDate = measured_series[~measured_series.isna()].index.min()\n",
        "    endDate = measured_series[~measured_series.isna()].index.max()\n",
        "    estimatedMaxDailyEnergy = generate_max_production_estimate(startDate, endDate, estimator, samplingFreq='1h')\n",
        "\n",
        "    # fill remaining days with NaN\n",
        "    estimatedMaxDailyEnergy = estimatedMaxDailyEnergy.reindex(measured_series.index, fill_value=np.nan)\n",
        "\n",
        "    # add the series to the dictionary\n",
        "    systemsData_EstimatedMaxDailyEnergy_test_dic[systemName] = estimatedMaxDailyEnergy\n",
        "\n",
        "\n",
        "# Concatenate all the columns in the list to create one dataframe\n",
        "systemsData_EstimatedMaxDailyEnergy_test = pd.concat(systemsData_EstimatedMaxDailyEnergy_test_dic, axis=1)\n",
        "systemsData_EstimatedMaxDailyEnergy_test.index = pd.to_datetime(systemsData_EstimatedMaxDailyEnergy_test.index)\n",
        "systemsData_EstimatedMaxDailyEnergy_test.sort_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute relative value\n",
        "systemsData_RelativeMeasuredDailyEnergy_test = systemsData_MeasuredDailyEnergy_test / normalizer_estimated_max_daily_energy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute expected daily energy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "systemsData_RelativeExpectedDailyEnergy_test_mean_List = []\n",
        "systemsData_RelativeExpectedDailyEnergy_test_std_List = []\n",
        "\n",
        "iteration_times_rf_prediction = []\n",
        "for targetName in tqdm(systems_trained):\n",
        "    start_time = time.time()\n",
        "\n",
        "    X_test, y_test = get_system_data(targetName, set='test', relative=True)\n",
        "    # check that there is at least one observation\n",
        "    if y_test.count() == 0:\n",
        "        continue\n",
        "    regressor = rf_regressors[targetName]\n",
        "    fitted_features = regressor.feature_names_in_\n",
        "\n",
        "    # adjust the feature in the validation set to match the feature in the training set\n",
        "    # Identify extra columns in X_test that are not used by the regressor\n",
        "    extra_features = set(X_test.columns) - set(fitted_features)\n",
        "    # Drop extra columns from X_val\n",
        "    X_test = X_test.drop(columns=list(extra_features), errors='ignore')\n",
        "    # Identify missing columns in X_test and add them as empty columns\n",
        "    missing_features = set(fitted_features) - set(X_test.columns)\n",
        "    for feature in missing_features:\n",
        "        X_test[feature] = np.nan\n",
        "\n",
        "    y_mean, y_std = regressor.predict_w_std(X_test)\n",
        "    y_mean = pd.Series(y_mean, index=X_test.index, name=targetName)\n",
        "    y_std = pd.Series(y_std, index=X_test.index, name=targetName)\n",
        "    systemsData_RelativeExpectedDailyEnergy_test_mean_List.append(y_mean)\n",
        "    systemsData_RelativeExpectedDailyEnergy_test_std_List.append(y_std)\n",
        "\n",
        "    iteration_duration = time.time() - start_time\n",
        "    iteration_times_rf_prediction.append(iteration_duration)\n",
        "\n",
        "\n",
        "\n",
        "systemsData_RelativeExpectedDailyEnergy_test_mean = pd.concat(systemsData_RelativeExpectedDailyEnergy_test_mean_List, axis=1)\n",
        "systemsData_RelativeExpectedDailyEnergy_test_mean.index = pd.to_datetime(systemsData_RelativeExpectedDailyEnergy_test_mean.index)\n",
        "systemsData_RelativeExpectedDailyEnergy_test_mean.sort_index(inplace=True)\n",
        "\n",
        "systemsData_RelativeExpectedDailyEnergy_test_std = pd.concat(systemsData_RelativeExpectedDailyEnergy_test_std_List, axis=1)\n",
        "systemsData_RelativeExpectedDailyEnergy_test_std.index = pd.to_datetime(systemsData_RelativeExpectedDailyEnergy_test_std.index)\n",
        "systemsData_RelativeExpectedDailyEnergy_test_std.sort_index(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "regressorsMetrics_mape_scaled_test = pd.Series(index=systems_trained, name='Test MAPE Normalized')\n",
        "for targetName in systems_trained:\n",
        "    X_test, y_test = get_system_data(targetName, set='test', relative=True)\n",
        "    y_pred = systemsData_RelativeExpectedDailyEnergy_test_mean[targetName].dropna()\n",
        "    regressorsMetrics_mape_scaled_test.loc[targetName] = mean_absolute_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute absolute expected daily energy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "systemsData_ExpectedDailyEnergy_test_mean = systemsData_RelativeExpectedDailyEnergy_test_mean * normalizer_estimated_max_daily_energy\n",
        "systemsData_ExpectedDailyEnergy_test_std = systemsData_RelativeExpectedDailyEnergy_test_std * normalizer_estimated_max_daily_energy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistics on the models metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# do a figure with 3 box plot, one for each column of the dataframe df_mape_train_save.\n",
        "regressorsMetrics_mape_scaled_train_percent = regressorsMetrics_mape_scaled_train[regressorsMetrics_mape_scaled_train < 0.5] * 100\n",
        "regressorsMetrics_mape_scaled_test_percent = regressorsMetrics_mape_scaled_test[regressorsMetrics_mape_scaled_test < 0.5] * 100\n",
        "\n",
        "fig = go.Figure()\n",
        "# fig.add_trace(go.Box(y=regressorsMetrics_mape_scaled_train_percent, name='Train Set', boxmean=True))\n",
        "fig.add_trace(go.Box(y=regressorsMetrics_mape_scaled_test_percent, name='Test Set', boxmean=True, boxpoints='all', jitter=0.5, pointpos=-1.8))\n",
        "\n",
        "\n",
        "# remove legend\n",
        "fig.update_layout(showlegend=False)\n",
        "# set the x axis name to \"Training Days\"\n",
        "# set y axis name to \"MAPE (%)\"\n",
        "fig.update_yaxes(title_text='MAPE (%)')\n",
        "fig.update_layout(width=666, height=666)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "systemsData_RelativeDelta_test = systemsData_RelativeExpectedDailyEnergy_test_mean - systemsData_RelativeMeasuredDailyEnergy_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Detector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# eronate data are the data where the relative delta is lower than regressorsMetrics_test\n",
        "max_z_score = 2.33  # 98% confidence interval\n",
        "systemsData_RelativeDelta_test_detected = systemsData_RelativeDelta_test[systemsData_RelativeDelta_test.loc[:, regressorsMetrics_mape_scaled_test.index] > max_z_score * regressorsMetrics_mape_scaled_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Scaling technics & Outliers removal\n",
        "\n",
        "Compute the:\n",
        "\n",
        "- Global mean\n",
        "- Global median\n",
        "- Global standard deviation\n",
        "- Rolling mean\n",
        "- Rolling median\n",
        "- Rolling standard deviation\n",
        "- Simulate max production without info\n",
        "- SImulated max production with info\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "targetName = \"a001395\"\n",
        "\n",
        "X = systemsData_MeasuredDailyEnergy.drop(columns=targetName)\n",
        "y = systemsData_MeasuredDailyEnergy[targetName]\n",
        "y.index = pd.to_datetime(y.index)\n",
        "# Global mean of the daily energy production of the target system\n",
        "globalMean = y.mean()\n",
        "\n",
        "# Global std of the daily energy production of the target system\n",
        "globalStd = y.std()\n",
        "\n",
        "# Gloabl median of the daily energy production of the target system\n",
        "globalMedian = y.median()\n",
        "\n",
        "roll = y.rolling(window='30D', min_periods=1, center=True)\n",
        "# Rolling mean of the daily energy production of the target system. The window is 1 month\n",
        "rollingMean = roll.mean()\n",
        "\n",
        "# Rolling std of the daily energy production of the target system. The window is 7 days.\n",
        "rollingStd = roll.std()\n",
        "\n",
        "# Rolling Mean Absolute Deviation of the daily energy production of the target system. the function is mad with the arguments how='median' and center='median'\n",
        "rollingMAD = roll.apply(mad)\n",
        "# Rolling median of the daily energy production of the target system. The window is 7 days.\n",
        "rollingMedian = roll.median()\n",
        "\n",
        "# Rolling z score of the daily energy production of the target system. The function is modified_z_score\n",
        "# modifiedZScore = 0.673 * (y - rollingMedian) / rollingMAD\n",
        "\n",
        "# Plot the global and rolling mean, std, and median of the daily energy production of the target system\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=y.index, y=y, mode='markers', name='Daily energy production'))\n",
        "# fig.add_trace(go.Scatter(x=y.index, y=[globalMean]*len(y), mode='lines', name='Global mean'))\n",
        "# fig.add_trace(go.Scatter(x=y.index, y=[globalMean+globalStd]*len(y), mode='lines', name='Global mean + std'))\n",
        "# fig.add_trace(go.Scatter(x=y.index, y=[globalMean-globalStd]*len(y), mode='lines', name='Global mean - std'))\n",
        "# fig.add_trace(go.Scatter(x=y.index, y=[globalMedian]*len(y), mode='lines', name='Global median'))\n",
        "fig.add_trace(go.Scatter(x=rollingMean.index, y=rollingMean, mode='lines', name='Rolling mean'))\n",
        "# fig.add_trace(go.Scatter(x=rollingMean.index, y=rollingMean+rollingStd, mode='lines', name='Rolling mean + std'))\n",
        "# fig.add_trace(go.Scatter(x=rollingMean.index, y=rollingMean-rollingStd, mode='lines', name='Rolling mean - std'))\n",
        "fig.add_trace(go.Scatter(x=rollingMedian.index, y=rollingMedian, mode='lines', name='Rolling median'))\n",
        "fig.add_trace(go.Scatter(x=rollingMAD.index, y=rollingMedian + 4 * rollingMAD, mode='lines', name='Rolling Median + 4*Rolling MAD'))\n",
        "fig.add_trace(go.Scatter(x=rollingMAD.index, y=rollingMAD, mode='lines', name='Rolling MAD'))\n",
        "\n",
        "# fig.add_trace(go.Scatter(x=modifiedZScore.index, y=rollingMedian+modifiedZScore, mode='lines', name='Rolling Median + Rolling Z score'))\n",
        "\n",
        "fig.update_layout(title=f'Global and rolling mean, std, and median of the daily energy production of system {targetName}', yaxis_title='Daily energy production (kWh)')\n",
        "# fig.update_layout(width=1000, height=666)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "def zscore(s, window, thresh=3, return_all=False):\n",
        "    roll = s.rolling(window=window, min_periods=1, center=True)\n",
        "    avg = roll.mean()\n",
        "    std = roll.std(ddof=0)\n",
        "    z = s.sub(avg).div(std)\n",
        "    m = z.between(-thresh, thresh)\n",
        "\n",
        "    if return_all:\n",
        "        return z, avg, std, m\n",
        "    return s.where(m, avg)\n",
        "\n",
        "\n",
        "z, avg, std, m = zscore(y, window=50, return_all=True)\n",
        "\n",
        "ax = plt.subplot()\n",
        "\n",
        "y.plot(label='data')\n",
        "avg.plot(label='mean')\n",
        "y.loc[~m].plot(label='outliers', marker='o', ls='')\n",
        "# avg[~m].plot(label='replacement', marker='o', ls='')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "pv_gis_pred_a001267_april_july = {\n",
        "    '2024-04-01': 38,\n",
        "    '2024-05-01': 41,\n",
        "    '2024-06-01': 47,\n",
        "    '2024-07-01': 47\n",
        "}"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "selected_system = 'a001267'\n",
        "\n",
        "# Prepare the measured data\n",
        "measuredDailyEnergy = systemsData_MeasuredDailyEnergy[selected_system].dropna()\n",
        "\n",
        "# Anomalies (manipulated data)\n",
        "colors = pd.Series(index=measuredDailyEnergy.index, data=\"Gold\", name='Anomalies')\n",
        "# colors.loc[['2024-05-24', '2024-06-26']] = 'red'\n",
        "\n",
        "measuredDailyEnergy.loc['2024-05-24'] *= 0.8\n",
        "measuredDailyEnergy.loc['2024-06-26'] *= 0.1\n",
        "\n",
        "\n",
        "fig1 = go.Figure(layout_yaxis_title=\"Daily Energy (kWh)\")\n",
        "\n",
        "# remove nan from systemsData_EstimatedMaxDailyEnergy[selected_system]\n",
        "\n",
        "# first_trace = True\n",
        "\n",
        "# for start_date, value in pv_gis_pred_a001267_april_july.items():\n",
        "#     end_date = (pd.to_datetime(start_date) + pd.DateOffset(months=1) - pd.DateOffset(days=1)).strftime('%Y-%m-%d')\n",
        "#     fig1.add_trace(go.Scatter(\n",
        "#         x=[start_date, end_date],\n",
        "#         y=[value, value],\n",
        "#         mode='lines',\n",
        "#         name='Actual Prediction from PV GIS' if first_trace else '',\n",
        "#         line=dict(color='yellow'),\n",
        "#         showlegend=first_trace  # Only show legend for the first trace\n",
        "#     ))\n",
        "#     first_trace = False\n",
        "\n",
        "# add a straight line for the PV GIS estimation at 41 kWh\n",
        "\n",
        "# Add normal data trace\n",
        "fig1.add_trace(go.Bar(\n",
        "    x=measuredDailyEnergy.index,\n",
        "    y=measuredDailyEnergy,\n",
        "    name='Measured Production',\n",
        "    marker_color=colors\n",
        "))\n",
        "\n",
        "fig1.add_trace(go.Scatter(\n",
        "    x=measuredDailyEnergy.index,\n",
        "    y=[41] * len(measuredDailyEnergy),\n",
        "    mode='lines',\n",
        "    name='PV GIS Estimation ',\n",
        "    line=dict(color='Green')\n",
        "))\n",
        "\n",
        "estimatedMaxDailyEnergy = normalizer_estimated_max_daily_energy[selected_system].dropna()\n",
        "fig1.add_trace(go.Scatter(\n",
        "    x=estimatedMaxDailyEnergy.index,\n",
        "    y=estimatedMaxDailyEnergy,\n",
        "    mode='lines',\n",
        "    name='Max Production',\n",
        "    marker_color='Purple'\n",
        "))\n",
        "\n",
        "\n",
        "\n",
        "expectedDailyEnergy_test_mean = systemsData_ExpectedDailyEnergy_test_mean[selected_system].dropna()\n",
        "expectedDailyEnergy_test_std = systemsData_ExpectedDailyEnergy_test_std[selected_system].dropna()\n",
        "fig1.add_trace(go.Bar(\n",
        "    x=expectedDailyEnergy_test_mean.index,\n",
        "    y=expectedDailyEnergy_test_mean,\n",
        "    # mode='markers',\n",
        "    name='Expected Production',\n",
        "    # color in fec214\n",
        "    marker_color='DarkTurquoise',\n",
        "    error_y=dict(\n",
        "        type='data',\n",
        "        array=expectedDailyEnergy_test_std*1.65,\n",
        "        visible=True,\n",
        "        thickness = 1.5,\n",
        "        width=4\n",
        "    )\n",
        "))\n",
        "\n",
        "fig1.add_trace(go.Scatter(\n",
        "    x=[None], y=[None],\n",
        "    mode='markers',\n",
        "    name='Detected Anomalies',\n",
        "    marker_color='red',\n",
        "    showlegend=True\n",
        "))\n",
        "\n",
        "# Update layout for legend position\n",
        "fig1.update_layout(\n",
        "    legend=dict(\n",
        "        x=0.99,\n",
        "        y=0.99,\n",
        "        xanchor='right',\n",
        "        yanchor='top',\n",
        "        orientation='h'\n",
        "    )\n",
        ")\n",
        "\n",
        "#set size to 1000x666\n",
        "fig1.update_layout(width=1000, height=666)\n",
        "\n",
        "\n",
        "\n",
        "config = {\n",
        "  'toImageButtonOptions': {\n",
        "    'format': 'png', # one of png, svg, jpeg, webp\n",
        "    'filename': 'custom_image',\n",
        "    'height': 666,\n",
        "    'width': 1000,\n",
        "    'scale':6 # Multiply title/legend/axis/canvas sizes by this factor\n",
        "  }\n",
        "}\n",
        "\n",
        "# set the x axis from May 21 to May 27, and the y axis from 0 to 80\n",
        "fig1.update_xaxes(range=['2024-05-20 12:00', '2024-05-28 12:00'])\n",
        "fig1.update_yaxes(range=[0, 85]) \n",
        "\n",
        "fig1.show(config=config)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plot results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "tab_height = '2em'\n",
        "app.layout = html.Div([\n",
        "    html.Div([\n",
        "        dcc.Dropdown(\n",
        "            id='system-dropdown',\n",
        "            options=[{'label': name, 'value': name} for name in systemsName_Valid],\n",
        "            value=systemsName_Valid[0],\n",
        "            style={'width': '50%'}  # Adjust width and font size\n",
        "        ),\n",
        "        html.Div(id='metric-text-container', style={'display': 'inline-block', 'margin-left': '20px'})  # Container for the metric text\n",
        "    ], style={'display': 'flex', 'align-items': 'center'}),  # Align items horizontally\n",
        "    dcc.Tabs(id='plot-tabs', value='tab-energy', children=[\n",
        "        dcc.Tab(label='Absolute Energy', value='tab-energy', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "        dcc.Tab(label='Normalized Energy', value='tab-rel-energy', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "        dcc.Tab(label='Normalizer Tuning', value='tab-norm-tuning', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "        # plot systemsData_RelativeDelta_test\n",
        "        dcc.Tab(label='All Normalized Energy', value='tab-rel-energy-all', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "        dcc.Tab(label='Under Production', value='tab-delta-rel-energy', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "        dcc.Tab(label='All Missing Value', value='tab-miss-val-all', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "        dcc.Tab(label='Selected Neighboring Systems', value='tab-neighbors', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "\n",
        "    ]),  # Adjust height for tabs\n",
        "    html.Div(id='tabs-content', style={'flex': '1 1 auto'})  # Allow the tabs-content div to grow\n",
        "], style={'display': 'flex', 'flexDirection': 'column', 'height': '100vh'})  # Make the outer container fill the screen height\n",
        "\n",
        "\n",
        "@app.callback(\n",
        "    [Output('tabs-content', 'children'),\n",
        "     Output('metric-text-container', 'children')],\n",
        "    [Input('plot-tabs', 'value'),\n",
        "     Input('system-dropdown', 'value')]\n",
        ")\n",
        "def render_content(tab, selected_system):\n",
        "    # Statistic text\n",
        "    try:\n",
        "        mae_train = regressorsMetrics_mape_scaled_train.loc[selected_system]\n",
        "    except:\n",
        "        mae_train = np.nan\n",
        "    try:\n",
        "        mae_test = regressorsMetrics_mape_scaled_test.loc[selected_system]\n",
        "    except:\n",
        "        mae_test = np.nan\n",
        "    try:\n",
        "        loss = systemsMetadata[selected_system]['metadata']['loss']\n",
        "    except:\n",
        "        loss = np.nan\n",
        "\n",
        "    mae_train_text = f\"Half Sibling Regressor - Train set MAPE: {mae_train * 100:.2f}%\"\n",
        "    mae_test_text = f\"Half Sibling Regressor - Test set MAPE: {mae_test * 100:.2f}%\"\n",
        "    loss_text = f\"Normalizer Tuning - Static System Loss : {loss * 100:.2f}%\"\n",
        "\n",
        "    metric_text_div = html.Div([\n",
        "        html.Div(mae_train_text),\n",
        "        html.Div(mae_test_text),\n",
        "        html.Div(loss_text)\n",
        "    ], style={'fontSize': 16})\n",
        "\n",
        "    if tab == 'tab-energy':\n",
        "        fig1 = go.Figure(layout_yaxis_title=\"Daily Energy (kWh)\")\n",
        "\n",
        "        # remove nan from systemsData_EstimatedMaxDailyEnergy[selected_system]\n",
        "\n",
        "        # first_trace = True\n",
        "\n",
        "        # for start_date, value in pv_gis_pred_a001267_april_july.items():\n",
        "        #     end_date = (pd.to_datetime(start_date) + pd.DateOffset(months=1) - pd.DateOffset(days=1)).strftime('%Y-%m-%d')\n",
        "        #     fig1.add_trace(go.Scatter(\n",
        "        #         x=[start_date, end_date],\n",
        "        #         y=[value, value],\n",
        "        #         mode='lines',\n",
        "        #         name='Actual Prediction from PV GIS' if first_trace else '',\n",
        "        #         line=dict(color='yellow'),\n",
        "        #         showlegend=first_trace  # Only show legend for the first trace\n",
        "        #     ))\n",
        "        #     first_trace = False\n",
        "\n",
        "        try:\n",
        "            estimatedMaxDailyEnergy = normalizer_estimated_max_daily_energy[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=estimatedMaxDailyEnergy.index,\n",
        "                y=estimatedMaxDailyEnergy,\n",
        "                mode='lines',\n",
        "                name='Estimated Max Daily Energy',\n",
        "                marker_color='LightSeaGreen'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            measuredDailyEnergy = systemsData_MeasuredDailyEnergy[selected_system].dropna()\n",
        "            fig1.add_trace(go.Bar(\n",
        "                x=measuredDailyEnergy.index,\n",
        "                y=measuredDailyEnergy,\n",
        "                # mode='markers',\n",
        "                name='Measured Daily Energy',\n",
        "                marker_color='blue'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # try:\n",
        "        # measuredDailyEnergy_train_outliers = systemsData_MeasuredDailyEnergy_train_outliers[selected_system].dropna()\n",
        "        #     fig1.add_trace(go.Scatter(\n",
        "        #         x=measuredDailyEnergy_train_outliers.index,\n",
        "        #         y=measuredDailyEnergy_train_outliers,\n",
        "        #         mode='markers',\n",
        "        #         name='Outliers',\n",
        "        #         marker_color='yellow'\n",
        "        #     ))\n",
        "        # except:\n",
        "        #     pass\n",
        "        # try:\n",
        "        #     expectedDailyEnergy_train = systemsData_ExpectedDailyEnergy_train[selected_system].dropna()\n",
        "        #     fig1.add_trace(go.Scatter(\n",
        "        #         x=expectedDailyEnergy_train.index,\n",
        "        #         y=expectedDailyEnergy_train,\n",
        "        #         mode='markers',\n",
        "        #         name='Expected Daily Energy',\n",
        "        #         marker_color='red'\n",
        "        #     ))\n",
        "        # except:\n",
        "        #     pass\n",
        "\n",
        "        try:\n",
        "            expectedDailyEnergy_test_mean = systemsData_ExpectedDailyEnergy_test_mean[selected_system].dropna()\n",
        "            expectedDailyEnergy_test_std = systemsData_ExpectedDailyEnergy_test_std[selected_system].dropna()\n",
        "            fig1.add_trace(go.Bar(\n",
        "                x=expectedDailyEnergy_test_mean.index,\n",
        "                y=expectedDailyEnergy_test_mean,\n",
        "                # mode='markers',\n",
        "                name='Expected Daily Energy',\n",
        "                marker_color='red'\n",
        "                # error_y=dict(\n",
        "                #     type='data',\n",
        "                #     array=expectedDailyEnergy_test_std,\n",
        "                #     visible=True\n",
        "                # )\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Update layout for legend position\n",
        "        fig1.update_layout(\n",
        "            legend=dict(\n",
        "                x=0.99,\n",
        "                y=0.99,\n",
        "                xanchor='right',\n",
        "                yanchor='top',\n",
        "                orientation='h'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return dcc.Graph(figure=fig1, style={'height': '100%', 'width': '100%'}), metric_text_div  # Adjust height and width of the figure\n",
        "\n",
        "    elif tab == 'tab-norm-tuning':\n",
        "        fig1 = go.Figure(layout_yaxis_title=\"Daily Energy (kWh)\")\n",
        "        try:\n",
        "            measuredDailyEnergy = systemsData_MeasuredDailyEnergy[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=measuredDailyEnergy.index,\n",
        "                y=measuredDailyEnergy,\n",
        "                mode='markers',\n",
        "                name='Measured Daily Energy',\n",
        "                marker_color='blue'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            measuredMax = normalizer_tuning_measure_max[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=measuredMax.index,\n",
        "                y=measuredMax,\n",
        "                mode='markers',\n",
        "                name='Max Measured Daily Energy (7 days window)',\n",
        "                marker_color='red'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            outliers = normalizer_tuning_outliers[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=outliers.index,\n",
        "                y=outliers,\n",
        "                mode='markers',\n",
        "                name='Tuning Outliers',\n",
        "                marker_color='yellow'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            estimatedMaxDailyEnergy_untuned = normalizer_tuning_estimated_max_daily_energy_untuned[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=estimatedMaxDailyEnergy_untuned.index,\n",
        "                y=estimatedMaxDailyEnergy_untuned,\n",
        "                mode='lines',\n",
        "                name='Estimated Max Daily Energy (Untuned)',\n",
        "                marker_color='violet'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            estimatedMaxDailyEnergy = normalizer_estimated_max_daily_energy[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=estimatedMaxDailyEnergy.index,\n",
        "                y=estimatedMaxDailyEnergy,\n",
        "                mode='lines',\n",
        "                name='Estimated Max Daily Energy (Tuned)',\n",
        "                marker_color='LightSeaGreen'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        fig1.update_layout(\n",
        "            legend=dict(\n",
        "                x=0.99,\n",
        "                y=0.99,\n",
        "                xanchor='right',\n",
        "                yanchor='top',\n",
        "                orientation='h'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return dcc.Graph(figure=fig1, style={'height': '100%', 'width': '100%'}), metric_text_div\n",
        "    elif tab == 'tab-rel-energy':\n",
        "        fig1 = go.Figure(layout_yaxis_title=\"Normalized Daily Energy (%)\")\n",
        "        # add a line at 100% for the Estimated Max Daily Energy\n",
        "        estimatedMaxDailyEnergy = normalizer_estimated_max_daily_energy[selected_system].dropna()\n",
        "        fig1.add_shape(\n",
        "            type=\"line\",\n",
        "            x0=estimatedMaxDailyEnergy.index.min(),\n",
        "            y0=100,\n",
        "            x1=estimatedMaxDailyEnergy.index.max(),\n",
        "            y1=100,\n",
        "            name='Estimated Max Daily Energy',\n",
        "            line_color='LightSeaGreen'\n",
        "            # line=dict(\n",
        "            #     color=\"LightSeaGreen\",\n",
        "            #     width=2,\n",
        "            #     dash=\"dashdot\",\n",
        "            # ),\n",
        "        )\n",
        "        try:\n",
        "            relativeMeasuredDailyEnergy = systemsData_RelativeMeasuredDailyEnergy[selected_system].dropna()\n",
        "            fig1.add_trace(go.Bar(\n",
        "                x=relativeMeasuredDailyEnergy.index,\n",
        "                y=relativeMeasuredDailyEnergy * 100,\n",
        "                # mode='markers',\n",
        "                name='Measured Daily Energy',\n",
        "                marker_color='blue'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            relativeExpectedDailyEnergy_test_mean = systemsData_RelativeExpectedDailyEnergy_test_mean[selected_system].dropna()\n",
        "            fig1.add_trace(go.Bar(\n",
        "                x=relativeExpectedDailyEnergy_test_mean.index,\n",
        "                y=relativeExpectedDailyEnergy_test_mean * 100,\n",
        "                # mode='markers',\n",
        "                name='Expected Daily Energy',\n",
        "                marker_color='red'\n",
        "                # error_y=dict(\n",
        "                #     type='data',\n",
        "                #     array=systemsData_RelativeExpectedDailyEnergy_test_std[selected_system] * 100,\n",
        "                #     visible=True\n",
        "                # )\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        fig1.update_layout(\n",
        "            legend=dict(\n",
        "                x=0.99,\n",
        "                y=0.99,\n",
        "                xanchor='right',\n",
        "                yanchor='top',\n",
        "                orientation='h'\n",
        "            )\n",
        "        )\n",
        "        return dcc.Graph(figure=fig1, style={'height': '100%', 'width': '100%'}), metric_text_div  # Adjust height and width of the figure\n",
        "    elif tab == 'tab-delta-rel-energy':\n",
        "        fig1 = go.Figure(layout_yaxis_title=\"Normalized Daily Energy Loss (%)\")\n",
        "        try:\n",
        "            relativeDelta_test = systemsData_RelativeDelta_test[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=relativeDelta_test.index,\n",
        "                y=relativeDelta_test * 100,\n",
        "                mode='markers',\n",
        "                name='Normalized Delta Energy',\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            relativeDelta_test_detected = systemsData_RelativeDelta_test_detected[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=relativeDelta_test_detected.index,\n",
        "                y=relativeDelta_test_detected * 100,\n",
        "                mode='markers',\n",
        "                name='Detected Anomaly',\n",
        "                marker_color='red'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        fig1.update_layout(\n",
        "            legend=dict(\n",
        "                x=0.99,\n",
        "                y=0.99,\n",
        "                xanchor='right',\n",
        "                yanchor='top',\n",
        "                orientation='h'\n",
        "            )\n",
        "        )\n",
        "        return dcc.Graph(figure=fig1, style={'height': '100%', 'width': '100%'}), metric_text_div  # Adjust height and width of the figure\n",
        "    elif tab == 'tab-rel-energy-all':\n",
        "        fig1 = go.Figure(layout_yaxis_title=\"Normalized Daily Energy (%)\")\n",
        "        # try:\n",
        "        features_importance_norm = features_importance_df.loc[selected_system] / features_importance_df.loc[selected_system].max()\n",
        "\n",
        "        for systemName in systemsName_Valid:\n",
        "            if systemName != selected_system:\n",
        "                if features_importance_norm[systemName] > 0.05:\n",
        "                    fig1.add_trace(go.Scatter(\n",
        "                        x=systemsData_RelativeMeasuredDailyEnergy[systemName].index,\n",
        "                        y=systemsData_RelativeMeasuredDailyEnergy[systemName] * 100,\n",
        "                        mode='markers',\n",
        "                        name=f'{systemName}',\n",
        "                        marker_color='blue',\n",
        "                        marker_opacity=features_importance_norm[systemName]\n",
        "                    ))\n",
        "        fig1.add_trace(go.Scatter(\n",
        "            x=systemsData_RelativeMeasuredDailyEnergy[selected_system].index,\n",
        "            y=systemsData_RelativeMeasuredDailyEnergy[selected_system] * 100,\n",
        "            mode='markers',\n",
        "            name=f'{selected_system}',\n",
        "            marker_color='red'\n",
        "        ))\n",
        "        fig1.update_layout(yaxis=dict(range=[-5, 120]))\n",
        "\n",
        "        # except:\n",
        "        #     pass\n",
        "\n",
        "        return dcc.Graph(figure=fig1, style={'height': '100%', 'width': '100%'}), metric_text_div  # Adjust height and width of the figure\n",
        "    elif tab == 'tab-miss-val-all':\n",
        "        measures = systemsData_MeasuredDailyEnergy\n",
        "\n",
        "        # Sort columns by the number of missing values\n",
        "        sorted_columns = measures.isnull().sum().sort_values().index\n",
        "        sorted_measures = measures[sorted_columns]\n",
        "\n",
        "        # Create a boolean DataFrame where True indicates missing values\n",
        "        missing_values = (~sorted_measures.isnull()).astype(int)\n",
        "\n",
        "        # Plot heatmap\n",
        "        fig = go.Figure(data=go.Heatmap(\n",
        "            z=missing_values,\n",
        "            x=missing_values.columns,\n",
        "            y=missing_values.index,\n",
        "            showscale=False,\n",
        "            colorscale='Greys'  # Set colorscale to black and white\n",
        "        ))\n",
        "        fig.update_layout(\n",
        "            yaxis=dict(\n",
        "                showticklabels=True,  # Show y-axis tick labels\n",
        "                autorange='reversed'  # Invert the y-axis\n",
        "            ),\n",
        "            yaxis_tickmode='array',\n",
        "            yaxis_tickvals=pd.date_range(start=missing_values.index.min(), end=missing_values.index.max(), freq='ME'),\n",
        "            yaxis_ticktext=pd.date_range(start=missing_values.index.min(), end=missing_values.index.max(), freq='ME').strftime('%b %Y')\n",
        "        )\n",
        "\n",
        "        return dcc.Graph(figure=fig, style={'height': '100%', 'width': '100%'}), metric_text_div  # Adjust height and width of the figure\n",
        "\n",
        "    elif tab == 'tab-neighbors':\n",
        "        fig2 = go.Figure()\n",
        "\n",
        "        # Add initial traces with secondary y-axis\n",
        "        try:\n",
        "            selected_features_importance_df = features_importance_df.loc[selected_system,].dropna()\n",
        "            fig2.add_trace(go.Bar(\n",
        "                x=selected_features_importance_df.index,\n",
        "                y=selected_features_importance_df*100,\n",
        "                name='Impurity-based Importance',\n",
        "                yaxis='y1',\n",
        "                offsetgroup=1,\n",
        "                texttemplate='%{y:.1f}%',  # Display the percentage value on top of each bar\n",
        "\n",
        "            ))\n",
        "            fig2.update_layout(\n",
        "                yaxis1=dict(\n",
        "                    title='Impurity-based Importance'\n",
        "                    # range=[0, selected_features_importance_df.max()],\n",
        "                )\n",
        "            )\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            fig2.add_trace(go.Bar(\n",
        "                x=permutation_importance_mean_df.columns,\n",
        "                y=permutation_importance_mean_df.loc[selected_system],\n",
        "                name='Permutation Importance',\n",
        "                yaxis='y2',\n",
        "                offsetgroup=2\n",
        "            ))\n",
        "            fig2.update_layout(\n",
        "                yaxis2=dict(\n",
        "                    title='Permutation Importance',\n",
        "                    overlaying='y',\n",
        "                    side='right',\n",
        "                    range=[0, permutation_importance_mean_df.loc[selected_system].max()],\n",
        "                )\n",
        "            )\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        return dcc.Graph(figure=fig2, style={'height': '100%', 'width': '100%'}), metric_text_div  # Adjust height and width of the figure\n",
        "\n",
        "\n",
        "def open_browser():\n",
        "    webbrowser.open(\"http://127.0.0.1:8050/\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Open the Dash app in a new browser window\n",
        "    Timer(1, open_browser).start()\n",
        "    app.run_server(debug=True, use_reloader=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparisons between regressors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Define the categories and their corresponding statistics\n",
        "categories = [\"PLR\", \"RF\", \"KNN\", \"SVR\", \"LR\"]\n",
        "q1 =            [3.5 , 2.8, 3.7, 5.8, 5.4    ]\n",
        "median =        [5.9 , 3.9, 4.5, 9.8, 11.7   ]\n",
        "q3 =            [10.8, 5.8, 6.5, 14.9, 19.5  ]\n",
        "lowerfence =    [1.4 , 0.6, 1.3, 1.5, 1.6    ]\n",
        "upperfence =    [14.8, 10.3, 9.6, 20.1, 35.3 ]\n",
        "mean =          [8.2 , 4.7, 5.0, 12.2, 15.8  ]\n",
        "\n",
        "# Define colors for each category, with \"PLR\" set to orange\n",
        "colors = ['orange', 'blue', 'blue', 'blue', 'blue']\n",
        "\n",
        "# Initialize the figure\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add a separate Box trace for each category\n",
        "for i, category in enumerate(categories):\n",
        "    fig.add_trace(go.Box(\n",
        "        name=category,\n",
        "        x=[category],\n",
        "        q1=[q1[i]],\n",
        "        median=[median[i]],\n",
        "        q3=[q3[i]],\n",
        "        lowerfence=[lowerfence[i]],\n",
        "        upperfence=[upperfence[i]],\n",
        "        mean=[mean[i]],\n",
        "        marker_color=colors[i],\n",
        "        showlegend=False  # Show legend only once for \"PLR\"\n",
        "    ))\n",
        "\n",
        "# Update layout settings\n",
        "fig.update_layout(\n",
        "    yaxis_title='MAPE [%]',\n",
        "    width=1000,\n",
        "    height=666\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Impact of number of neighbors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Regressor hyperparameters\n",
        "n_estimators = 100  # Number of trees in random forest\n",
        "max_features = None  # Number of features to consider at every split\n",
        "max_depth = None  # Maximum number of levels in tree\n",
        "min_samples_split = 2  # Minimum number of samples required to split a node\n",
        "min_samples_leaf = 1  # Minimum number of samples required at each leaf node\n",
        "\n",
        "\n",
        "df_mape_n_neighbors_test = pd.DataFrame(index=systemsName_Valid, columns=[1, 2, 5, 10, 25, 50, 150, 300])\n",
        "for max_neighbors in df_mape_n_neighbors_test.columns:\n",
        "    for targetName in tqdm(systemsName_Valid):\n",
        "        # train\n",
        "        rf_regressor = RandomForestRegressor(oob_score=True, random_state=random_state, n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "        X_train, y_train = get_system_data(targetName, set='train', relative=True, max_neighbors=max_neighbors)\n",
        "        # split the data into training and testing sets\n",
        "        rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "        # predict\n",
        "        X_test, y_test = get_system_data(targetName, set='test', relative=True)\n",
        "        if y_test.count() == 0:\n",
        "            continue\n",
        "\n",
        "        # adjust the feature in the validation set to match the feature in the training set\n",
        "        fitted_features = rf_regressor.feature_names_in_\n",
        "        # Identify extra columns in X_test that are not used by the regressor\n",
        "        extra_features = set(X_test.columns) - set(fitted_features)\n",
        "        # Drop extra columns from X_val\n",
        "        X_test = X_test.drop(columns=list(extra_features), errors='ignore')\n",
        "        # Identify missing columns in X_test and add them as empty columns\n",
        "        missing_features = set(fitted_features) - set(X_test.columns)\n",
        "        for feature in missing_features:\n",
        "            X_test[feature] = np.nan\n",
        "\n",
        "        y_mean_array = rf_regressor.predict(X_test)\n",
        "        y_pred = pd.Series(y_mean_array, index=X_test.index, name=targetName)\n",
        "        df_mape_n_neighbors_test.loc[targetName, max_neighbors] = mean_absolute_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# do a figure with 3 box plot, one for each column of the dataframe df_mape_train_save.\n",
        "df_mape_n_neighbors_test_filtered = df_mape_n_neighbors_test[df_mape_n_neighbors_test < 0.5] * 100\n",
        "fig = go.Figure()\n",
        "for column in df_mape_n_neighbors_test_filtered.columns:\n",
        "    fig.add_trace(go.Box(y=df_mape_n_neighbors_test_filtered[column], name=column, boxmean=True))\n",
        "\n",
        "# remove legend\n",
        "fig.update_layout(showlegend=False)\n",
        "# set the x axis name to \"Training Days\"\n",
        "fig.update_xaxes(title_text='Neighbors systems')\n",
        "# set y axis name to \"MAPE (%)\"\n",
        "fig.update_yaxes(title_text='MAPE (%)')\n",
        "# set the fig size to 1000 x 666\n",
        "fig.update_layout(width=1000, height=666)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Convert 'training_time' from 'HH:MM' format to minutes\n",
        "data = {'systems': df_mape_n_neighbors_test.columns,\n",
        "        'training_time': ['01:04','01:07','01:25','02:06','03:49','05:49','15:38','29:21']}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert training time to minutes\n",
        "df['training_time_seconds'] = df['training_time'].apply(lambda x: int(x.split(':')[0]) * 60 + int(x.split(':')[1])) / 326\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df_mape_n_neighbors_test.astype(float)*100).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Impact of the number of training data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Regressor hyperparameters\n",
        "n_estimators = 100  # Number of trees in random forest\n",
        "max_features = 'log2'  # Number of features to consider at every split\n",
        "max_depth = None  # Maximum number of levels in tree\n",
        "min_samples_split = 2  # Minimum number of samples required to split a node\n",
        "min_samples_leaf = 1  # Minimum number of samples required at each leaf node\n",
        "\n",
        "\n",
        "df_mape_n_history_test = pd.DataFrame(index=systemsName_Valid, columns=[2])\n",
        "for max_training_days in df_mape_n_history_test.columns:\n",
        "    for targetName in tqdm(systemsName_Valid):\n",
        "        # train\n",
        "        rf_regressor = RandomForestRegressor(oob_score=False, random_state=random_state, n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "        X_train, y_train = get_system_data(targetName, set='train', relative=True, max_days=max_training_days)\n",
        "\n",
        "        # split the data into training and testing sets\n",
        "        rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "        # predict\n",
        "        X_test, y_test = get_system_data(targetName, set='test', relative=True)\n",
        "        if y_test.count() == 0:\n",
        "            continue\n",
        "\n",
        "        # adjust the feature in the validation set to match the feature in the training set\n",
        "        fitted_features = rf_regressor.feature_names_in_\n",
        "        # Identify extra columns in X_test that are not used by the regressor\n",
        "        extra_features = set(X_test.columns) - set(fitted_features)\n",
        "        # Drop extra columns from X_val\n",
        "        X_test = X_test.drop(columns=list(extra_features), errors='ignore')\n",
        "        # Identify missing columns in X_test and add them as empty columns\n",
        "        missing_features = set(fitted_features) - set(X_test.columns)\n",
        "        for feature in missing_features:\n",
        "            X_test[feature] = np.nan\n",
        "\n",
        "        y_mean_array = rf_regressor.predict(X_test)\n",
        "        y_pred = pd.Series(y_mean_array, index=X_test.index, name=targetName)\n",
        "        df_mape_n_history_test.loc[targetName, max_training_days] = mean_absolute_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean Distance to the important features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from haversine import haversine, Unit\n",
        "\n",
        "# Rest of the code\n",
        "weighted_mean_distances = pd.Series(index=features_importance_df.index, name='distances')\n",
        "for targetName in features_importance_df.index:\n",
        "    important_neighbors_sytems = features_importance_df.loc[targetName].sort_values(ascending=False).dropna()\n",
        "    important_neighbors_sytems_names = important_neighbors_sytems.index\n",
        "\n",
        "    long_target = systemsMetadata[targetName]['metadata']['loc_longitude']\n",
        "    lat_target = systemsMetadata[targetName]['metadata']['loc_latitude']\n",
        "    distances = pd.Series(index=important_neighbors_sytems_names, name='distance')\n",
        "    for systemName in important_neighbors_sytems_names:\n",
        "        long = systemsMetadata[systemName]['metadata']['loc_longitude']\n",
        "        lat = systemsMetadata[systemName]['metadata']['loc_latitude']\n",
        "        # compute the distance between the two systems\n",
        "        distances[systemName] = haversine((lat_target, long_target), (lat, long), Unit.KILOMETERS)\n",
        "        \n",
        "    weighted_mean_distances[targetName] = (distances * important_neighbors_sytems).sum() / important_neighbors_sytems.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# box plot of weighted_mean_distances using plotly\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Box(y=weighted_mean_distances, name='Weighted Mean Distances', boxmean=True,\n",
        "            boxpoints='all', # can also be outliers, or suspectedoutliers, or False\n",
        "            jitter=0.3, # add some jitter for a better separation between points\n",
        "            pointpos=-1.8))\n",
        "fig.update_layout(showlegend=False)\n",
        "fig.update_yaxes(title_text='Distance (km)')\n",
        "fig.update_layout(width=1000, height=666)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#squatter plot with X weighted_mean_distances and Y regressorsMetrics_mape_scaled_test\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=weighted_mean_distances, y=regressorsMetrics_mape_scaled_test*100, mode='markers', text=regressorsMetrics_mape_scaled_test.index))\n",
        "fig.update_xaxes(title_text='Distance (km)')\n",
        "fig.update_yaxes(title_text='MAPE (%)')\n",
        "fig.update_layout(width=1000, height=666)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean Number of important features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nbr_significant_neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nbr_significant_neighbors = (features_importance_df>0.1).sum(axis=1)\n",
        "\n",
        "# Create the histogram\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add the histogram trace with percentage normalization\n",
        "fig.add_trace(go.Histogram(\n",
        "    x=nbr_significant_neighbors,\n",
        "    nbinsx=10,\n",
        "    histnorm='percent',\n",
        "    texttemplate='%{y:.1f}%',  # Display the percentage value on top of each bar\n",
        "    textposition='auto',        # Position the text on top of each bar\n",
        "    marker_color='#1f77b4',     # Optional: Set a custom color for the bars\n",
        "))\n",
        "\n",
        "# Update layout for axis titles and figure size\n",
        "fig.update_layout(\n",
        "    xaxis_title='Number of selected neighbors (more than 10% importance)',\n",
        "    yaxis_title='Percentage of PV Systems (%)',\n",
        "    width=1000,\n",
        "    height=666\n",
        ")\n",
        "\n",
        "# Display the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Number of days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Assuming systemsData_MeasuredDailyEnergy is a DataFrame\n",
        "non_na_counts = systemsData_MeasuredDailyEnergy.notna().sum(axis=0)\n",
        "\n",
        "# Create a Plotly histogram\n",
        "fig = go.Figure(data=[go.Histogram(\n",
        "    x=non_na_counts.values,  # Count of non-NA values\n",
        "    nbinsx=100  # Number of bins (adjust as needed)\n",
        ")])\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(\n",
        "    xaxis_title='Number of Days',\n",
        "    yaxis_title='Number of Systems'\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    width=1000,\n",
        "    height=666\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "non_na_counts.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Timing Stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#do box plots of the iteration times of the 3 variables, iteration_times_rf_training, iteration_times_rf_prediction, iteration_times_normalizer\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Box(y=iteration_times_normalizer, name='Normalizer', boxmean=True))\n",
        "fig.add_trace(go.Box(y=iteration_times_rf_training, name='HSR Training', boxmean=True))\n",
        "fig.add_trace(go.Box(y=iteration_times_rf_prediction, name='Prediction', boxmean=True))\n",
        "\n",
        "# remove legend\n",
        "fig.update_layout(showlegend=False)\n",
        "# set the x axis name to \"Training Days\"\n",
        "fig.update_yaxes(title_text='Time (s)')\n",
        "# set y axis name to \"MAPE (%)\"\n",
        "fig.update_layout(width=1000, height=666)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
