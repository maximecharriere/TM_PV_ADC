{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup & Import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pvlib\n",
        "import json\n",
        "import os\n",
        "from pvlib.pvsystem import PVSystem, Array, FixedMount\n",
        "from pvlib.location import Location\n",
        "from pvlib.modelchain import ModelChain\n",
        "from pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, root_mean_squared_error, r2_score\n",
        "from sklearn.inspection import permutation_importance\n",
        "import forestci as fci\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import threading\n",
        "from sklearn.metrics import make_scorer\n",
        "import dash\n",
        "from dash import dcc, html\n",
        "import plotly.graph_objects as go\n",
        "from dash.dependencies import Input, Output\n",
        "import webbrowser\n",
        "from threading import Timer\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from sklearn.utils.parallel import Parallel, delayed\n",
        "from sklearn.utils.validation import (\n",
        "    check_is_fitted,\n",
        ")\n",
        "from sklearn.ensemble._base import _partition_estimators\n",
        "\n",
        "pio.renderers.default = \"browser\"  # render plotly figures in browser\n",
        "\n",
        "PARENT_DATA_DIR = os.getenv('PARENT_DATA_DIR')\n",
        "if PARENT_DATA_DIR is None:\n",
        "    raise ValueError(\"PARENT_DATA_DIR environment variable is not set\")\n",
        "\n",
        "\n",
        "dataDirpath = PARENT_DATA_DIR + r\"\\PRiOT\\dataExport_2\"  # \"/Applications/Documents/TM Maxime/dataExport_3400_daily\"#\n",
        "dataCacheDirpath = os.path.join(dataDirpath, \"cache\")\n",
        "logsDirpath = \"../logs\"\n",
        "useCached = False\n",
        "forceTrain = True\n",
        "tuneMaxProductionEstimators = True\n",
        "random_state = 42\n",
        "\n",
        "\n",
        "testingDays = 100\n",
        "minTestingDays = 30\n",
        "trainingDays = None  # if None, all remaining days are used for training\n",
        "minTrainingDays = 7\n",
        "\n",
        "if not os.path.exists(logsDirpath):\n",
        "    os.makedirs(logsDirpath)\n",
        "\n",
        "if not os.path.exists(dataCacheDirpath):\n",
        "    os.makedirs(dataCacheDirpath)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# create 15 random value between 0.0 and 20.0\n",
        "expected = np.random.uniform(0.0, 20.0, 15)\n",
        "expectedRelative = expected/20.0\n",
        "# create 10 value linearly spaced between 100 and 95\n",
        "linear_values = np.linspace(1.0, 0.90, num=10)\n",
        "#create 5 value at 50\n",
        "constant_values = np.repeat(0.60, 5)\n",
        "#concatenate the three arrays\n",
        "factors = np.concatenate([linear_values, constant_values])\n",
        "measure =  factors*expected\n",
        "measureRelative = measure/20.0\n",
        "\n",
        "mape = (expected-measure)/expected*100\n",
        "mapeRelative = (expectedRelative-measureRelative)/expectedRelative*100\n",
        "\n",
        "# plot expected values and measure in two trace. y axis is kWh, x axis is the date from June 1st 2024 to June 15th 2024\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=pd.date_range(start='2024-06-01', periods=15, freq='D'), y=expected, mode='lines+markers', name='Expected'))\n",
        "fig.add_trace(go.Scatter(x=pd.date_range(start='2024-06-01', periods=15, freq='D'), y=measure, mode='lines+markers', name='Measure'))\n",
        "fig.update_layout(xaxis_title='Date', yaxis_title='Production [kWh]')\n",
        "\n",
        "# set the fig to 1000x666\n",
        "fig.update_layout(width=1000, height=666)\n",
        "fig.show()\n",
        "# plot factors\n",
        "# set the y axis to % between 0 and 100\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=pd.date_range(start='2024-06-01', periods=15, freq='D'), y=mape, mode='markers', name='Relative Error'))\n",
        "fig.add_trace(go.Scatter(x=pd.date_range(start='2024-06-01', periods=15, freq='D'), y=mapeRelative, mode='markers', name='Relative Error RELATIVE'))\n",
        "fig.update_layout(xaxis_title='Date', yaxis_title='Relative Difference [%]')\n",
        "fig.update_yaxes(range=[0, 100])\n",
        "fig.update_layout(width=1000, height=666)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Serializer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/model_persistence.html\n",
        "\n",
        "\n",
        "class ModelSerializer:\n",
        "    def _save_model(self, model, serial_type, save_params):\n",
        "        serial_type.dump(model, save_params)\n",
        "\n",
        "    def _retrieve_model(self, serial_type, retrieve_params):\n",
        "        return serial_type.load(retrieve_params)\n",
        "\n",
        "\n",
        "# save_model_path = \"Serialized_models\\\\\"\n",
        "\n",
        "\n",
        "class JoblibSerializer(ModelSerializer):\n",
        "    def save_model(self, model, save_model_path, filename):\n",
        "        super()._save_model(model, joblib, os.path.join(save_model_path, filename + \".joblib\"))\n",
        "\n",
        "    def retrieve_model(self, save_model_path, filename):\n",
        "        return super()._retrieve_model(joblib, os.path.join(save_model_path, filename + '.joblib'))\n",
        "\n",
        "\n",
        "class PickleSerializer(ModelSerializer):\n",
        "    def save_model(self, model, save_model_path, filename):\n",
        "        # create folder if not exists\n",
        "        if not os.path.exists(save_model_path):\n",
        "            os.makedirs(save_model_path)\n",
        "        with open(os.path.join(save_model_path, filename + \".pkl\"), 'wb') as f:\n",
        "            super()._save_model(model, pickle, f)\n",
        "\n",
        "    def retrieve_model(self, save_model_path, filename):\n",
        "        with open(os.path.join(save_model_path, filename + \".pkl\"), 'rb') as f:\n",
        "            return super()._retrieve_model(pickle, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_altitude_from_wgs84(longitude, latitude):\n",
        "    # Convert WGS84 to LV95\n",
        "    lv95_url = \"https://geodesy.geo.admin.ch/reframe/wgs84tolv95\"\n",
        "    params_lv95 = {\n",
        "        \"easting\": longitude,\n",
        "        \"northing\": latitude,\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    response_lv95 = requests.get(lv95_url, params=params_lv95)\n",
        "    if response_lv95.status_code != 200:\n",
        "        raise Exception(\"Error converting WGS84 to LV95: \" + response_lv95.text)\n",
        "\n",
        "    lv95_data = response_lv95.json()\n",
        "    lv95_easting = lv95_data[\"easting\"]\n",
        "    lv95_northing = lv95_data[\"northing\"]\n",
        "\n",
        "    # Get altitude from LV95 coordinates\n",
        "    altitude_url = \"https://api3.geo.admin.ch/rest/services/height\"\n",
        "    params_altitude = {\n",
        "        \"easting\": lv95_easting,\n",
        "        \"northing\": lv95_northing\n",
        "    }\n",
        "\n",
        "    response_altitude = requests.get(altitude_url, params=params_altitude)\n",
        "    if response_altitude.status_code != 200:\n",
        "        raise Exception(\"Error retrieving altitude: \" + response_altitude.text)\n",
        "\n",
        "    altitude_data = response_altitude.json()\n",
        "    altitude = altitude_data[\"height\"]\n",
        "\n",
        "    return float(altitude)\n",
        "\n",
        "\n",
        "def remove_system(systemName, message):\n",
        "    if 'systemsName_Valid' in globals() and systemName in systemsName_Valid:\n",
        "        systemsName_Valid.remove(systemName)\n",
        "    if 'systemsName_Valid' in globals() and systemName in systemsName_Valid:\n",
        "        systemsName_Valid.remove(systemName)\n",
        "    if 'systemsData_EstimatedMaxDailyEnergy' in globals() and systemName in systemsData_EstimatedMaxDailyEnergy.columns:\n",
        "        systemsData_EstimatedMaxDailyEnergy.drop(columns=systemName, inplace=True)\n",
        "    if 'systemsData_MeasuredDailyEnergy_train' in globals() and systemName in systemsData_MeasuredDailyEnergy_train.columns:\n",
        "        systemsData_MeasuredDailyEnergy_train.drop(columns=systemName, inplace=True)\n",
        "    if 'systemsData_MeasuredDailyEnergy_test' in globals() and systemName in systemsData_MeasuredDailyEnergy_test.columns:\n",
        "        systemsData_MeasuredDailyEnergy_test.drop(columns=systemName, inplace=True)\n",
        "    print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadataFilepath = os.path.join(dataDirpath, \"metadata.json\")\n",
        "\n",
        "with open(metadataFilepath, 'r') as f:\n",
        "    systemsMetadata = json.load(f)\n",
        "\n",
        "# Add altitude to metadata, if not already present (TODO : imporove with multi threading)\n",
        "\n",
        "for systemId, systemMetadata in tqdm(systemsMetadata.items()):\n",
        "    if \"loc_altitude\" not in systemMetadata['metadata']:\n",
        "        if \"loc_longitude\" in systemMetadata['metadata'] and \"loc_latitude\" in systemMetadata['metadata']:\n",
        "            systemMetadata['metadata'][\"loc_altitude\"] = get_altitude_from_wgs84(systemMetadata['metadata'][\"loc_longitude\"], systemMetadata['metadata'][\"loc_latitude\"])\n",
        "\n",
        "# Split arrays in dictionaries by module number\n",
        "for systemId, systemMetadata in systemsMetadata.items():\n",
        "    arrays = {}\n",
        "    keys_to_delete = []\n",
        "    for key, value in systemMetadata['metadata'].items():\n",
        "        if 'mod' in key:\n",
        "            # Extract the module number\n",
        "            array_num = key.split('_')[1][-1]\n",
        "            # Remove the module number from the key\n",
        "            new_key = '_'.join(key.split('_')[:1] + key.split('_')[2:])\n",
        "            # Add the key-value pair to the appropriate module dictionary\n",
        "            if 'arrays' not in systemMetadata:\n",
        "                systemMetadata['arrays'] = {}\n",
        "            if array_num not in systemMetadata['arrays']:\n",
        "                systemMetadata['arrays'][array_num] = {}\n",
        "            systemMetadata['arrays'][array_num][new_key] = value\n",
        "            keys_to_delete.append(key)\n",
        "    for key in keys_to_delete:\n",
        "        del systemMetadata['metadata'][key]\n",
        "\n",
        "# Save metadata with altitude\n",
        "with open(metadataFilepath, 'w') as f:\n",
        "    json.dump(systemsMetadata, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import measures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "cacheFilename_systemsData_MeasuredDailyEnergy = os.path.join(dataCacheDirpath, 'systemsData_MeasuredDailyEnergy.pkl')\n",
        "if useCached and os.path.exists(cacheFilename_systemsData_MeasuredDailyEnergy):\n",
        "    print(f\"Loading cached data in {cacheFilename_systemsData_MeasuredDailyEnergy}\")\n",
        "    systemsData_MeasuredDailyEnergy = pd.read_pickle(cacheFilename_systemsData_MeasuredDailyEnergy)\n",
        "    systemsName_Valid = systemsData_MeasuredDailyEnergy.columns\n",
        "else:\n",
        "    # Load all csv files from the data directory\n",
        "    systemsData = {}\n",
        "    for file in os.listdir(dataDirpath):\n",
        "        if file.endswith(\".csv\"):\n",
        "            systemName = file.split(\"_\")[0]\n",
        "            systemsData[systemName] = pd.read_csv(os.path.join(dataDirpath, file))\n",
        "            systemsData[systemName]['Datetime'] = pd.to_datetime(systemsData[systemName]['Timestamp'], unit='ms', utc=True).dt.tz_convert('Europe/Zurich')\n",
        "            systemsData[systemName]['Date'] = (systemsData[systemName]['Datetime'] + pd.Timedelta(hours=1)).dt.date  # Convert the datetime to only the date, as the production is the daily production. The +1h is to manage the saving time. Normally PRiOT exports the data at midnight (local time) for the day after (e.g. the energy for the July 1st is saved at July 1st 00:00 Europe/Zurich). However it seams that the saving time is not always correctly handled, and sometime the export is done at 23:00 the day before (e.g. the energy for the July 1st is saved at June 30th 23:00 Europe/Zurich). This is why we add 1h to the datetime to be sure to have the correct date.\n",
        "\n",
        "    systemsName = list(systemsData.keys())\n",
        "\n",
        "    df_duplicate_list = list()\n",
        "    for systemName, systemData in systemsData.items():\n",
        "        # Save duplicate dates to log list, and the in a log file\n",
        "        duplicates = systemData[systemData['Date'].duplicated(keep=False)]\n",
        "        if len(duplicates) > 0:\n",
        "            df_duplicate_list.append(duplicates)\n",
        "\n",
        "            # Remove duplicate date where tt_forward_active_energy_total_toDay is the smallest\n",
        "            # TODO maybe we should sum the energy of the duplicates instead of removing the smallest one. However, when looking in PRiOT Portal, it seams that in the daily energy, only the biggest value is represented. We do the same here.\n",
        "            systemData.sort_values('tt_forward_active_energy_total_toDay', ascending=True, inplace=True)\n",
        "            systemsData[systemName].drop_duplicates(subset='Date', keep='last', inplace=True)\n",
        "\n",
        "        # Set date as the index and sort the data by date\n",
        "        systemsData[systemName].set_index('Date', inplace=True)\n",
        "        systemData.sort_index(ascending=True, inplace=True)\n",
        "\n",
        "    # Save duplicate dates to log file\n",
        "    df_duplicate = pd.concat(df_duplicate_list)\n",
        "    print(f\"Number of duplicate dates found: {len(df_duplicate)} (see log file for more details)\")\n",
        "    df_duplicate.to_csv(os.path.join(logsDirpath, 'duplicateDates.csv'), index=True)\n",
        "\n",
        "    ## ----------------------------------------------- ##\n",
        "    ## Convert data & Filter out invalid PRiOT systems ##\n",
        "    ## ----------------------------------------------- ##\n",
        "\n",
        "    systemsName_Valid = systemsName.copy()\n",
        "    for systemName in systemsName:\n",
        "        missingData = False\n",
        "        # Check if the system has measures\n",
        "        if len(systemsData[systemName]) == 0:\n",
        "            missingData = True\n",
        "            print(f\"System {systemName} : No measures found\")\n",
        "        # Check if the system has metadata\n",
        "        if systemName not in systemsMetadata:\n",
        "            missingData = True\n",
        "            print(f\"System {systemName} : No metadata found\")\n",
        "\n",
        "        else:\n",
        "            # Check metadata for the system\n",
        "            for key in ['loc_latitude', 'loc_longitude', 'loc_altitude', 'pv_kwp']:\n",
        "                # test that the key is present\n",
        "                if key not in systemsMetadata[systemName]['metadata']:\n",
        "                    missingData = True\n",
        "                    print(f\"System {systemName} : No '{key}' found\")\n",
        "                # if present, convert the value to a number, if possible\n",
        "                elif not isinstance(systemsMetadata[systemName]['metadata'][key], (int, float)):\n",
        "                    try:\n",
        "                        systemsMetadata[systemName]['metadata'][key] = int(systemsMetadata[systemName]['metadata'][key])\n",
        "                    except ValueError:\n",
        "                        try:\n",
        "                            systemsMetadata[systemName]['metadata'][key] = float(systemsMetadata[systemName]['metadata'][key])\n",
        "                        except ValueError:\n",
        "                            missingData = True\n",
        "                            print(f\"System {systemName} : The key-value '{key}:{systemsMetadata[systemName]['metadata'][key]}' is not a number\")\n",
        "\n",
        "            # Check metadata for the arrays\n",
        "            if 'arrays' not in systemsMetadata[systemName] or len(systemsMetadata[systemName]['arrays']) == 0:\n",
        "                print(f\"System {systemName} : No PV arrays found\")\n",
        "                missingData = True\n",
        "            else:\n",
        "                for array_num, arrayData in systemsMetadata[systemName]['arrays'].items():\n",
        "                    for key in ['pv_tilt', 'pv_azimut', 'pv_wp', 'pv_number']:\n",
        "                        if key not in arrayData:\n",
        "                            missingData = True\n",
        "                            print(f\"System {systemName} : No '{key}' found for array {array_num}\")\n",
        "                        # test that the value is a number\n",
        "                        elif not isinstance(arrayData[key], (int, float)):\n",
        "                            try:\n",
        "                                arrayData[key] = int(arrayData[key])\n",
        "                            except ValueError:\n",
        "                                try:\n",
        "                                    arrayData[key] = float(arrayData[key])\n",
        "                                except ValueError:\n",
        "                                    missingData = True\n",
        "                                    print(f\"System {systemName} : The key-value '{key}:{arrayData[key]}' is not a number for array {array_num}\")\n",
        "\n",
        "            # add the loss metadata if not present\n",
        "            if 'loss' not in systemsMetadata[systemName]['metadata']:\n",
        "                systemsMetadata[systemName]['metadata']['loss'] = 0\n",
        "\n",
        "        if missingData:\n",
        "            systemsName_Valid.remove(systemName)\n",
        "            print(f\"-> Removing system {systemName} from the list of systems\")\n",
        "\n",
        "    print(f\"Number of systems with all the necessary data: {len(systemsName_Valid)}/{len(systemsName)}\")\n",
        "\n",
        "    # # Filter out systems with less than X days of data\n",
        "    # for systemName in systemsName_Valid[:]:  # Create a copy of the list using slicing [:] to avoid removing elements while iterating over the list itself\n",
        "    #     if len(systemsData[systemName]) < minMeasurements:\n",
        "    #         systemsName_Valid.remove(systemName)\n",
        "    #         print(f\"-> Removing system {systemName} from the list of systems because it has less than {minMeasurements} days of data\")\n",
        "\n",
        "    # print(f\"Number of systems with at least {minMeasurements} days of data: {len(systemsName_Valid)}/{len(systemsName)}\")\n",
        "\n",
        "    ## ---------------------------------------------------------------------------- ##\n",
        "    ## Create one 2D DataFrame with the daily production of every remaining systems ##\n",
        "    ## ---------------------------------------------------------------------------- ##\n",
        "\n",
        "    # Create an empty list to store all measured data for each systems\n",
        "    systemsData_MeasuredDailyEnergy_List = []\n",
        "\n",
        "    # Iterate over each key-value pair in the systemsData dictionary\n",
        "    for systemName in systemsName_Valid:\n",
        "        # Extract the 'tt_forward_active_energy_total_toDay' column from the current dataframe\n",
        "        measuredDailyEnergy = systemsData[systemName]['tt_forward_active_energy_total_toDay']\n",
        "\n",
        "        # Rename the column with the system name\n",
        "        measuredDailyEnergy.rename(systemName, inplace=True)\n",
        "\n",
        "        systemsData_MeasuredDailyEnergy_List.append(measuredDailyEnergy)\n",
        "        # Concatenate the column to the new_dataframe\n",
        "\n",
        "    # Concatenate all the columns in the list to create one dataframe\n",
        "    systemsData_MeasuredDailyEnergy = pd.concat(systemsData_MeasuredDailyEnergy_List, axis=1)\n",
        "    systemsData_MeasuredDailyEnergy.index = pd.to_datetime(systemsData_MeasuredDailyEnergy.index)\n",
        "    systemsData_MeasuredDailyEnergy.sort_index(inplace=True)\n",
        "\n",
        "    ## ------------------ ##\n",
        "    ## Save the dataframe ##\n",
        "    ## ------------------ ##\n",
        "    # Save the dataframe for later use\n",
        "    # create cache directory if it does not exist\n",
        "\n",
        "    systemsData_MeasuredDailyEnergy.to_pickle(cacheFilename_systemsData_MeasuredDailyEnergy)\n",
        "\n",
        "# Print the dataframe\n",
        "systemsData_MeasuredDailyEnergy"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Assuming systemsData_MeasuredDailyEnergy is already defined\n",
        "\n",
        "# To store the regressors and their evaluation metrics\n",
        "lin_regressors = {}\n",
        "r2_scores = {}\n",
        "\n",
        "for systemName in systemsData_MeasuredDailyEnergy.columns:\n",
        "    val = systemsData_MeasuredDailyEnergy[['a001035', systemName]].dropna()\n",
        "    if not len(val):\n",
        "        continue\n",
        "    X = val[[systemName]]\n",
        "    y = val['a001035']\n",
        "    \n",
        "    # Fit the linear regression model\n",
        "    linreg = LinearRegression().fit(X, y)\n",
        "    lin_regressors[systemName] = linreg\n",
        "    \n",
        "    # Make predictions   \n",
        "    r2_scores[systemName] = linreg.score(X, y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Create a list of index in r2_scores where the value is more than 0.9\n",
        "high_r2_scores = r2_scores[r2_scores > 0.9].index\n",
        "print(\"number of systems with R^2 > 0.95:\", len(high_r2_scores))\n",
        "# Prepare the feature matrix X and the target vector y\n",
        "X = filtered_data.drop(columns='a001035')\n",
        "y = filtered_data['a001035']\n",
        "\n",
        "# Remove observations where y is NA\n",
        "X = X[~y.isna()]\n",
        "y = y[~y.isna()]\n",
        "\n",
        "# Create an empty DataFrame to store the predictions\n",
        "inter_pred = pd.DataFrame(index=y.index, columns=high_r2_scores)\n",
        "\n",
        "for systemName in high_r2_scores:\n",
        "    if systemName not in lin_regressors:\n",
        "        continue\n",
        "    \n",
        "    # Drop observations with NA values in the current feature\n",
        "    valid_X = X[[systemName]].dropna()\n",
        "    \n",
        "    # Get the indices of valid observations\n",
        "    valid_indices = valid_X.index\n",
        "    \n",
        "    # Make predictions only for valid observations\n",
        "    inter_pred.loc[valid_indices, systemName] = lin_regressors[systemName].predict(valid_X)\n",
        "\n",
        "# Display the inter_pred DataFrame\n",
        "inter_pred\n",
        "\n",
        "# For each day (index) in the inter_pred DataFrame, calculate the mean of the predictions\n",
        "pred = inter_pred.mean(axis=1)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
        "\n",
        "class SplittedLinearRegression:\n",
        "    def __init__(self, min_score=0.9):\n",
        "        self.regressors = None\n",
        "        self.scores = None\n",
        "        self.min_score = min_score\n",
        "    def fit(self, X, y):\n",
        "        self.regressors = {}\n",
        "        self.scores = pd.Series(index=X.columns)\n",
        "        # fit a linear regression for each feature in X\n",
        "        for featureName in X.columns:\n",
        "            # Manage NA value: Keep only observations where both systems (X and y) have values\n",
        "            val = pd.concat([X[featureName], y], axis=1).dropna()\n",
        "            if not len(val):\n",
        "                continue\n",
        "            X_test = val[[featureName]]\n",
        "            y_test = val[y]\n",
        "\n",
        "            # Fit the linear regression model\n",
        "            linreg = LinearRegression().fit(X_test, y_test)\n",
        "            self.regressors[featureName] = linreg\n",
        "\n",
        "            # Make predictions   \n",
        "            self.scores[featureName] = linreg.score(X_test, y_test)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Make predictions for each features in X where the score is above the threshold min_score\n",
        "        high_scores_features = self.scores[self.scores > self.min_score].index\n",
        "\n",
        "        # Create an empty DataFrame to store the intermediate predictions\n",
        "        inter_y_pred = pd.DataFrame(index=X.index, columns=high_sco res_features)\n",
        "        for featureName in high_scores_features:\n",
        "            if featureName not in self.regressors:\n",
        "                continue\n",
        "            # Drop observations with NA values in the current feature\n",
        "            valid_X = X[[featureName]].dropna()\n",
        "            # Get the indices of valid observations\n",
        "            valid_indices = valid_X.index\n",
        "            # Make predictions only for valid observations\n",
        "            inter_y_pred.loc[valid_indices, featureName] = self.regressors[featureName].predict(valid_X)\n",
        "        # Return the mean of the predictions\n",
        "        return inter_y_pred.mean(axis=1)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# create a mask to remove outliers of the shape of systemsData_MeasuredDailyEnergy\n",
        "inlier_masks = pd.DataFrame(True, index=systemsData_MeasuredDailyEnergy.index, columns=systemsData_MeasuredDailyEnergy.columns)\n",
        "# set the mask to false for value in systemsData_MeasuredDailyEnergy under 1kWh\n",
        "inlier_masks[systemsData_MeasuredDailyEnergy < 1] = False\n",
        "\n",
        "# set the mask to false, for each column, for each value in the upper quantile (Q3 + 1.5 * IQR) of each column\n",
        "for systemName in systemsData_MeasuredDailyEnergy.columns:\n",
        "    Q1 = systemsData_MeasuredDailyEnergy[systemName].quantile(0.25)\n",
        "    Q3 = systemsData_MeasuredDailyEnergy[systemName].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    inlier_masks[systemsData_MeasuredDailyEnergy[systemName] > Q3 + 1.5 * IQR] = False\n",
        "\n",
        "filtered_data = systemsData_MeasuredDailyEnergy.copy()\n",
        "filtered_data[~inlier_masks] = np.nan\n",
        "\n",
        "X = filtered_data.drop(columns='a001035')\n",
        "y = filtered_data['a001035']\n",
        "\n",
        "# Remove observations where y is NA\n",
        "X = X[~y.isna()]\n",
        "y = y[~y.isna()]\n",
        "\n",
        "regressor = SplittedLinearRegression().fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = regressor.predict(X)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Create a figure with 52 subplots\n",
        "fig, axs = plt.subplots(13, 4, figsize=(20, 40))\n",
        "\n",
        "# Flatten the axs array to iterate over it\n",
        "axs = axs.flatten()\n",
        "\n",
        "# Iterate over each system\n",
        "for i, systemName in enumerate([name for name in systemsData_MeasuredDailyEnergy.columns if name != 'a001035']):\n",
        "    if systemName not in lin_regressors:\n",
        "        continue\n",
        "    # Plot the daily production of the current system against the daily production of all other systems\n",
        "    val = systemsData_MeasuredDailyEnergy[['a001035', systemName]].dropna()\n",
        "    X = val[[systemName]]\n",
        "    y = val['a001035']\n",
        "    \n",
        "    # Plot all\n",
        "    sns.scatterplot(x=X.values.flatten(), y=y, ax=axs[i])\n",
        "    # Plot inliers\n",
        "    # sns.scatterplot(x=X[inlier_mask].values.flatten(), y=y[inlier_mask], ax=axs[i], color='blue', label='Inliers')\n",
        "    # # Plot outliers\n",
        "    # sns.scatterplot(x=X[outlier_mask].values.flatten(), y=y[outlier_mask], ax=axs[i], color='red', label='Outliers')\n",
        "    \n",
        "    # # Plot the regression line\n",
        "    line_x = pd.DataFrame(np.linspace(X.min().iloc[0], X.max().iloc[0], 10), columns=[systemName])\n",
        "    line_y = lin_regressors[systemName].predict(line_x)\n",
        "    axs[i].plot(line_x, line_y, color='green', linewidth=2)\n",
        "    \n",
        "    axs[i].set_xlabel(systemName)\n",
        "    axs[i].set_ylabel('a001035')\n",
        "    axs[i].set_title(f'R^2: {r2_scores[systemName]:.2f}')\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Create a list of index in r2_scores where the value is more than 0.9\n",
        "high_r2_scores = r2_scores[r2_scores > 0.9].index\n",
        "print(\"number of systems with R^2 > 0.95:\", len(high_r2_scores))\n",
        "# Prepare the feature matrix X and the target vector y\n",
        "X = filtered_data.drop(columns='a001035')\n",
        "y = filtered_data['a001035']\n",
        "\n",
        "# Remove observations where y is NA\n",
        "X = X[~y.isna()]\n",
        "y = y[~y.isna()]\n",
        "\n",
        "# Create an empty DataFrame to store the predictions\n",
        "inter_pred = pd.DataFrame(index=y.index, columns=high_r2_scores)\n",
        "\n",
        "for systemName in high_r2_scores:\n",
        "    if systemName not in lin_regressors:\n",
        "        continue\n",
        "    \n",
        "    # Drop observations with NA values in the current feature\n",
        "    valid_X = X[[systemName]].dropna()\n",
        "    \n",
        "    # Get the indices of valid observations\n",
        "    valid_indices = valid_X.index\n",
        "    \n",
        "    # Make predictions only for valid observations\n",
        "    inter_pred.loc[valid_indices, systemName] = lin_regressors[systemName].predict(valid_X)\n",
        "\n",
        "# Display the inter_pred DataFrame\n",
        "inter_pred\n",
        "\n",
        "# For each day (index) in the inter_pred DataFrame, calculate the mean of the predictions\n",
        "pred = inter_pred.mean(axis=1)\n",
        "\n",
        "# plot the predictions against the target, with markers, using plotly\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=y.index, y=y, mode='markers', name='True'))\n",
        "fig.add_trace(go.Scatter(x=pred.index, y=pred, mode='markers', name='Predicted'))\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Choose system to train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "systemsName_Valid = systemsName_Valid.copy()\n",
        "# systemsName_Valid = [\"a001464\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create train & test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a validation set with the last 100 days\n",
        "# if testingDays == 0:\n",
        "#     systemsData_MeasuredDailyEnergy_train = systemsData_MeasuredDailyEnergy\n",
        "#     systemsData_MeasuredDailyEnergy_test = pd.DataFrame()\n",
        "# else:\n",
        "if testingDays > len(systemsData_MeasuredDailyEnergy):\n",
        "    raise ValueError(f\"testingDays ({testingDays}) is greater than the number of days in the dataset ({len(systemsData_MeasuredDailyEnergy)})\")\n",
        "systemsData_MeasuredDailyEnergy_train, systemsData_MeasuredDailyEnergy_test = train_test_split(systemsData_MeasuredDailyEnergy, train_size=trainingDays, test_size=testingDays, random_state=42, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove systems with not enough days that are not null for training or testing\n",
        "for systemName in systemsData_MeasuredDailyEnergy_train.loc[:, systemsData_MeasuredDailyEnergy_train.notnull().sum() < minTrainingDays].columns:\n",
        "\n",
        "    remove_system(systemName, f\"System {systemName} : Not enough days for training (min {minTrainingDays} days required)\")\n",
        "\n",
        "for systemName in systemsData_MeasuredDailyEnergy_test.loc[:, systemsData_MeasuredDailyEnergy_test.notnull().sum() < minTestingDays].columns:\n",
        "    remove_system(systemName, f\"System {systemName} : Not enough days for testing (min {minTestingDays} days required)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Max production estimator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the power production with a given frequency to the total daily energy\n",
        "def daily_energy(df_power):\n",
        "    # Get the frequency in minutes\n",
        "    freq_in_minutes = pd.Timedelta(df_power.index.freq).seconds / 60\n",
        "    # Convert power from kW to kWh\n",
        "    df_energy = df_power * (freq_in_minutes / 60)\n",
        "    # Resample to daily frequency and sum the values\n",
        "    daily_energy = df_energy.resample('D').sum()\n",
        "    # daily_energy.index = daily_energy.index.date\n",
        "\n",
        "    return daily_energy\n",
        "\n",
        "# Simulate the daily production of a system from a start date to an end date using the given PVLib ModelChain\n",
        "\n",
        "\n",
        "def generate_max_production_estimate(startDate, endDate, estimator: ModelChain, samplingFreq='1h'):\n",
        "    # The end date needs to be estimated completly(end date at 23:59). But \"endDate\" is considered as 00:00 by pd.date_range().\n",
        "    # So we add 1 day to the end date to include the entire end date in the date_range(), and then we exclude the last value with the inclusive='left' proprety, to remove \"endDate+1\" at 00:00) in the date_range().\n",
        "    endDate = endDate + pd.Timedelta(days=1)\n",
        "\n",
        "    times = pd.date_range(start=startDate, end=endDate, freq=samplingFreq, tz=estimator.location.tz, inclusive='left')\n",
        "    weatherClearSky = estimator.location.get_clearsky(times)  # In W/m2\n",
        "    # TODO adjust the clear sky model to take into account the horizon https://pvlib-python.readthedocs.io/en/stable/gallery/shading/plot_simple_irradiance_adjustment_for_horizon_shading.html\n",
        "    estimator.run_model(weatherClearSky)\n",
        "    production = estimator.results.ac / 1000  # Convert W to kW\n",
        "    dailyProduction = daily_energy(production)\n",
        "    dailyProduction.index = pd.to_datetime(dailyProduction.index.date)\n",
        "    return dailyProduction\n",
        "\n",
        "\n",
        "def generate_max_production_estimator(systemMetadata):\n",
        "    latitude = systemMetadata['metadata']['loc_latitude']\n",
        "    longitude = systemMetadata['metadata']['loc_longitude']\n",
        "    altitude = systemMetadata['metadata']['loc_altitude']\n",
        "    Wp_Tot = systemMetadata['metadata']['pv_kwp'] * 1000\n",
        "    loss = systemMetadata['metadata']['loss'] * 100\n",
        "\n",
        "    arrays = []\n",
        "    for array_num, arrayData in systemMetadata['arrays'].items():\n",
        "        array = Array(\n",
        "            mount=FixedMount(surface_tilt=arrayData['pv_tilt'], surface_azimuth=arrayData['pv_azimut'], racking_model='open_rack'),\n",
        "            module_parameters={'pdc0': arrayData['pv_wp'], 'gamma_pdc': -0.004},\n",
        "            module_type='glass_polymer',\n",
        "            modules_per_string=arrayData['pv_number'],\n",
        "            strings=1,\n",
        "            temperature_model_parameters=TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_polymer'],\n",
        "        )\n",
        "        arrays.append(array)\n",
        "\n",
        "    location = Location(latitude=latitude, longitude=longitude, altitude=altitude, tz='Europe/Zurich')\n",
        "    system = PVSystem(arrays=arrays,\n",
        "                      inverter_parameters={'pdc0': Wp_Tot, 'eta_inv_nom': 0.96},\n",
        "                      losses_parameters={'nameplate_rating': loss, 'soiling': 0, 'shading': 0, 'snow': 0, 'mismatch': 0, 'wiring': 0, 'connections': 0, 'lid': 0, 'age': 0, 'availability': 0})\n",
        "    modelChain = ModelChain(system, location, clearsky_model='ineichen', aoi_model='no_loss', spectral_model=\"no_loss\", losses_model='pvwatts')\n",
        "\n",
        "    return modelChain\n",
        "\n",
        "\n",
        "def tune_max_production_estimator(measured_series, max_estimated_series, window=7):\n",
        "    # Remove the obvious outliers. It's important before calculating the std, which can be strongly impacted by the strong outliers.\n",
        "    outliers_mask = measured_series > 2 * max_estimated_series\n",
        "    measured_no_outliers_series = measured_series[~outliers_mask]\n",
        "    # if 10% of the data is removed as outliers, we consider that the system is not valid\n",
        "    if outliers_mask.sum().sum() / outliers_mask.size > 0.1:\n",
        "        return None, None, None, None\n",
        "    # Keep only the max measured value\n",
        "    max_measured_series = pd.Series(index=measured_series.index, dtype=float)\n",
        "    # Iterate over windows of a given size, and keep only the maximum value in each window\n",
        "    for i in range(0, len(measured_series), window):\n",
        "        window_data = measured_no_outliers_series.iloc[i:i + window]\n",
        "        if not window_data.empty and not window_data.isna().all():\n",
        "            max_value = window_data.max()\n",
        "            max_index = window_data.idxmax(skipna=True)\n",
        "            max_measured_series[max_index] = max_value\n",
        "\n",
        "    # Calculate the relative difference between the maximum measured and maximum estimated value\n",
        "    realtive_difference = max_measured_series / max_estimated_series\n",
        "\n",
        "    # Compute statistics\n",
        "    std = realtive_difference.std()\n",
        "    mean = realtive_difference.mean()\n",
        "\n",
        "    # Remove the outilers that have a z-score greater than 1\n",
        "    z_scores = np.abs(realtive_difference - mean) / std\n",
        "\n",
        "    # Add the measure with a z-score greater than 1 to the previous outliers (AND operation)\n",
        "    outliers_mask = outliers_mask | (z_scores > 1)\n",
        "\n",
        "    # Get the loss that overestimate the estimate maximum daily energy\n",
        "    loss = 1 - realtive_difference[~outliers_mask].max()\n",
        "\n",
        "    return loss, std, max_measured_series, outliers_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create estimator\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "\n",
        "systemsData_EstimatedMaxDailyEnergy_dic = {}\n",
        "unfitted_systems = []\n",
        "for systemName in tqdm(systemsName_Valid):\n",
        "\n",
        "    systemsMetadata[systemName]['metadata']['loss'] = 0\n",
        "\n",
        "    estimator = generate_max_production_estimator(systemsMetadata[systemName])\n",
        "\n",
        "    ## ------------------- ##\n",
        "    ## Simulate production ##\n",
        "    ## ------------------- ##\n",
        "    measured_series = systemsData_MeasuredDailyEnergy[systemName]\n",
        "    startDate = measured_series[~measured_series.isna()].index.min()\n",
        "    endDate = measured_series[~measured_series.isna()].index.max()\n",
        "    estimatedMaxDailyEnergy = generate_max_production_estimate(startDate, endDate, estimator, samplingFreq='1h')\n",
        "\n",
        "        # fill remaining days with NaN\n",
        "    estimatedMaxDailyEnergy = estimatedMaxDailyEnergy.reindex(measured_series.index, fill_value=np.nan)\n",
        "\n",
        "        # add the series to the dictionary\n",
        "    systemsData_EstimatedMaxDailyEnergy_dic[systemName] = estimatedMaxDailyEnergy\n",
        "\n",
        "    # loss, std = tune_max_production_estimator(measured_series, estimatedMaxDailyEnergy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Concatenate all the columns in the list to create one dataframe\n",
        "systemsData_EstimatedMaxDailyEnergy = pd.concat(systemsData_EstimatedMaxDailyEnergy_dic, axis=1)\n",
        "systemsData_EstimatedMaxDailyEnergy.index = pd.to_datetime(systemsData_EstimatedMaxDailyEnergy.index)\n",
        "systemsData_EstimatedMaxDailyEnergy.sort_index(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cacheFilename_systemsData_EstimatedMaxDailyEnergy = os.path.join(dataCacheDirpath, 'systemsData_EstimatedMaxDailyEnergy.pkl')\n",
        "\n",
        "# if useCached and os.path.exists(cacheFilename_systemsData_EstimatedMaxDailyEnergy):\n",
        "if True and os.path.exists(cacheFilename_systemsData_EstimatedMaxDailyEnergy):\n",
        "    # TODO how to deal if the cached data is not up to date and some systems have been added or removed?\n",
        "    print(f\"Loading cached data in {cacheFilename_systemsData_EstimatedMaxDailyEnergy}\")\n",
        "    systemsData_EstimatedMaxDailyEnergy = pd.read_pickle(cacheFilename_systemsData_EstimatedMaxDailyEnergy)\n",
        "else:\n",
        "    systemsData_EstimatedMaxDailyEnergy_dic = {}\n",
        "    systemsData_Tuning_EstimatedMaxDailyEnergy_untuned_dic = {}\n",
        "    systemsData_Tuning_MeasureMax_dic = {}\n",
        "    systemsData_Tuning_Outliers_dic = {}\n",
        "\n",
        "    unfitted_systems = []\n",
        "    for systemName in tqdm(systemsName_Valid):\n",
        "        tuned = not tuneMaxProductionEstimators  # If we don't want to tune the estimators, we say that the estimator is already tuned\n",
        "        # reset the loss in the metadata if we want to tune the estimators\n",
        "        if tuneMaxProductionEstimators:\n",
        "            systemsMetadata[systemName]['metadata']['loss'] = 0\n",
        "\n",
        "        while True:  # emulate do while loop\n",
        "\n",
        "            ## ------------------ ##\n",
        "            ## Create ModelChains ##\n",
        "            ## ------------------ ##\n",
        "            estimator = generate_max_production_estimator(systemsMetadata[systemName])\n",
        "\n",
        "            ## ------------------- ##\n",
        "            ## Simulate production ##\n",
        "            ## ------------------- ##\n",
        "            measured_series = systemsData_MeasuredDailyEnergy[systemName]\n",
        "            startDate = measured_series[~measured_series.isna()].index.min()\n",
        "            endDate = measured_series[~measured_series.isna()].index.max()\n",
        "            estimatedMaxDailyEnergy = generate_max_production_estimate(startDate, endDate, estimator, samplingFreq='1h')\n",
        "\n",
        "            # fill remaining days with NaN\n",
        "            estimatedMaxDailyEnergy = estimatedMaxDailyEnergy.reindex(measured_series.index, fill_value=np.nan)\n",
        "\n",
        "            # add the series to the dictionary\n",
        "            systemsData_EstimatedMaxDailyEnergy_dic[systemName] = estimatedMaxDailyEnergy\n",
        "\n",
        "            ## --------------- ##\n",
        "            ## Tune estimators ##\n",
        "            ## --------------- ##\n",
        "            if tuned:\n",
        "                break\n",
        "\n",
        "            loss, std, measuredMax, outliersMask = tune_max_production_estimator(measured_series, estimatedMaxDailyEnergy)\n",
        "\n",
        "            if loss is None:\n",
        "                unfitted_systems.append(systemName)\n",
        "                break\n",
        "\n",
        "            systemsData_Tuning_EstimatedMaxDailyEnergy_untuned_dic[systemName] = estimatedMaxDailyEnergy\n",
        "            systemsData_Tuning_MeasureMax_dic[systemName] = measuredMax\n",
        "            systemsData_Tuning_Outliers_dic[systemName] = measured_series[outliersMask]\n",
        "\n",
        "            # If the std is greater than 1, we remove the system from the list of systems to be processed.\n",
        "            # This is to avoid to have a system that is not well fitted by the maximum energy estimator model, and that could impact the training of the RF model.\n",
        "            if std is None or std > 1 or measured_series.count() == 0:\n",
        "                unfitted_systems.append(systemName)\n",
        "                break\n",
        "\n",
        "            # write the loss in systemsMetadata\n",
        "            systemsMetadata[systemName]['metadata']['loss'] = loss\n",
        "\n",
        "            tuned = True\n",
        "\n",
        "    systemsData_EstimatedMaxDailyEnergy = pd.concat(systemsData_EstimatedMaxDailyEnergy_dic, axis=1)\n",
        "    systemsData_EstimatedMaxDailyEnergy.index = pd.to_datetime(systemsData_EstimatedMaxDailyEnergy.index)\n",
        "    systemsData_EstimatedMaxDailyEnergy.sort_index(inplace=True)\n",
        "\n",
        "    systemsData_Tuning_EstimatedMaxDailyEnergy_untuned = pd.concat(systemsData_Tuning_EstimatedMaxDailyEnergy_untuned_dic, axis=1)\n",
        "    systemsData_Tuning_EstimatedMaxDailyEnergy_untuned.index = pd.to_datetime(systemsData_Tuning_EstimatedMaxDailyEnergy_untuned.index)\n",
        "    systemsData_Tuning_EstimatedMaxDailyEnergy_untuned.sort_index(inplace=True)\n",
        "\n",
        "    systemsData_Tuning_MeasureMax = pd.concat(systemsData_Tuning_MeasureMax_dic, axis=1)\n",
        "    systemsData_Tuning_MeasureMax.index = pd.to_datetime(systemsData_Tuning_MeasureMax.index)\n",
        "    systemsData_Tuning_MeasureMax.sort_index(inplace=True)\n",
        "\n",
        "    systemsData_Tuning_Outliers = pd.concat(systemsData_Tuning_Outliers_dic, axis=1)\n",
        "    systemsData_Tuning_Outliers.index = pd.to_datetime(systemsData_Tuning_Outliers.index)\n",
        "    systemsData_Tuning_Outliers.sort_index(inplace=True)\n",
        "\n",
        "    # Remove unfitted systems from systemsName_Valid, systemsName_Valid, systemsData_EstimatedMaxDailyEnergy, systemsData_MeasuredDailyEnergy\n",
        "    for systemName in unfitted_systems:\n",
        "        remove_system(systemName, f\"System {systemName} : We can't find the model corresponding to the measured data. This system is removed from the list of systems to be processed.\")\n",
        "\n",
        "    # Save the dataframe to a CSV file\n",
        "    systemsData_EstimatedMaxDailyEnergy.to_pickle(cacheFilename_systemsData_EstimatedMaxDailyEnergy)\n",
        "\n",
        "    # Save metadata with tuned parameters\n",
        "    if tuneMaxProductionEstimators:\n",
        "        with open(metadataFilepath, 'w') as f:\n",
        "            json.dump(systemsMetadata, f, indent=4)\n",
        "\n",
        "    # save systemsData_EstimatedMaxDailyEnergy in cacheFilename_systemsData_EstimatedMaxDailyEnergy\n",
        "    systemsData_EstimatedMaxDailyEnergy.to_pickle(cacheFilename_systemsData_EstimatedMaxDailyEnergy)\n",
        "\n",
        "\n",
        "# Print the dataframe\n",
        "systemsData_EstimatedMaxDailyEnergy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remove outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rel_mesasured_series = systemsData_MeasuredDailyEnergy_train / systemsData_EstimatedMaxDailyEnergy\n",
        "\n",
        "# remove the outliers in measured data that are greater than 1.1 times (+10%) the maximum estimated value, or less than 1% of the maximum estimated value\n",
        "inliers = (rel_mesasured_series < 1.1) & (rel_mesasured_series > 0.01)\n",
        "systemsData_MeasuredDailyEnergy_train_outliers = systemsData_MeasuredDailyEnergy_train[~inliers]\n",
        "systemsData_MeasuredDailyEnergy_train = systemsData_MeasuredDailyEnergy_train[inliers]\n",
        "\n",
        "# remove the systems that have less than 7 days\n",
        "for systemName in systemsData_MeasuredDailyEnergy_train.loc[:, systemsData_MeasuredDailyEnergy_train.count() < minTrainingDays].columns:\n",
        "    remove_system(systemName, f\"System {systemName} : The system has less than {minTrainingDays} days of data. This system is removed from the list of systems to be processed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Relative production\n",
        "\n",
        "True production scaled by the maximum production from the simulator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the relative energy for each system\n",
        "systemsData_RelativeMeasuredDailyEnergy_train = systemsData_MeasuredDailyEnergy_train / systemsData_EstimatedMaxDailyEnergy\n",
        "systemsData_RelativeMeasuredDailyEnergy = systemsData_MeasuredDailyEnergy / systemsData_EstimatedMaxDailyEnergy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare the difference between simulation with hourly and 10min sampling rate\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Simulate the daily production for each system with 1h and 10min sampling rate\n",
        "dailyProductions = {}\n",
        "\n",
        "for systemName, modelChain in modelChains.items():\n",
        "    try:\n",
        "        dailyProduction_hour = simulateDailyProduction(systemName, systemsData, modelChains, samplingFreq='1h')\n",
        "        dailyProduction_min = simulateDailyProduction(systemName, systemsData, modelChains, samplingFreq='10min')\n",
        "        dailyProductions[systemName] = pd.DataFrame({'Simulator hour': dailyProduction_hour, 'Simulator 10min': dailyProduction_min})\n",
        "    except Exception as e:\n",
        "        print(f\"Error for system {systemName}: {e}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "# Compute the descriptive statistics of the difference between the 1h and 10min simulations on all systems\n",
        "allSimulations = pd.concat(dailyProductions.values())\n",
        "\n",
        "allSimulations['Difference'] = allSimulations['Simulator hour'] - allSimulations['Simulator 10min']\n",
        "allSimulations['Percentage'] = allSimulations['Difference'] / allSimulations['Simulator 10min'] * 100\n",
        "\n",
        "descriptiveStat = allSimulations[['Difference', 'Percentage']].describe()\n",
        "print(descriptiveStat)\n",
        "\n",
        "\n",
        "# Plot the histogram of the percentage of the difference\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Histogram(x=allSimulations['Percentage'], nbinsx=1000))\n",
        "fig.add_vline(x=descriptiveStat.loc['mean','Percentage'], line_color='red', line_width=2, annotation_text='mean')\n",
        "fig.add_vline(x=descriptiveStat.loc['25%','Percentage'], line_color='green', line_width=2, annotation_text='25%')\n",
        "fig.add_vline(x=descriptiveStat.loc['75%','Percentage'], line_color='green', line_width=2, annotation_text='75%')\n",
        "fig.update_xaxes(dtick=0.1)\n",
        "fig.update_xaxes(range=[-1, 1])\n",
        "fig.update_layout(width=1000, height=666)\n",
        "fig.update_layout(xaxis_title='Percentage of the difference (%)')\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# Plot the daily production of a system with 1h and 10min sampling rate\n",
        "systemName = 'a001096'\n",
        "dailyProduction_hour = simulateDailyProduction(systemName, systemsData, modelChains, samplingFreq='1h')\n",
        "dailyProduction_min = simulateDailyProduction(systemName, systemsData, modelChains, samplingFreq='10min')\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=dailyProduction_min.index, y=dailyProduction_min, mode='markers', name='10min sampling rate'))\n",
        "fig.add_trace(go.Scatter(x=dailyProduction_hour.index, y=dailyProduction_hour, mode='markers', name='Hourly sampling rate'))\n",
        "\n",
        "fig.update_layout(title=f'Simulated daily max AC energy of system {systemName}', xaxis_title='Time', yaxis_title='Energy (kWh)')\n",
        "fig.update_layout(width=1000, height=666)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "test"
        ]
      },
      "source": [
        "## Correlation between Systems\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correlation_matrix = systemsData_MeasuredDailyEnergy.corr(method='pearson', min_periods=minTrainingDays)\n",
        "# set all negative value (therefore when the value of one system increasse, the other systme decrease) to 0\n",
        "correlation_matrix[correlation_matrix < 0] = 0"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Plot correlation matrix\n",
        "\n",
        "# Set the size of the figure\n",
        "plt.figure(figsize=(100, 80))\n",
        "\n",
        "# Creating the heatmap without modifying the default behavior of axis labels\n",
        "sns.heatmap(correlation_matrix, cmap='coolwarm', xticklabels=True, yticklabels=True)\n",
        "\n",
        "# Rotating the tick labels for readability\n",
        "plt.xticks(rotation=90,)\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot linear regression between 2 systems\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.linear_model import RANSACRegressor, LinearRegression\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Remove observation where a001266 and a001036 dataframes have NA value\n",
        "system1 = 'a001236'\n",
        "system2 = 'a001097'\n",
        "\n",
        "df = pd.concat([systemsData_RelativeMeasuredDailyEnergy_train[system1], systemsData_RelativeMeasuredDailyEnergy_train[system2]], axis=1).dropna()\n",
        "\n",
        "x_values = np.linspace(df[system1].min(), df[system1].max(), 100)\n",
        "\n",
        "# Fit line using RANSAC\n",
        "ransac = RANSACRegressor(LinearRegression(), min_samples=20, residual_threshold=None, random_state=42)\n",
        "ransac.fit(df[[system1]], df[system2] )\n",
        "y_values_ransac = ransac.predict(x_values.reshape(-1, 1))\n",
        "\n",
        "# Plot the data\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df[system1], y=df[system2], mode='markers', name='Data'))\n",
        "fig.add_trace(go.Scatter(x=x_values, y=y_values_ransac, mode='lines', name='RANSAC Regression'))\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Half-Sibling Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(columns=['system1', 'system2', 'system2'], index=range(10))\n",
        "df_test.iloc[-1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_system_data(targetName, set='train', relative=True, max_neighbors=None):\n",
        "    # take the max_neighbors best neighbours from the correlation matrix\n",
        "    # if none, take all the neighbours\n",
        "    if max_neighbors == None or max_neighbors > len(systemsName_Valid) - 1:\n",
        "        max_neighbors = len(systemsName_Valid) - 1\n",
        "    best_neighbours = correlation_matrix.loc[targetName, systemsName_Valid].sort_values(ascending=False).index[1:max_neighbors + 1]\n",
        "    # Create the feature matrix X and the target vector y\n",
        "\n",
        "    if set == 'train' and relative:\n",
        "\n",
        "        X = systemsData_RelativeMeasuredDailyEnergy_train[best_neighbours]\n",
        "        y = systemsData_RelativeMeasuredDailyEnergy_train[targetName]\n",
        "    elif set == 'train' and not relative:\n",
        "\n",
        "        X = systemsData_MeasuredDailyEnergy_train[best_neighbours]\n",
        "        y = systemsData_MeasuredDailyEnergy_train[targetName]\n",
        "    elif set == 'test' and relative:\n",
        "\n",
        "        X = systemsData_RelativeMeasuredDailyEnergy_test[best_neighbours]\n",
        "        y = systemsData_RelativeMeasuredDailyEnergy_test[targetName]\n",
        "    elif set == 'test' and not relative:\n",
        "\n",
        "        X = systemsData_MeasuredDailyEnergy_test[best_neighbours]\n",
        "        y = systemsData_MeasuredDailyEnergy_test[targetName]\n",
        "    else:\n",
        "\n",
        "        raise ValueError(f\"Invalid set value: {set}\")\n",
        "\n",
        "    # remove the observations where their is no target value\n",
        "\n",
        "    X = X[~y.isna()]\n",
        "    y = y[~y.isna()]\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "get_system_data('a001305', set='train', relative=True, max_days=100)\n",
        "\n",
        "\n",
        "def mean_absolute_percentage_error_mean_denominator(\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    y_true, y_pred, *, sample_weight=None, multioutput=\"uniform_average\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "):\n",
        "\n",
        "\n",
        "    # Copy of the function mean_absolute_percentage_error from sklearn.metrics._regression, with the denominator of the MAPE changed to the mean of the true values\n",
        "\n",
        "    import sklearn\n",
        "\n",
        "\n",
        "    y_type, y_true, y_pred, multioutput = sklearn.metrics._regression._check_reg_targets(\n",
        "        y_true, y_pred, multioutput\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    )\n",
        "\n",
        "    sklearn.utils.validation.check_consistent_length(y_true, y_pred, sample_weight)\n",
        "\n",
        "\n",
        "    epsilon = np.finfo(np.float64).eps\n",
        "\n",
        "    mape = np.abs(y_pred - y_true) / np.maximum(np.mean(np.abs(y_true)), epsilon)\n",
        "\n",
        "    output_errors = np.average(mape, weights=sample_weight, axis=0)\n",
        "\n",
        "    if isinstance(multioutput, str):\n",
        "\n",
        "        if multioutput == \"raw_values\":\n",
        "            return output_errors\n",
        "\n",
        "\n",
        "        elif multioutput == \"uniform_average\":\n",
        "\n",
        "            # pass None as weights to np.average: uniform mean\n",
        "\n",
        "            multioutput = None\n",
        "\n",
        "\n",
        "    return np.average(output_errors, weights=multioutput)\n",
        "\n",
        "\n",
        "\n",
        "def mean_absolute_percentage_error_epsilon(\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    y_true, y_pred, epsilon=np.finfo(np.float64).eps, *, sample_weight=None, multioutput=\"uniform_average\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "):\n",
        "\n",
        "    # Copy of the function mean_absolute_percentage_error from sklearn.metrics._regression, with epsilon as a parameter\n",
        "\n",
        "    import sklearn\n",
        "\n",
        "    y_type, y_true, y_pred, multioutput = sklearn.metrics._regression._check_reg_targets(\n",
        "        y_true, y_pred, multioutput\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    )\n",
        "\n",
        "    sklearn.utils.validation.check_consistent_length(y_true, y_pred, sample_weight)\n",
        "\n",
        "    mape = np.abs(y_pred - y_true) / np.maximum(np.abs(y_true), epsilon)\n",
        "\n",
        "    output_errors = np.average(mape, weights=sample_weight, axis=0)\n",
        "\n",
        "    if isinstance(multioutput, str):\n",
        "\n",
        "        if multioutput == \"raw_values\":\n",
        "            return output_errors\n",
        "\n",
        "\n",
        "        elif multioutput == \"uniform_average\":\n",
        "\n",
        "            # pass None as weights to np.average: uniform mean\n",
        "\n",
        "            multioutput = None\n",
        "\n",
        "\n",
        "    return np.average(output_errors, weights=multioutput)\n",
        "\n",
        "\n",
        "\n",
        "def mad(arr):\n",
        "\n",
        "\n",
        "    return abs(arr - arr.median()).median()\n",
        "\n",
        "\n",
        "\n",
        "def modified_z_score(arr):\n",
        "\n",
        "\n",
        "    # based on https://www.ibm.com/docs/en/cognos-analytics/11.1.0?topic=terms-modified-z-score\n",
        "\n",
        "    mad_value = mad(arr)\n",
        "\n",
        "    if mad_value == 0:\n",
        "\n",
        "        MeanAD = np.mean(np.abs(arr - np.mean(arr)))\n",
        "\n",
        "        denominator = 1.253314 * MeanAD\n",
        "\n",
        "    else:\n",
        "\n",
        "        denominator = 1.486 * mad_value\n",
        "\n",
        "\n",
        "    return (arr - np.median(arr)) / denominator\n",
        "\n",
        "\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "\n",
        "    return {\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        'MAPE': mean_absolute_percentage_error(y_true, y_pred),\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        'MAPE-MD': mean_absolute_percentage_error_mean_denominator(y_true, y_pred),\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        'MAE': mean_absolute_error(y_true, y_pred),\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        'RMSE': root_mean_squared_error(y_true, y_pred),\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        'R2': r2_score(y_true, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
        "\n",
        "\n",
        "mape_eps_scorer = make_scorer(mean_absolute_percentage_error_epsilon, greater_is_better=False)\n",
        "\n",
        "\n",
        "\n",
        "# Return the metrics for a RFR model trained on the given data.\n",
        "\n",
        "\n",
        "# The entire dataset is used for training, and the OOB prediction is used to compute the metrics.\n",
        "\n",
        "\n",
        "\n",
        "def oob_metrics(X, y, metricFct, rf_parames={}):\n",
        "\n",
        "    model = RandomForestRegressor(oob_score=True, **rf_parames)\n",
        "\n",
        "    y_pred = model.fit(X, y).oob_prediction_\n",
        "\n",
        "    return metricFct(y, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "# Return the metrics for a RFR model trained on the given data.\n",
        "\n",
        "\n",
        "# KFold cross-validation is used train the model and to compute the metrics.\n",
        "\n",
        "\n",
        "\n",
        "def kfold_metrics(X, y, metricFct, rf_parames={}, n_folds=5):\n",
        "\n",
        "    model = RandomForestRegressor(**rf_parames)\n",
        "\n",
        "    metrics_list = []\n",
        "\n",
        "\n",
        "    for train_index, test_index in KFold(n_splits=n_folds).split(X):\n",
        "\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        y_pred = model.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "        metrics_list.append(metricFct(y_test, y_pred))\n",
        "\n",
        "\n",
        "    if isinstance(metrics_list[0], dict):\n",
        "\n",
        "        # Convert list of dictionaries to a DataFrame\n",
        "\n",
        "        metrics_df = pd.DataFrame(metrics_list)\n",
        "\n",
        "        # Compute mean for each column\n",
        "\n",
        "        aggregated_metrics = metrics_df.mean().to_dict()\n",
        "        return aggregated_metrics\n",
        "\n",
        "\n",
        "    else:\n",
        "\n",
        "        # Compute mean of the list for numerical metrics\n",
        "\n",
        "        return np.mean(metrics_list)\n",
        "\n",
        "\n",
        "\n",
        "def _accumulate_prediction(predict, X, out, lock):\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    This is a utility function for joblib's Parallel.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    It can't go locally in ForestClassifier or ForestRegressor, because joblib\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    complains that it cannot pickle it when placed there.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    prediction = predict(X, check_input=False)\n",
        "\n",
        "    with lock:\n",
        "\n",
        "        out.append(prediction)\n",
        "\n",
        "\n",
        "\n",
        "def predict_w_std(self, X):\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    Predict regression target and standard deviation for X.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    The predicted regression target of an input sample is computed as the\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    mean predicted regression targets of the trees in the forest. The standard\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    deviation of the predicted regression targets of the trees in the forest\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    is also computed to provide an estimate of the prediction uncertainty.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    Parameters\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ----------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        The input samples. Internally, its dtype will be converted to\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        converted into a sparse ``csr_matrix``.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    Returns\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    -------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    mean_predictions : ndarray of shape (n_samples,)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        The predicted values (mean of the predictions from all estimators).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    std_predictions : ndarray of shape (n_samples,)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        The standard deviation of the predicted values (standard deviation of the\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        predictions from all estimators).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    Raises\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    NotImplementedError\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        If the model was trained for multi-output regression.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    Notes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    -----\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    This function does not support multi-output regression. If the model was\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    trained for multi-output regression, an exception will be raised.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if self.n_outputs_ > 1:\n",
        "\n",
        "\n",
        "        raise NotImplementedError(\"Variance for multi-output regression is not supported now\")\n",
        "\n",
        "\n",
        "    check_is_fitted(self)\n",
        "\n",
        "    # Check data\n",
        "\n",
        "\n",
        "    X = self._validate_X_predict(X)\n",
        "\n",
        "\n",
        "    # Assign chunk of trees to jobs\n",
        "\n",
        "    n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n",
        "\n",
        "\n",
        "    # avoid storing the output of every estimator by summing them here\n",
        "\n",
        "\n",
        "    # Initialize a list to collect predictions from each estimator\n",
        "\n",
        "\n",
        "    all_predictions = []\n",
        "\n",
        "\n",
        "    # Parallel loop\n",
        "\n",
        "\n",
        "    lock = threading.Lock()\n",
        "\n",
        "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        delayed(_accumulate_prediction)(e.predict, X, all_predictions, lock)\n",
        "\n",
        "        for e in self.estimators_\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "    # Convert list to numpy array for easier manipulation\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "\n",
        "\n",
        "    # Compute mean and variance across predictions from all estimators\n",
        "\n",
        "\n",
        "    mean_predictions = np.mean(all_predictions, axis=0)\n",
        "\n",
        "    std_predictions = np.std(all_predictions, axis=0)\n",
        "\n",
        "    return mean_predictions, std_predictions\n",
        "\n",
        "\n",
        "\n",
        "RandomForestRegressor.predict_w_std = predict_w_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameters tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Hyperparameters tuning\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Number of trees in random forest. from 1 to 200, with 20 steps\n",
        "n_estimators = [int(x) for x in np.linspace(start=1, stop=100, num=10)]\n",
        "# # Number of features to consider at every split\n",
        "max_features = ['log2']\n",
        "# # Maximum number of levels in tree\n",
        "# max_depth = [None]\n",
        "# # Minimum number of samples required to split a node\n",
        "# min_samples_split = [2]\n",
        "# # Minimum number of samples required at each leaf node\n",
        "# min_samples_leaf = [1]\n",
        "\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               # 'max_features': max_features,\n",
        "               # 'max_depth': max_depth,\n",
        "               # 'min_samples_split': min_samples_split,\n",
        "               # 'min_samples_leaf': min_samples_leaf\n",
        "            }"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# GRID SEARCH\n",
        "\n",
        "gs_results = {}\n",
        "\n",
        "for systemName in tqdm(systemsName_Valid):\n",
        "    # remove the target column from the features\n",
        "    X, y = get_system_data(systemName)\n",
        "    # Use the random grid to search for best hyperparameters\n",
        "    # First create the base model to tune\n",
        "    rf = RandomForestRegressor(random_state=random_state, max_features='log2')\n",
        "    # Random search of parameters, using 3 fold cross validation, \n",
        "    # search across 100 different combinations, and use all available cores\n",
        "    rf_grid = GridSearchCV(estimator = rf, param_grid = random_grid, cv = 5, n_jobs=-1, refit=False, verbose=2, return_train_score=True, scoring=mae_scorer)\n",
        "    # Fit the random search model\n",
        "    gs_results.update({systemName:rf_grid.fit(X, y).cv_results_})"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# PLOT RESULTS AND TIME\n",
        "\n",
        "fig = go.Figure()\n",
        "for systemName in systemsName_Valid:\n",
        "    fig.add_trace(go.Scatter(x=gs_results[systemName]['param_n_estimators'], y=gs_results[systemName]['mean_test_score']*(-100), mode='lines+markers', name=systemName))\n",
        "# fig.add_trace(go.Scatter(x=gs_results['param_min_samples_leaf'], y=gs_results['mean_test_score']*(-100), mode='lines+markers'))\n",
        "fig.update_layout(\n",
        "    yaxis_title=\"Mean Absolute Error (%)\",\n",
        "    xaxis_title=\"Number of trees\",\n",
        "    autosize=False,\n",
        "    width=1000,\n",
        "    height=666\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# fig = go.Figure()\n",
        "# fig.add_trace(go.Scatter(x=gs_results['param_min_samples_leaf'], y=gs_results['mean_fit_time'], mode='lines+markers'))\n",
        "# fig.update_layout(\n",
        "#     yaxis_title=\"Fit time (s)\",\n",
        "#     xaxis_title=\"Min samples to create a node\",\n",
        "#     autosize=False,\n",
        "#     width=1000,\n",
        "#     height=666\n",
        "# )\n",
        "# fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train regressors\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
        "print(X)\n",
        "print(list(y))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.33, random_state=42, shuffle=False)\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "print(X_test)\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Random Forest Regressor hyperparameters\n",
        "n_estimators = 100  # Number of trees in random forest\n",
        "max_features = 'log2'  # Number of features to consider at every split\n",
        "max_depth = None  # Maximum number of levels in tree\n",
        "min_samples_split = 2  # Minimum number of samples required to split a node\n",
        "min_samples_leaf = 1  # Minimum number of samples required at each leaf node\n",
        "\n",
        "targetName = systemsName_Valid[0]\n",
        "\n",
        "\n",
        "X, y = get_system_data(targetName, set='train')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "rf_regressor = RandomForestRegressor(oob_score=True, random_state=random_state, n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "y_pred, y_pred_std = rf_regressor.predict_w_std(X_test)\n",
        "\n",
        "# plot with squater poot the prediction y_pred with the standard deviation y_pred_std, as well as the measured values y_val\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=X_test.index, y=y_test, mode='markers', name='Measured'))\n",
        "fig.add_trace(go.Scatter(x=X_test.index, y=y_pred, mode='markers', name='Predicted'))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "serializer = PickleSerializer()\n",
        "\n",
        "rf_regressors = {}\n",
        "\n",
        "# Random Forest Regressor hyperparameters\n",
        "n_estimators = 100  # Number of trees in random forest\n",
        "max_features = 'log2'  # Number of features to consider at every split\n",
        "max_depth = None  # Maximum number of levels in tree\n",
        "min_samples_split = 2  # Minimum number of samples required to split a node\n",
        "min_samples_leaf = 1  # Minimum number of samples required at each leaf node\n",
        "\n",
        "\n",
        "if useCached and not forceTrain:\n",
        "    # load the models in dataCacheDirpath/rf_regressors. The file name is the system name.\n",
        "    for systemName in systemsName_Valid:\n",
        "        try:\n",
        "            rf_regressors[systemName] = serializer.retrieve_model(os.path.join(dataCacheDirpath, 'rf_regressors'), systemName)\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "    print(f\"Loaded {len(rf_regressors)}/{len(systemsName_Valid)} models. {len(systemsName_Valid) - len(rf_regressors)} models to train.\")\n",
        "\n",
        "systemsData_RelativeExpectedDailyEnergy_train_List = []\n",
        "for targetName in tqdm(set(systemsName_Valid) - set(rf_regressors), desc='Training regressors'):\n",
        "    rf_regressor = RandomForestRegressor(oob_score=True, random_state=random_state, n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "    X_train, y_train = get_system_data(targetName, set='train', relative=True)\n",
        "\n",
        "    # split the data into training and testing sets\n",
        "    rf_regressor.fit(X_train, y_train)\n",
        "    rf_regressors[targetName] = rf_regressor\n",
        "    # save the rf_regressor.oob_prediction_ in systemsData_RelativeExpectedDailyEnergy_train_List\n",
        "    systemsData_RelativeExpectedDailyEnergy_train_List.append(pd.Series(rf_regressor.oob_prediction_, index=X_train.index, name=targetName))\n",
        "    # save the model in dataCacheDirpath/rf_regressors. The file name is the system name.\n",
        "    serializer.save_model(rf_regressor, os.path.join(dataCacheDirpath, 'rf_regressors'), targetName)\n",
        "\n",
        "# Concatenate all the columns in the list to create one dataframe\n",
        "systemsData_RelativeExpectedDailyEnergy_train = pd.concat(systemsData_RelativeExpectedDailyEnergy_train_List, axis=1)\n",
        "systemsData_RelativeExpectedDailyEnergy_train.index = pd.to_datetime(systemsData_RelativeExpectedDailyEnergy_train.index)\n",
        "systemsData_RelativeExpectedDailyEnergy_train.sort_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute absolute expected daily energy\n",
        "systemsData_ExpectedDailyEnergy_train = systemsData_RelativeExpectedDailyEnergy_train * systemsData_EstimatedMaxDailyEnergy"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Compute absolute expected daily energy\n",
        "systemsData_ExpectedDailyEnergy_train = systemsData_RelativeExpectedDailyEnergy_train\n",
        "systemsData_RelativeExpectedDailyEnergy_train = systemsData_ExpectedDailyEnergy_train/systemsData_EstimatedMaxDailyEnergy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split between two dates\n",
        "\n",
        "TODO\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "targetName = 'a001286'\n",
        "# Create the feature matrix X and the target vector y\n",
        "X = systemsData_RelativeMeasuredDailyEnergy.drop(columns=targetName)\n",
        "y = systemsData_RelativeMeasuredDailyEnergy[targetName]\n",
        "# remove the observations where their is no target value\n",
        "X = X[~y.isna()]\n",
        "y = y[~y.isna()]\n",
        "\n",
        "# split the data into training and testing sets. data after the 1st June 2023 are used for training\n",
        "X_test, X_train  = X.loc[X.index < pd.Timestamp('2023-06-01')], X.loc[X.index >= pd.Timestamp('2023-06-01')]\n",
        "y_test, y_train = y.loc[y.index < pd.Timestamp('2023-06-01')], y.loc[y.index >= pd.Timestamp('2023-06-01')]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "rf_regressor = RandomForestRegressor(oob_score=True, random_state=random_state, n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "y_pred, y_std = rf_regressor.predict_w_std(X_test)\n",
        "\n",
        "# plot y_test, y_train, and y_pred with error bar y_std with two colors\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=y_test.index, y=y_test, mode='markers', name='y_test'))\n",
        "fig.add_trace(go.Scatter(x=y_train.index, y=y_train, mode='markers', name='y_train'))\n",
        "fig.add_trace(go.Scatter(x=y_test.index, y=y_pred, mode='markers', name='y_pred'))\n",
        "# fig.add_trace(go.Scatter(x=y_test.index, y=y_pred + y_std, mode='lines', line=dict(width=0), showlegend=False))\n",
        "# fig.add_trace(go.Scatter(x=y_test.index, y=y_pred - y_std, mode='lines', fill='tonexty', fillcolor='rgba(0,100,80,0.2)', line=dict(width=0), showlegend=False))\n",
        "fig.update_layout(title=f'{targetName} prediction with error bars', xaxis_title='Date', yaxis_title='Relative energy')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compupte training metrics of the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cacheFilename_regressorsMetrics_train = os.path.join(dataCacheDirpath, 'metrics_train.csv')\n",
        "\n",
        "if useCached and os.path.exists(cacheFilename_regressorsMetrics_train):\n",
        "    # TODO how to deal if the cached data is not up to date and some systems have been added or removed?\n",
        "    print(f\"Loading cached data in {cacheFilename_regressorsMetrics_train}\")\n",
        "    regressorsMetrics = pd.read_csv(cacheFilename_regressorsMetrics_train, index_col=0).squeeze()\n",
        "else:\n",
        "\n",
        "    # regressorsMetrics_mape_train = pd.Series(index=systemsName_Valid, name='Train MAE')\n",
        "    regressorsMetrics_mape_scaled_train = pd.Series(index=systemsName_Valid, name='Train MAPE Normalized')\n",
        "\n",
        "    for targetName in systemsName_Valid:\n",
        "\n",
        "        X_train, y_train = get_system_data(targetName, set='train', relative=True)\n",
        "\n",
        "        rf_regressor = rf_regressors[targetName]\n",
        "        y_pred = pd.Series(rf_regressor.oob_prediction_, index=X_train.index, name=targetName)\n",
        "        y_train_scaled = y_train  # (y_train / systemsData_EstimatedMaxDailyEnergy[targetName]).dropna()\n",
        "        y_pred_scaled = y_pred  # (y_pred / systemsData_EstimatedMaxDailyEnergy[targetName]).dropna()\n",
        "\n",
        "        # regressorsMetrics_mae_train.loc[targetName] = mean_absolute_error(y_train, y_pred)\n",
        "        # regressorsMetrics_mape_train.loc[targetName] = mean_absolute_percentage_error_epsilon(y_train, y_pred, epsilon=1)\n",
        "\n",
        "        regressorsMetrics_mape_scaled_train.loc[targetName] = mean_absolute_error(y_train_scaled, y_pred_scaled)\n",
        "        # regressorsMetrics_mape_scaled_train.loc[targetName] = mean_absolute_percentage_error_epsilon(y_train_scaled, y_pred_scaled, epsilon=0.01)\n",
        "\n",
        "    # save the metrics\n",
        "\n",
        "    # regressorsMetrics_mae_train.to_csv(cacheFilename_regressorsMetrics_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute feature importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compute_permutation_importance = False\n",
        "\n",
        "cacheFilename_features_importance = os.path.join(dataCacheDirpath, 'features_importance.csv')\n",
        "cacheFilename_permutation_importance_mean = os.path.join(dataCacheDirpath, 'permutation_importance_mean.csv')\n",
        "cacheFilename_permutation_importance_std = os.path.join(dataCacheDirpath, 'permutation_importance_std.csv')\n",
        "\n",
        "# start = time.time()\n",
        "\n",
        "if useCached and os.path.exists(cacheFilename_features_importance):\n",
        "    print(f\"Loading cached data in {cacheFilename_features_importance}\")\n",
        "    features_importance_df = pd.read_csv(cacheFilename_features_importance, index_col=0)\n",
        "else:\n",
        "    features_importance_df = pd.DataFrame(index=systemsName_Valid, columns=systemsName_Valid)\n",
        "    for targetName in systemsName_Valid:\n",
        "        rf_regressor = rf_regressors[targetName]\n",
        "        features_importance_df.loc[targetName, rf_regressor.feature_names_in_] = rf_regressor.feature_importances_\n",
        "    # save the feature importances\n",
        "    features_importance_df.to_csv(cacheFilename_features_importance)\n",
        "\n",
        "\n",
        "if compute_permutation_importance:\n",
        "    if useCached and os.path.exists(cacheFilename_permutation_importance_mean) and os.path.exists(cacheFilename_permutation_importance_std):\n",
        "        print(f\"Loading cached data in {cacheFilename_permutation_importance_mean}\")\n",
        "        permutation_importance_mean_df = pd.read_csv(cacheFilename_permutation_importance_mean, index_col=0)\n",
        "        print(f\"Loading cached data in {cacheFilename_permutation_importance_std}\")\n",
        "        permutation_importance_std_df = pd.read_csv(cacheFilename_permutation_importance_std, index_col=0)\n",
        "    else:\n",
        "        permutation_importance_mean_df = pd.DataFrame(index=systemsName_Valid, columns=systemsName_Valid)\n",
        "        permutation_importance_std_df = pd.DataFrame(index=systemsName_Valid, columns=systemsName_Valid)\n",
        "        for targetName in tqdm(systemsName_Valid):\n",
        "            X, y = get_system_data(targetName)\n",
        "            rf_regressor = rf_regressors[targetName]\n",
        "            permutation_importance_results = permutation_importance(rf_regressor, X, y, n_repeats=5, random_state=random_state, n_jobs=-1, scoring=mae_scorer)\n",
        "            permutation_importance_mean_df.loc[targetName, X.columns] = permutation_importance_results.importances_mean\n",
        "            permutation_importance_std_df.loc[targetName, X.columns] = permutation_importance_results.importances_std\n",
        "        # save the permutation importances\n",
        "        permutation_importance_mean_df.to_csv(cacheFilename_permutation_importance_mean)\n",
        "        permutation_importance_std_df.to_csv(cacheFilename_permutation_importance_std)\n",
        "\n",
        "\n",
        "# print(f\"Time elapsed: {time.time() - start} - Time per system: {(time.time() - start) / len(systemsName_Valid)}\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "serializer = PickleSerializer()\n",
        "\n",
        "rf_regressors = {}\n",
        "forceTrain = True\n",
        "if not forceTrain:\n",
        "    # load the models in dataCacheDirpath/rf_regressors. The file name is the system name.\n",
        "    for systemName in systemsName_Valid:\n",
        "        try:\n",
        "            rf_regressors[systemName] = serializer.retrieve_model(os.path.join(dataCacheDirpath, 'rf_regressors'), systemName)\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "    print(f\"Loaded {len(rf_regressors)}/{len(systemsName_Valid)} models. {len(systemsName_Valid) - len(rf_regressors)} models to train.\")\n",
        "\n",
        "# Train a Random Forest Regressor model to predict the daily energy production of a system based on the daily energy production of the other systems\n",
        "metrics_df = pd.DataFrame(index=systemsName_Valid, columns=['MAPE', 'MAPE-MD', 'MAE', 'RMSE', 'R2'])\n",
        "features_importance_df = pd.DataFrame(index=systemsName_Valid, columns=systemsName_Valid)\n",
        "permutation_importance_df = pd.DataFrame(index=systemsName_Valid, columns=systemsName_Valid)\n",
        "\n",
        "for targetName in tqdm(set(systemsName_Valid) - set(rf_regressors), desc='Training regressors'):\n",
        "    rf_regressor = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=random_state)\n",
        "    # remove the target column from the features\n",
        "    X = systemsData_MeasuredRelativeDailyEnergy.drop(columns=targetName)\n",
        "    y = systemsData_MeasuredRelativeDailyEnergy[targetName]\n",
        "    # remove the observations where their is no target value\n",
        "    X = X[~systemsData_MeasuredRelativeDailyEnergy[targetName].isna()]\n",
        "    y = y[~systemsData_MeasuredRelativeDailyEnergy[targetName].isna()]\n",
        "    # split the data into training and testing sets\n",
        "    # TODo utiliser OOB\n",
        "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_state) # Not necessary to split the data, as the OOB can be used to estimate the error\n",
        "    # train the regressor\n",
        "    y_oob_pred = rf_regressor.fit(X, y).oob_prediction_\n",
        "    # save the feature importances\n",
        "    features_importance_df.loc[targetName, X.columns] = rf_regressor.feature_importances_\n",
        "    # permutation_importance_df.loc[targetName, X.columns] = permutation_importance(rf_regressor, X_test, y_test, n_repeats=10, random_state=random_state, n_jobs=-1).importances_mean\n",
        "\n",
        "    # test the regressor\n",
        "    # y_mean = rf_regressor.predict(X_test)\n",
        "\n",
        "    # y_pred_V_IJ_unbiased = fci.random_forest_error(rf_regressor, X_train, X_test)\n",
        "\n",
        "    # compute the metrics\n",
        "    metrics_df.loc[targetName] = metrics(y, y_oob_pred)\n",
        "\n",
        "    # save the model\n",
        "    # serializer.save_model(rf_regressor, os.path.join(dataCacheDirpath, 'rf_regressors'), targetName)\n",
        "    rf_regressors[targetName] = rf_regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate expected value for each systems\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# valid system that have been trained\n",
        "systems_trained = [systemName for systemName in systemsName_Valid if systemName in rf_regressors]\n",
        "\n",
        "print(\"Systems not trained:\", [systemName for systemName in systemsName_Valid if systemName not in rf_regressors])"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# generate max value\n",
        "\n",
        "systemsData_EstimatedMaxDailyEnergy_test_dic = {}\n",
        "for systemName in tqdm(systemsName_Valid):\n",
        "    estimator = generate_max_production_estimator(systemsMetadata[systemName])\n",
        "    measured_series = systemsData_MeasuredDailyEnergy_test[systemName]\n",
        "    if measured_series.count() == 0:\n",
        "        continue\n",
        "    startDate = measured_series[~measured_series.isna()].index.min()\n",
        "    endDate = measured_series[~measured_series.isna()].index.max()\n",
        "    estimatedMaxDailyEnergy = generate_max_production_estimate(startDate, endDate, estimator, samplingFreq='1h')\n",
        "\n",
        "    # fill remaining days with NaN\n",
        "    estimatedMaxDailyEnergy = estimatedMaxDailyEnergy.reindex(measured_series.index, fill_value=np.nan)\n",
        "\n",
        "    # add the series to the dictionary\n",
        "    systemsData_EstimatedMaxDailyEnergy_test_dic[systemName] = estimatedMaxDailyEnergy\n",
        "\n",
        "\n",
        "# Concatenate all the columns in the list to create one dataframe\n",
        "systemsData_EstimatedMaxDailyEnergy_test = pd.concat(systemsData_EstimatedMaxDailyEnergy_test_dic, axis=1)\n",
        "systemsData_EstimatedMaxDailyEnergy_test.index = pd.to_datetime(systemsData_EstimatedMaxDailyEnergy_test.index)\n",
        "systemsData_EstimatedMaxDailyEnergy_test.sort_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check that all the index in systemsData_MeasuredDailyEnergy_test are in systemsData_EstimatedMaxDailyEnergy\n",
        "if not systemsData_MeasuredDailyEnergy_test.index.isin(systemsData_EstimatedMaxDailyEnergy.index).all():\n",
        "    raise ValueError(\"Some index in systemsData_MeasuredDailyEnergy_test are not in systemsData_EstimatedMaxDailyEnergy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute relative value\n",
        "systemsData_RelativeMeasuredDailyEnergy_test = systemsData_MeasuredDailyEnergy_test / systemsData_EstimatedMaxDailyEnergy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute estimate and metrics\n",
        "\n",
        "systemsData_RelativeExpectedDailyEnergy_test_mean_List = []\n",
        "systemsData_RelativeExpectedDailyEnergy_test_std_List = []\n",
        "\n",
        "# regressorsMetrics_mae_test = pd.Series(index=systems_trained, name='Test MAE')\n",
        "# regressorsMetrics_mape_test = pd.Series(index=systems_trained, name='Test MAPE')\n",
        "regressorsMetrics_mape_scaled_test = pd.Series(index=systems_trained, name='Test MAPE Normalized')\n",
        "# regressorsMetrics_mape_scaled_test = pd.Series(index=systems_trained, name='Test MAPE Scaled')\n",
        "\n",
        "for targetName in tqdm(systems_trained):\n",
        "    X_test, y_test = get_system_data(targetName, set='test', relative=True)\n",
        "    # check that there is at least one observation\n",
        "    if y_test.count() == 0:\n",
        "        continue\n",
        "    regressor = rf_regressors[targetName]\n",
        "    fitted_features = regressor.feature_names_in_\n",
        "\n",
        "    # adjust the feature in the validation set to match the feature in the training set\n",
        "    # Identify extra columns in X_test that are not used by the regressor\n",
        "    extra_features = set(X_test.columns) - set(fitted_features)\n",
        "    # Drop extra columns from X_val\n",
        "    X_test = X_test.drop(columns=list(extra_features), errors='ignore')\n",
        "    # Identify missing columns in X_test and add them as empty columns\n",
        "    missing_features = set(fitted_features) - set(X_test.columns)\n",
        "    for feature in missing_features:\n",
        "        X_test[feature] = np.nan\n",
        "\n",
        "    y_mean, y_std = regressor.predict_w_std(X_test)\n",
        "    y_mean = pd.Series(y_mean, index=X_test.index, name=targetName)\n",
        "    y_std = pd.Series(y_std, index=X_test.index, name=targetName)\n",
        "    systemsData_RelativeExpectedDailyEnergy_test_mean_List.append(y_mean)\n",
        "    systemsData_RelativeExpectedDailyEnergy_test_std_List.append(y_std)\n",
        "\n",
        "    # metrics\n",
        "    y_test_scaled = y_test  # (y_test / systemsData_EstimatedMaxDailyEnergy[targetName]).dropna()\n",
        "    y_mean_scaled = y_mean  # (y_mean / systemsData_EstimatedMaxDailyEnergy[targetName]).dropna()\n",
        "\n",
        "    # regressorsMetrics_mae_test.loc[targetName] = mean_absolute_error(y_test, y_mean)\n",
        "    # regressorsMetrics_mape_test.loc[targetName] = mean_absolute_percentage_error_epsilon(y_test, y_mean, epsilon=1)\n",
        "\n",
        "    regressorsMetrics_mape_scaled_test.loc[targetName] = mean_absolute_error(y_test_scaled, y_mean_scaled)\n",
        "    # regressorsMetrics_mape_scaled_test.loc[targetName] = mean_absolute_percentage_error_epsilon(y_test_scaled, y_mean_scaled, epsilon=0.01)\n",
        "\n",
        "\n",
        "systemsData_RelativeExpectedDailyEnergy_test_mean = pd.concat(systemsData_RelativeExpectedDailyEnergy_test_mean_List, axis=1)\n",
        "systemsData_RelativeExpectedDailyEnergy_test_mean.index = pd.to_datetime(systemsData_RelativeExpectedDailyEnergy_test_mean.index)\n",
        "systemsData_RelativeExpectedDailyEnergy_test_mean.sort_index(inplace=True)\n",
        "\n",
        "systemsData_RelativeExpectedDailyEnergy_test_std = pd.concat(systemsData_RelativeExpectedDailyEnergy_test_std_List, axis=1)\n",
        "systemsData_RelativeExpectedDailyEnergy_test_std.index = pd.to_datetime(systemsData_RelativeExpectedDailyEnergy_test_std.index)\n",
        "systemsData_RelativeExpectedDailyEnergy_test_std.sort_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute absolute expected daily energy\n",
        "systemsData_ExpectedDailyEnergy_test_mean = systemsData_RelativeExpectedDailyEnergy_test_mean * systemsData_EstimatedMaxDailyEnergy\n",
        "systemsData_ExpectedDailyEnergy_test_std = systemsData_RelativeExpectedDailyEnergy_test_std * systemsData_EstimatedMaxDailyEnergy"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Compute absolute expected daily energy\n",
        "systemsData_ExpectedDailyEnergy_test_mean = systemsData_RelativeExpectedDailyEnergy_test_mean # * systemsData_EstimatedMaxDailyEnergy\n",
        "systemsData_RelativeExpectedDailyEnergy_test_mean = systemsData_ExpectedDailyEnergy_test_mean / systemsData_EstimatedMaxDailyEnergy\n",
        "systemsData_ExpectedDailyEnergy_test_std = systemsData_RelativeExpectedDailyEnergy_test_std # * systemsData_EstimatedMaxDailyEnergy\n",
        "systemsData_RelativeExpectedDailyEnergy_test_std = systemsData_ExpectedDailyEnergy_test_std / systemsData_EstimatedMaxDailyEnergy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statics on the models metrics\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Do statistics about the series regressorsMetrics_train\n",
        "metrics = pd.concat([regressorsMetrics_mape_scaled_train_not_norm, regressorsMetrics_mape_scaled_train, regressorsMetrics_mape_scaled_test_not_norm, regressorsMetrics_mape_scaled_test], axis=1)\n",
        "print((metrics*100).describe())\n",
        "\n",
        "# box plot of the metrics\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=metrics * 100)\n",
        "plt.ylabel('Mean Absolute Percentage Error (%)')\n",
        "# plt.title('Box plot of the Mean Absolute Error (%) of the regressors on the validation set')\n",
        "plt.ylim(0, 40)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "systemsData_RelativeDelta_test = systemsData_RelativeExpectedDailyEnergy_test_mean - systemsData_RelativeMeasuredDailyEnergy_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Detector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# eronate data are the data where the relative delta is lower than regressorsMetrics_test\n",
        "max_z_score = 2.33  # 98% confidence interval\n",
        "systemsData_RelativeDelta_test_detected = systemsData_RelativeDelta_test[systemsData_RelativeDelta_test.loc[:, regressorsMetrics_mape_scaled_test.index] > max_z_score * regressorsMetrics_mape_scaled_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Scaling technics & Outliers removal\n",
        "\n",
        "Compute the:\n",
        "\n",
        "- Global mean\n",
        "- Global median\n",
        "- Global standard deviation\n",
        "- Rolling mean\n",
        "- Rolling median\n",
        "- Rolling standard deviation\n",
        "- Simulate max production without info\n",
        "- SImulated max production with info\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "targetName = \"a001395\"\n",
        "\n",
        "X = systemsData_MeasuredDailyEnergy.drop(columns=targetName)\n",
        "y = systemsData_MeasuredDailyEnergy[targetName]\n",
        "y.index = pd.to_datetime(y.index)\n",
        "# Global mean of the daily energy production of the target system\n",
        "globalMean = y.mean()\n",
        "\n",
        "# Global std of the daily energy production of the target system\n",
        "globalStd = y.std()\n",
        "\n",
        "# Gloabl median of the daily energy production of the target system\n",
        "globalMedian = y.median()\n",
        "\n",
        "roll = y.rolling(window='30D', min_periods=1, center=True)\n",
        "# Rolling mean of the daily energy production of the target system. The window is 1 month\n",
        "rollingMean = roll.mean()\n",
        "\n",
        "# Rolling std of the daily energy production of the target system. The window is 7 days.\n",
        "rollingStd = roll.std()\n",
        "\n",
        "# Rolling Mean Absolute Deviation of the daily energy production of the target system. the function is mad with the arguments how='median' and center='median'\n",
        "rollingMAD = roll.apply(mad)\n",
        "# Rolling median of the daily energy production of the target system. The window is 7 days.\n",
        "rollingMedian = roll.median()\n",
        "\n",
        "# Rolling z score of the daily energy production of the target system. The function is modified_z_score\n",
        "# modifiedZScore = 0.673 * (y - rollingMedian) / rollingMAD\n",
        "\n",
        "# Plot the global and rolling mean, std, and median of the daily energy production of the target system\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=y.index, y=y, mode='markers', name='Daily energy production'))\n",
        "# fig.add_trace(go.Scatter(x=y.index, y=[globalMean]*len(y), mode='lines', name='Global mean'))\n",
        "# fig.add_trace(go.Scatter(x=y.index, y=[globalMean+globalStd]*len(y), mode='lines', name='Global mean + std'))\n",
        "# fig.add_trace(go.Scatter(x=y.index, y=[globalMean-globalStd]*len(y), mode='lines', name='Global mean - std'))\n",
        "# fig.add_trace(go.Scatter(x=y.index, y=[globalMedian]*len(y), mode='lines', name='Global median'))\n",
        "fig.add_trace(go.Scatter(x=rollingMean.index, y=rollingMean, mode='lines', name='Rolling mean'))\n",
        "# fig.add_trace(go.Scatter(x=rollingMean.index, y=rollingMean+rollingStd, mode='lines', name='Rolling mean + std'))\n",
        "# fig.add_trace(go.Scatter(x=rollingMean.index, y=rollingMean-rollingStd, mode='lines', name='Rolling mean - std'))\n",
        "fig.add_trace(go.Scatter(x=rollingMedian.index, y=rollingMedian, mode='lines', name='Rolling median'))\n",
        "fig.add_trace(go.Scatter(x=rollingMAD.index, y=rollingMedian + 4 * rollingMAD, mode='lines', name='Rolling Median + 4*Rolling MAD'))\n",
        "fig.add_trace(go.Scatter(x=rollingMAD.index, y=rollingMAD, mode='lines', name='Rolling MAD'))\n",
        "\n",
        "# fig.add_trace(go.Scatter(x=modifiedZScore.index, y=rollingMedian+modifiedZScore, mode='lines', name='Rolling Median + Rolling Z score'))\n",
        "\n",
        "fig.update_layout(title=f'Global and rolling mean, std, and median of the daily energy production of system {targetName}', yaxis_title='Daily energy production (kWh)')\n",
        "# fig.update_layout(width=1000, height=666)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "def zscore(s, window, thresh=3, return_all=False):\n",
        "    roll = s.rolling(window=window, min_periods=1, center=True)\n",
        "    avg = roll.mean()\n",
        "    std = roll.std(ddof=0)\n",
        "    z = s.sub(avg).div(std)\n",
        "    m = z.between(-thresh, thresh)\n",
        "\n",
        "    if return_all:\n",
        "        return z, avg, std, m\n",
        "    return s.where(m, avg)\n",
        "\n",
        "\n",
        "z, avg, std, m = zscore(y, window=50, return_all=True)\n",
        "\n",
        "ax = plt.subplot()\n",
        "\n",
        "y.plot(label='data')\n",
        "avg.plot(label='mean')\n",
        "y.loc[~m].plot(label='outliers', marker='o', ls='')\n",
        "# avg[~m].plot(label='replacement', marker='o', ls='')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plot results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "systemsData_MeasuredDailyEnergy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "tab_height = '2em'\n",
        "app.layout = html.Div([\n",
        "    html.Div([\n",
        "        dcc.Dropdown(\n",
        "            id='system-dropdown',\n",
        "            options=[{'label': name, 'value': name} for name in systemsName_Valid],\n",
        "            value=systemsName_Valid[0],\n",
        "            style={'width': '50%'}  # Adjust width and font size\n",
        "        ),\n",
        "        html.Div(id='metric-text-container', style={'display': 'inline-block', 'margin-left': '20px'})  # Container for the metric text\n",
        "    ], style={'display': 'flex', 'align-items': 'center'}),  # Align items horizontally\n",
        "    dcc.Tabs(id='plot-tabs', value='tab-energy', children=[\n",
        "        dcc.Tab(label='Absolute Energy', value='tab-energy', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "        dcc.Tab(label='Normalized Energy', value='tab-rel-energy', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "        dcc.Tab(label='Normalizer Tuning', value='tab-norm-tuning', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "        # plot systemsData_RelativeDelta_test\n",
        "        dcc.Tab(label='All Normalized Energy', value='tab-rel-energy-all', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "        dcc.Tab(label='Dynamic Losses', value='tab-delta-rel-energy', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "        dcc.Tab(label='All Missing Value', value='tab-miss-val-all', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "        dcc.Tab(label='Similar neighboring systems', value='tab-neighbors', style={'padding': '0px', 'lineHeight': tab_height}, selected_style={'padding': '0px', 'lineHeight': tab_height, 'fontWeight': 'bold'}),  # Adjust height and line height\n",
        "\n",
        "    ]),  # Adjust height for tabs\n",
        "    html.Div(id='tabs-content', style={'flex': '1 1 auto'})  # Allow the tabs-content div to grow\n",
        "], style={'display': 'flex', 'flexDirection': 'column', 'height': '100vh'})  # Make the outer container fill the screen height\n",
        "\n",
        "\n",
        "@app.callback(\n",
        "    [Output('tabs-content', 'children'),\n",
        "     Output('metric-text-container', 'children')],\n",
        "    [Input('plot-tabs', 'value'),\n",
        "     Input('system-dropdown', 'value')]\n",
        ")\n",
        "def render_content(tab, selected_system):\n",
        "    # Statistic text\n",
        "    try:\n",
        "        mae_train = regressorsMetrics_mape_scaled_train.loc[selected_system]\n",
        "    except:\n",
        "        mae_train = np.nan\n",
        "    try:\n",
        "        mae_test = regressorsMetrics_mape_scaled_test.loc[selected_system]\n",
        "    except:\n",
        "        mae_test = np.nan\n",
        "    try:\n",
        "        loss = systemsMetadata[selected_system]['metadata']['loss']\n",
        "    except:\n",
        "        loss = np.nan\n",
        "\n",
        "    mae_train_text = f\"Half Sibling Regressor - Train set MAPE: {mae_train * 100:.2f}%\"\n",
        "    mae_test_text = f\"Half Sibling Regressor - Test set MAPE: {mae_test * 100:.2f}%\"\n",
        "    loss_text = f\"Normalizer Tuning - Static System Loss : {loss * 100:.2f}%\"\n",
        "\n",
        "    metric_text_div = html.Div([\n",
        "        html.Div(mae_train_text),\n",
        "        html.Div(mae_test_text),\n",
        "        html.Div(loss_text)\n",
        "    ], style={'fontSize': 16})\n",
        "\n",
        "    if tab == 'tab-energy':\n",
        "        fig1 = go.Figure(layout_yaxis_title=\"Daily Energy (kWh)\")\n",
        "\n",
        "        # remove nan from systemsData_EstimatedMaxDailyEnergy[selected_system]\n",
        "\n",
        "        try:\n",
        "            estimatedMaxDailyEnergy = systemsData_EstimatedMaxDailyEnergy[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=estimatedMaxDailyEnergy.index,\n",
        "                y=estimatedMaxDailyEnergy,\n",
        "                mode='lines',\n",
        "                name='Estimated Max Daily Energy',\n",
        "                marker_color='LightSeaGreen'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            measuredDailyEnergy = systemsData_MeasuredDailyEnergy[selected_system].dropna()\n",
        "            fig1.add_trace(go.Bar(\n",
        "                x=measuredDailyEnergy.index,\n",
        "                y=measuredDailyEnergy,\n",
        "                # mode='markers',\n",
        "                name='Measured Daily Energy',\n",
        "                marker_color='blue'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # try:\n",
        "        # measuredDailyEnergy_train_outliers = systemsData_MeasuredDailyEnergy_train_outliers[selected_system].dropna()\n",
        "        #     fig1.add_trace(go.Scatter(\n",
        "        #         x=measuredDailyEnergy_train_outliers.index,\n",
        "        #         y=measuredDailyEnergy_train_outliers,\n",
        "        #         mode='markers',\n",
        "        #         name='Outliers',\n",
        "        #         marker_color='yellow'\n",
        "        #     ))\n",
        "        # except:\n",
        "        #     pass\n",
        "        try:\n",
        "            expectedDailyEnergy_train = systemsData_ExpectedDailyEnergy_train[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=expectedDailyEnergy_train.index,\n",
        "                y=expectedDailyEnergy_train,\n",
        "                mode='markers',\n",
        "                name='Expected Daily Energy',\n",
        "                marker_color='red'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            expectedDailyEnergy_test_mean = systemsData_ExpectedDailyEnergy_test_mean[selected_system].dropna()\n",
        "            expectedDailyEnergy_test_std = systemsData_ExpectedDailyEnergy_test_std[selected_system].dropna()\n",
        "            fig1.add_trace(go.Bar(\n",
        "                x=expectedDailyEnergy_test_mean.index,\n",
        "                y=expectedDailyEnergy_test_mean,\n",
        "                # mode='markers',\n",
        "                name='Expected Daily Energy',\n",
        "                marker_color='red'\n",
        "                # error_y=dict(\n",
        "                #     type='data',\n",
        "                #     array=expectedDailyEnergy_test_std,\n",
        "                #     visible=True\n",
        "                # )\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Update layout for legend position\n",
        "        fig1.update_layout(\n",
        "            legend=dict(\n",
        "                x=0.99,\n",
        "                y=0.99,\n",
        "                xanchor='right',\n",
        "                yanchor='top',\n",
        "                orientation='h'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return dcc.Graph(figure=fig1, style={'height': '100%', 'width': '100%'}), metric_text_div  # Adjust height and width of the figure\n",
        "\n",
        "    elif tab == 'tab-norm-tuning':\n",
        "        fig1 = go.Figure(layout_yaxis_title=\"Daily Energy (kWh)\")\n",
        "        try:\n",
        "            measuredDailyEnergy = systemsData_MeasuredDailyEnergy[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=measuredDailyEnergy.index,\n",
        "                y=measuredDailyEnergy,\n",
        "                mode='markers',\n",
        "                name='Measured Daily Energy',\n",
        "                marker_color='blue'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            measuredMax = systemsData_Tuning_MeasureMax[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=measuredMax.index,\n",
        "                y=measuredMax,\n",
        "                mode='markers',\n",
        "                name='Max Measured Daily Energy (7 days window)',\n",
        "                marker_color='red'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            outliers = systemsData_Tuning_Outliers[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=outliers.index,\n",
        "                y=outliers,\n",
        "                mode='markers',\n",
        "                name='Tuning Outliers',\n",
        "                marker_color='yellow'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            estimatedMaxDailyEnergy_untuned = systemsData_Tuning_EstimatedMaxDailyEnergy_untuned[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=estimatedMaxDailyEnergy_untuned.index,\n",
        "                y=estimatedMaxDailyEnergy_untuned,\n",
        "                mode='lines',\n",
        "                name='Estimated Max Daily Energy (Untuned)',\n",
        "                marker_color='violet'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            estimatedMaxDailyEnergy = systemsData_EstimatedMaxDailyEnergy[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=estimatedMaxDailyEnergy.index,\n",
        "                y=estimatedMaxDailyEnergy,\n",
        "                mode='lines',\n",
        "                name='Estimated Max Daily Energy (Tuned)',\n",
        "                marker_color='LightSeaGreen'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        fig1.update_layout(\n",
        "            legend=dict(\n",
        "                x=0.99,\n",
        "                y=0.99,\n",
        "                xanchor='right',\n",
        "                yanchor='top',\n",
        "                orientation='h'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return dcc.Graph(figure=fig1, style={'height': '100%', 'width': '100%'}), metric_text_div\n",
        "    elif tab == 'tab-rel-energy':\n",
        "        fig1 = go.Figure(layout_yaxis_title=\"Normalized Daily Energy (%)\")\n",
        "        # add a line at 100% for the Estimated Max Daily Energy\n",
        "        estimatedMaxDailyEnergy = systemsData_EstimatedMaxDailyEnergy[selected_system].dropna()\n",
        "        fig1.add_shape(\n",
        "            type=\"line\",\n",
        "            x0=estimatedMaxDailyEnergy.index.min(),\n",
        "            y0=100,\n",
        "            x1=estimatedMaxDailyEnergy.index.max(),\n",
        "            y1=100,\n",
        "            name='Estimated Max Daily Energy',\n",
        "            line_color='LightSeaGreen'\n",
        "            # line=dict(\n",
        "            #     color=\"LightSeaGreen\",\n",
        "            #     width=2,\n",
        "            #     dash=\"dashdot\",\n",
        "            # ),\n",
        "        )\n",
        "        try:\n",
        "            relativeMeasuredDailyEnergy = systemsData_RelativeMeasuredDailyEnergy[selected_system].dropna()\n",
        "            fig1.add_trace(go.Bar(\n",
        "                x=relativeMeasuredDailyEnergy.index,\n",
        "                y=relativeMeasuredDailyEnergy * 100,\n",
        "                # mode='markers',\n",
        "                name='Measured Daily Energy',\n",
        "                marker_color='blue'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            relativeExpectedDailyEnergy_test_mean = systemsData_RelativeExpectedDailyEnergy_test_mean[selected_system].dropna()\n",
        "            fig1.add_trace(go.Bar(\n",
        "                x=relativeExpectedDailyEnergy_test_mean.index,\n",
        "                y=relativeExpectedDailyEnergy_test_mean * 100,\n",
        "                # mode='markers',\n",
        "                name='Expected Daily Energy',\n",
        "                marker_color='red'\n",
        "                # error_y=dict(\n",
        "                #     type='data',\n",
        "                #     array=systemsData_RelativeExpectedDailyEnergy_test_std[selected_system] * 100,\n",
        "                #     visible=True\n",
        "                # )\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        fig1.update_layout(\n",
        "            legend=dict(\n",
        "                x=0.99,\n",
        "                y=0.99,\n",
        "                xanchor='right',\n",
        "                yanchor='top',\n",
        "                orientation='h'\n",
        "            )\n",
        "        )\n",
        "        return dcc.Graph(figure=fig1, style={'height': '100%', 'width': '100%'}), metric_text_div  # Adjust height and width of the figure\n",
        "    elif tab == 'tab-delta-rel-energy':\n",
        "        fig1 = go.Figure(layout_yaxis_title=\"Normalized Daily Energy Loss (%)\")\n",
        "        try:\n",
        "            relativeDelta_test = systemsData_RelativeDelta_test[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=relativeDelta_test.index,\n",
        "                y=relativeDelta_test * 100,\n",
        "                mode='markers',\n",
        "                name='Normalized Delta Energy',\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            relativeDelta_test_detected = systemsData_RelativeDelta_test_detected[selected_system].dropna()\n",
        "            fig1.add_trace(go.Scatter(\n",
        "                x=relativeDelta_test_detected.index,\n",
        "                y=relativeDelta_test_detected * 100,\n",
        "                mode='markers',\n",
        "                name='Detected Anomaly',\n",
        "                marker_color='red'\n",
        "            ))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        fig1.update_layout(\n",
        "            legend=dict(\n",
        "                x=0.99,\n",
        "                y=0.99,\n",
        "                xanchor='right',\n",
        "                yanchor='top',\n",
        "                orientation='h'\n",
        "            )\n",
        "        )\n",
        "        return dcc.Graph(figure=fig1, style={'height': '100%', 'width': '100%'}), metric_text_div  # Adjust height and width of the figure\n",
        "    elif tab == 'tab-rel-energy-all':\n",
        "        fig1 = go.Figure(layout_yaxis_title=\"Normalized Daily Energy (%)\")\n",
        "        # try:\n",
        "        features_importance_norm = features_importance_df.loc[selected_system] / features_importance_df.loc[selected_system].max()\n",
        "\n",
        "        for systemName in systemsName_Valid:\n",
        "            if systemName != selected_system:\n",
        "                if features_importance_norm[systemName] > 0.1:\n",
        "                    fig1.add_trace(go.Scatter(\n",
        "                        x=systemsData_RelativeMeasuredDailyEnergy[systemName].index,\n",
        "                        y=systemsData_RelativeMeasuredDailyEnergy[systemName] * 100,\n",
        "                        mode='markers',\n",
        "                        name=f'{systemName}',\n",
        "                        marker_color='blue',\n",
        "                        marker_opacity=features_importance_norm[systemName]\n",
        "                    ))\n",
        "        fig1.add_trace(go.Scatter(\n",
        "            x=systemsData_RelativeMeasuredDailyEnergy[selected_system].index,\n",
        "            y=systemsData_RelativeMeasuredDailyEnergy[selected_system] * 100,\n",
        "            mode='markers',\n",
        "            name=f'{selected_system}',\n",
        "            marker_color='red'\n",
        "        ))\n",
        "        fig1.update_layout(yaxis=dict(range=[-5, 120]))\n",
        "\n",
        "        # except:\n",
        "        #     pass\n",
        "\n",
        "        return dcc.Graph(figure=fig1, style={'height': '100%', 'width': '100%'}), metric_text_div  # Adjust height and width of the figure\n",
        "    elif tab == 'tab-miss-val-all':\n",
        "        measures = systemsData_MeasuredDailyEnergy\n",
        "\n",
        "        # Sort columns by the number of missing values\n",
        "        sorted_columns = measures.isnull().sum().sort_values().index\n",
        "        sorted_measures = measures[sorted_columns]\n",
        "\n",
        "        # Create a boolean DataFrame where True indicates missing values\n",
        "        missing_values = (~sorted_measures.isnull()).astype(int)\n",
        "\n",
        "        # Plot heatmap\n",
        "        fig = go.Figure(data=go.Heatmap(\n",
        "            z=missing_values,\n",
        "            x=missing_values.columns,\n",
        "            y=missing_values.index,\n",
        "            showscale=False,\n",
        "            colorscale='Greys'  # Set colorscale to black and white\n",
        "        ))\n",
        "        fig.update_layout(\n",
        "            yaxis=dict(\n",
        "                showticklabels=True,  # Show y-axis tick labels\n",
        "                autorange='reversed'  # Invert the y-axis\n",
        "            ),\n",
        "            yaxis_tickmode='array',\n",
        "            yaxis_tickvals=pd.date_range(start=missing_values.index.min(), end=missing_values.index.max(), freq='ME'),\n",
        "            yaxis_ticktext=pd.date_range(start=missing_values.index.min(), end=missing_values.index.max(), freq='ME').strftime('%b %Y')\n",
        "        )\n",
        "\n",
        "        return dcc.Graph(figure=fig, style={'height': '100%', 'width': '100%'}), metric_text_div  # Adjust height and width of the figure\n",
        "\n",
        "    elif tab == 'tab-neighbors':\n",
        "        fig2 = go.Figure()\n",
        "\n",
        "        # Add initial traces with secondary y-axis\n",
        "        try:\n",
        "            fig2.add_trace(go.Bar(\n",
        "                x=features_importance_df.columns,\n",
        "                y=features_importance_df.loc[selected_system],\n",
        "                name='Impurity-based Importance',\n",
        "                yaxis='y1',\n",
        "                offsetgroup=1\n",
        "            ))\n",
        "            fig2.update_layout(\n",
        "                yaxis1=dict(\n",
        "                    title='Impurity-based Importance',\n",
        "                    range=[0, features_importance_df.loc[selected_system].max()],\n",
        "                )\n",
        "            )\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            fig2.add_trace(go.Bar(\n",
        "                x=permutation_importance_mean_df.columns,\n",
        "                y=permutation_importance_mean_df.loc[selected_system],\n",
        "                name='Permutation Importance',\n",
        "                yaxis='y2',\n",
        "                offsetgroup=2\n",
        "            ))\n",
        "            fig2.update_layout(\n",
        "                yaxis2=dict(\n",
        "                    title='Permutation Importance',\n",
        "                    overlaying='y',\n",
        "                    side='right',\n",
        "                    range=[0, permutation_importance_mean_df.loc[selected_system].max()],\n",
        "                )\n",
        "            )\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        return dcc.Graph(figure=fig2, style={'height': '100%', 'width': '100%'}), metric_text_div  # Adjust height and width of the figure\n",
        "\n",
        "\n",
        "def open_browser():\n",
        "    webbrowser.open(\"http://127.0.0.1:8050/\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Open the Dash app in a new browser window\n",
        "    Timer(1, open_browser).start()\n",
        "    app.run_server(debug=True, use_reloader=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpreting result from a prediction\n",
        "\n",
        "https://towardsdatascience.com/interpreting-random-forests-638bca8b49ea\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparisons between regressors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# show stats for the series regressorsMetrics_mape_scaled_test\n",
        "test_mape = regressorsMetrics_mape_scaled_test[regressorsMetrics_mape_scaled_test < 1] * 100\n",
        "print(test_mape.describe())\n",
        "# show a box plot\n",
        "# test_mape.plot.box()\n",
        "\n",
        "# show histogram\n",
        "test_mape.plot.hist(bins=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Impact of number of neighbors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Regressor hyperparameters\n",
        "n_estimators = 100  # Number of trees in random forest\n",
        "max_features = 'log2'  # Number of features to consider at every split\n",
        "max_depth = None  # Maximum number of levels in tree\n",
        "min_samples_split = 2  # Minimum number of samples required to split a node\n",
        "min_samples_leaf = 1  # Minimum number of samples required at each leaf node\n",
        "\n",
        "\n",
        "df_mape_n_neighbors_test = pd.DataFrame(index=systemsName_Valid, columns=[1, 2, 5, 10, 50, 150, 300])\n",
        "for max_neighbors in df_mape_n_neighbors_test.columns:\n",
        "    for targetName in tqdm(systemsName_Valid):\n",
        "        # train\n",
        "        rf_regressor = RandomForestRegressor(oob_score=True, random_state=random_state, n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "        X_train, y_train = get_system_data(targetName, set='train', relative=True, max_neighbors=max_neighbors)\n",
        "        # split the data into training and testing sets\n",
        "        rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "        # predict\n",
        "        X_test, y_test = get_system_data(targetName, set='test', relative=True)\n",
        "        if y_test.count() == 0:\n",
        "            continue\n",
        "\n",
        "        # adjust the feature in the validation set to match the feature in the training set\n",
        "        fitted_features = rf_regressor.feature_names_in_\n",
        "        # Identify extra columns in X_test that are not used by the regressor\n",
        "        extra_features = set(X_test.columns) - set(fitted_features)\n",
        "        # Drop extra columns from X_val\n",
        "        X_test = X_test.drop(columns=list(extra_features), errors='ignore')\n",
        "        # Identify missing columns in X_test and add them as empty columns\n",
        "        missing_features = set(fitted_features) - set(X_test.columns)\n",
        "        for feature in missing_features:\n",
        "            X_test[feature] = np.nan\n",
        "\n",
        "        y_mean_array = rf_regressor.predict(X_test)\n",
        "        y_pred = pd.Series(y_mean_array, index=X_test.index, name=targetName)\n",
        "        df_mape_n_neighbors_test.loc[targetName, max_neighbors] = mean_absolute_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# do a figure with 3 box plot, one for each column of the dataframe df_mape_train_save.\n",
        "df_mape_n_neighbors_test_filtered = df_mape_n_neighbors_test[df_mape_n_neighbors_test < 0.5]*100\n",
        "fig = go.Figure()\n",
        "for column in df_mape_n_neighbors_test_filtered.columns:\n",
        "    fig.add_trace(go.Box(y=df_mape_n_neighbors_test_filtered[column], name=column, boxmean=True))\n",
        "\n",
        "# remove legend\n",
        "fig.update_layout(showlegend=False)\n",
        "# set the x axis name to \"Training Days\"\n",
        "fig.update_xaxes(title_text='Neighbors systems')\n",
        "# set y axis name to \"MAPE (%)\"\n",
        "fig.update_yaxes(title_text='MAPE (%)')\n",
        "# set the fig size to 1000 x 666\n",
        "fig.update_layout(width=1000, height=666)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Impact of the number of training data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Regressor hyperparameters\n",
        "n_estimators = 100  # Number of trees in random forest\n",
        "max_features = 'log2'  # Number of features to consider at every split\n",
        "max_depth = None  # Maximum number of levels in tree\n",
        "min_samples_split = 2  # Minimum number of samples required to split a node\n",
        "min_samples_leaf = 1  # Minimum number of samples required at each leaf node\n",
        "\n",
        "\n",
        "df_mape_n_history_test = pd.DataFrame(index=systemsName_Valid, columns=[2])\n",
        "for max_training_days in df_mape_n_history_test.columns:\n",
        "    for targetName in tqdm(systemsName_Valid):\n",
        "        # train\n",
        "        rf_regressor = RandomForestRegressor(oob_score=False, random_state=random_state, n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "        X_train, y_train = get_system_data(targetName, set='train', relative=True)\n",
        "\n",
        "        # keep only the last max_training_days days\n",
        "        X_train = X_train.iloc[-max_training_days:]\n",
        "        y_train = y_train.iloc[-max_training_days:]\n",
        "\n",
        "        # split the data into training and testing sets\n",
        "        rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "        # predict\n",
        "        X_test, y_test = get_system_data(targetName, set='test', relative=True)\n",
        "        if y_test.count() == 0:\n",
        "            continue\n",
        "\n",
        "        # adjust the feature in the validation set to match the feature in the training set\n",
        "        fitted_features = rf_regressor.feature_names_in_\n",
        "        # Identify extra columns in X_test that are not used by the regressor\n",
        "        extra_features = set(X_test.columns) - set(fitted_features)\n",
        "        # Drop extra columns from X_val\n",
        "        X_test = X_test.drop(columns=list(extra_features), errors='ignore')\n",
        "        # Identify missing columns in X_test and add them as empty columns\n",
        "        missing_features = set(fitted_features) - set(X_test.columns)\n",
        "        for feature in missing_features:\n",
        "            X_test[feature] = np.nan\n",
        "\n",
        "        y_mean_array = rf_regressor.predict(X_test)\n",
        "        y_pred = pd.Series(y_mean_array, index=X_test.index, name=targetName)\n",
        "        df_mape_n_history_test.loc[targetName, max_training_days] = mean_absolute_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# do a figure with 3 box plot, one for each column of the dataframe df_mape_train_save.\n",
        "df_mape_n_history_test_filtered = df_mape_n_history_test_save[df_mape_n_history_test_save < 0.5]*100\n",
        "fig = go.Figure()\n",
        "for column in df_mape_n_history_test_filtered.columns:\n",
        "    fig.add_trace(go.Box(y=df_mape_n_history_test_filtered[column], name=column, boxmean=True))\n",
        "    \n",
        "# remove legend\n",
        "fig.update_layout(showlegend=False)\n",
        "# set the x axis name to \"Training Days\"\n",
        "fig.update_xaxes(title_text='Training Days')\n",
        "# set y axis name to \"MAPE (%)\"\n",
        "fig.update_yaxes(title_text='MAPE (%)')\n",
        "fig.update_layout(width=1000, height=666)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_mape_n_history_test_filtered.astype(float).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "# Step 1: Convert 'training_time' from 'HH:MM' format to minutes\n",
        "data = {'days': [2, 7, 14, 30, 180, 365],\n",
        "        'training_time': ['02:36', '02:27', '02:29', '02:47', '03:30', '04:10']}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert training time to minutes\n",
        "df['training_time_seconds'] = df['training_time'].apply(lambda x: int(x.split(':')[0]) * 60 + int(x.split(':')[1]))/326\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
