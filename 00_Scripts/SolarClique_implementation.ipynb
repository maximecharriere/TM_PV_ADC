{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pvlib\n",
    "import json\n",
    "import os\n",
    "from pvlib.pvsystem import PVSystem, Array, FixedMount\n",
    "from pvlib.location import Location\n",
    "from pvlib.modelchain import ModelChain\n",
    "from pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"browser\" # render plotly figures in browser\n",
    "\n",
    "PARENT_DATA_DIR = os.getenv('PARENT_DATA_DIR')\n",
    "if PARENT_DATA_DIR is None:\n",
    "    raise ValueError(\"PARENT_DATA_DIR environment variable is not set\")\n",
    "\n",
    "\n",
    "dataDirpath = PARENT_DATA_DIR + r\"\\PRiOT\\dataExport_3400_daily\"\n",
    "logsDirpath = r\"..\\logs\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PRiOT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metadata JSON file\n",
    "metadataFilepath = os.path.join(dataDirpath, \"metadata.json\")\n",
    "\n",
    "with open(metadataFilepath, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Load all csv files from the data directory\n",
    "systemsData = {}\n",
    "for file in os.listdir(dataDirpath):\n",
    "    if file.endswith(\".csv\") and not file == 'all_daily_production_v1.csv':\n",
    "        systemName = file.split(\"_\")[0]\n",
    "        systemsData[systemName] = pd.read_csv(os.path.join(dataDirpath, file))\n",
    "        systemsData[systemName]['Datetime'] = pd.to_datetime(systemsData[systemName]['Timestamp'], unit='ms', utc=True).dt.tz_convert('Europe/Zurich')\n",
    "        systemsData[systemName]['Date'] = (systemsData[systemName]['Datetime']+pd.Timedelta(hours=1)).dt.date # Convert the datetime to only the date, as the production is the daily production. The +1h is to manage the saving time. Normally PRiOT exports the data at midnight (local time) for the day after (e.g. the energy for the July 1st is saved at July 1st 00:00 Europe/Zurich). However it seams that the saving time is not always correctly handled, and sometime the export is done at 23:00 the day before (e.g. the energy for the July 1st is saved at June 30th 23:00 Europe/Zurich). This is why we add 1h to the datetime to be sure to have the correct date.\n",
    "        # systemsData[systemName]['energy_daily_norm'] = systemsData[systemName]['tt_forward_active_energy_total_toDay'] / metadata[systemName]['metadata']['pv_kwp']\n",
    "\n",
    "systemsName = list(systemsData.keys())\n",
    "\n",
    "df_duplicate_list = list()\n",
    "for systemName, systemData in systemsData.items():\n",
    "    # Save duplicate dates to log list, and the in a log file\n",
    "    df_duplicate_list.append(systemData[systemsData[systemName]['Date'].duplicated(keep=False)])\n",
    "\n",
    "    # Remove duplicate date where tt_forward_active_energy_total_toDay is the smallest \n",
    "    # TODO maybe we should sum the energy of the duplicates instead of removing the smallest one. However, when looking in PRiOT Portal, it seams that in the daily energy, only the biggest value is represented. We do the same here.\n",
    "    systemData.sort_values('tt_forward_active_energy_total_toDay', ascending=True, inplace=True)\n",
    "    systemsData[systemName].drop_duplicates(subset='Date', keep='last', inplace=True)\n",
    "\n",
    "    # Set date as the index and sort the data by date\n",
    "    systemsData[systemName].set_index('Date', inplace=True)\n",
    "    systemData.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "# Save duplicate dates to log file\n",
    "df_duplicate = pd.concat(df_duplicate_list)\n",
    "print(f\"Number of duplicate dates found: {len(df_duplicate)}\")\n",
    "df_duplicate.to_csv(os.path.join(logsDirpath,'duplicateDates.csv'), index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data & Filter out invalid PRiOT systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemsNameRemaining = systemsName.copy()\n",
    "for systemName in systemsName:\n",
    "    missingData = False\n",
    "    if len(systemsData[systemName]) == 0:\n",
    "        missingData = True\n",
    "        print(f\"No measures found for system {systemName}\")\n",
    "    for key in ['loc_latitude', 'loc_longitude', 'pv_kwp']:\n",
    "        if key not in metadata[systemName]['metadata']:\n",
    "            missingData = True\n",
    "            print(f\"No {key} found for {systemName}\")\n",
    "        # test that the value is a number\n",
    "        elif not isinstance(metadata[systemName]['metadata'][key], (int, float)):\n",
    "            try:\n",
    "                metadata[systemName]['metadata'][key] = int(metadata[systemName]['metadata'][key])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    metadata[systemName]['metadata'][key] = float(metadata[systemName]['metadata'][key])\n",
    "                except ValueError:\n",
    "                    missingData = True\n",
    "                    print(f\"The key-value '{key}:{metadata[systemName]['metadata'][key]}' is not a number for system {systemName}\")\n",
    "\n",
    "\n",
    "    if(len(metadata[systemName]['arrays'])==0):\n",
    "        print(f\"No PV arrays found for system {systemName}\")\n",
    "        missingData = True  \n",
    "    for array_num, arrayData in metadata[systemName]['arrays'].items():\n",
    "        for key in ['pv_tilt', 'pv_azimut', 'pv_wp', 'pv_number']:\n",
    "            if key not in arrayData:\n",
    "                missingData = True\n",
    "                print(f\"No {key} found for array {array_num} of system {systemName}\")\n",
    "            # test that the value is a number\n",
    "            elif not isinstance(arrayData[key], (int, float)):\n",
    "                try:\n",
    "                    arrayData[key] = int(arrayData[key])\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        arrayData[key] = float(arrayData[key])\n",
    "                    except ValueError:\n",
    "                        missingData = True\n",
    "                        print(f\"The key-value '{key}:{arrayData[key]}' is not a number for array {array_num} of system {systemName}\")\n",
    "\n",
    "    if missingData:\n",
    "        systemsNameRemaining.remove(systemName)\n",
    "        print(f\"-> Removing system {systemName} from the list of systems\")\n",
    "\n",
    "print(f\"Number of systems with all the necessary data: {len(systemsNameRemaining)}/{len(systemsName)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty dataframe to store the concatenated column\n",
    "dailyEnergyTotalColumns = []\n",
    "\n",
    "# Iterate over each key-value pair in the systemsData dictionary\n",
    "for systemName in systemsNameRemaining:\n",
    "    # Extract the 'tt_forward_active_energy_total_toDay' column from the current dataframe\n",
    "    dailyEnergyTotalColumn = systemsData[systemName]['tt_forward_active_energy_total_toDay']\n",
    "    \n",
    "    # Rename the column with the system name\n",
    "    dailyEnergyTotalColumn = dailyEnergyTotalColumn.rename(systemName)\n",
    "    \n",
    "    dailyEnergyTotalColumns.append(dailyEnergyTotalColumn)\n",
    "    # Concatenate the column to the new_dataframe\n",
    "    \n",
    "systemsData_dailyEnergyTotal = pd.concat(dailyEnergyTotalColumns, axis=1)\n",
    "systemsData_dailyEnergyTotal.sort_index(inplace=True)\n",
    "# Print the new_dataframe\n",
    "systemsData_dailyEnergyTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemsData_dailyEnergyTotal.to_csv(os.path.join(dataDirpath, 'all_daily_production_v1.csv'), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "msno.matrix(systemsData_dailyEnergyTotal, filter='bottom', labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of available values per day. On the X axis is the day, and on the Y axis is the number of available values for this day.\n",
    "\n",
    "# Count the number of available values per day (number of value per index)\n",
    "availableValuesPerDay = systemsData_dailyEnergyTotal.count(axis=1)\n",
    "\n",
    "# Plot the number of available values per day\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=availableValuesPerDay.index, y=availableValuesPerDay.values, mode='lines'))\n",
    "fig.update_layout(title='Number of available system\\'s values per day', yaxis_title='Number of available values')\n",
    "fig.update_layout(width=1000, height=666)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "targetName = 'a001155'\n",
    "\n",
    "X_train = systemsData_dailyEnergyTotal.drop(columns=targetName)\n",
    "y_train = systemsData_dailyEnergyTotal[targetName]\n",
    "\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "# predictions = knn_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Regressor model to predict the daily energy production of a system based on the daily energy production of the other systems\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "targetName = 'a001231'\n",
    "\n",
    "X_train = systemsData_dailyEnergyTotal.drop(columns=targetName)\n",
    "X_train = X_train[~systemsData_dailyEnergyTotal[targetName].isna()]\n",
    "y_train = systemsData_dailyEnergyTotal[targetName][~systemsData_dailyEnergyTotal[targetName].isna()]\n",
    "\n",
    "rf_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the training data\n",
    "y_train_pred = rf_regressor.predict(X_train)\n",
    "\n",
    "# Plot the predicted values against the true values\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=y_train, y=y_train_pred, mode='markers'))\n",
    "fig.update_layout(title='Predicted vs True values on the training data', xaxis_title='True values', yaxis_title='Predicted values')\n",
    "fig.show()\n",
    "\n",
    "# Plot the predicted value and true value with the date as the x-axis\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=X_train.index, y=y_train, mode='markers', name='True values'))\n",
    "fig.add_trace(go.Scatter(x=X_train.index, y=y_train_pred, mode='markers', name='Predicted values'))\n",
    "fig.update_layout(title='Predicted vs True values on the training data', xaxis_title='Date', yaxis_title='Energy production')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.sort(5 * np.random.rand(40, 1), axis=0)\n",
    "T = np.linspace(0, 5, 500)[:, np.newaxis]\n",
    "y = np.sin(X).ravel()\n",
    "\n",
    "# Add noise to targets\n",
    "y[::5] += 1 * (0.5 - np.random.rand(8))\n",
    "\n",
    "n_neighbors = 5\n",
    "\n",
    "for i, weights in enumerate([\"uniform\", \"distance\"]):\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors, weights=weights)\n",
    "    y_ = knn.fit(X, y).predict(T)\n",
    "\n",
    "    plt.subplot(2, 1, i + 1)\n",
    "    plt.scatter(X, y, color=\"darkorange\", label=\"data\")\n",
    "    plt.plot(T, y_, color=\"navy\", label=\"prediction\")\n",
    "    plt.axis(\"tight\")\n",
    "    plt.legend()\n",
    "    plt.title(\"KNeighborsRegressor (k = %i, weights = '%s')\" % (n_neighbors, weights))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
