{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pvlib\n",
    "import json\n",
    "import os\n",
    "from pvlib.pvsystem import PVSystem, Array, FixedMount\n",
    "from pvlib.location import Location\n",
    "from pvlib.modelchain import ModelChain\n",
    "from pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"browser\" # render plotly figures in browser\n",
    "\n",
    "PARENT_DATA_DIR = os.getenv('PARENT_DATA_DIR')\n",
    "if PARENT_DATA_DIR is None:\n",
    "    raise ValueError(\"PARENT_DATA_DIR environment variable is not set\")\n",
    "\n",
    "\n",
    "dataDirpath = PARENT_DATA_DIR + r\"\\PRiOT\\dataExport_3400_daily\"\n",
    "logsDirpath = r\"..\\logs\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PRiOT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metadata JSON file\n",
    "metadataFilepath = os.path.join(dataDirpath, \"metadata.json\")\n",
    "\n",
    "with open(metadataFilepath, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Load all csv files from the data directory\n",
    "systemsData = {}\n",
    "for file in os.listdir(dataDirpath):\n",
    "    if file.endswith(\".csv\"):\n",
    "        systemName = file.split(\"_\")[0]\n",
    "        systemsData[systemName] = pd.read_csv(os.path.join(dataDirpath, file))\n",
    "        systemsData[systemName]['Datetime'] = pd.to_datetime(systemsData[systemName]['Timestamp'], unit='ms', utc=True).dt.tz_convert('Europe/Zurich')\n",
    "        systemsData[systemName]['Date'] = (systemsData[systemName]['Datetime']+pd.Timedelta(hours=1)).dt.date # Convert the datetime to only the date, as the production is the daily production. The +1h is to manage the saving time. Normally PRiOT exports the data at midnight (local time) for the day after (e.g. the energy for the July 1st is saved at July 1st 00:00 Europe/Zurich). However it seams that the saving time is not always correctly handled, and sometime the export is done at 23:00 the day before (e.g. the energy for the July 1st is saved at June 30th 23:00 Europe/Zurich). This is why we add 1h to the datetime to be sure to have the correct date.\n",
    "        # systemsData[systemName]['energy_daily_norm'] = systemsData[systemName]['tt_forward_active_energy_total_toDay'] / metadata[systemName]['metadata']['pv_kwp']\n",
    "\n",
    "systemsName = list(systemsData.keys())\n",
    "\n",
    "df_duplicate_list = list()\n",
    "for systemName, systemData in systemsData.items():\n",
    "    # Save duplicate dates to log list, and the in a log file\n",
    "    df_duplicate_list.append(systemData[systemsData[systemName]['Date'].duplicated(keep=False)])\n",
    "\n",
    "    # Remove duplicate date where tt_forward_active_energy_total_toDay is the smallest \n",
    "    # TODO maybe we should sum the energy of the duplicates instead of removing the smallest one. However, when looking in PRiOT Portal, it seams that in the daily energy, only the biggest value is represented. We do the same here.\n",
    "    systemData.sort_values('tt_forward_active_energy_total_toDay', ascending=True, inplace=True)\n",
    "    systemsData[systemName].drop_duplicates(subset='Date', keep='last', inplace=True)\n",
    "\n",
    "    # Set date as the index and sort the data by date\n",
    "    systemsData[systemName].set_index('Date', inplace=True)\n",
    "    systemData.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "# Save duplicate dates to log file\n",
    "df_duplicate = pd.concat(df_duplicate_list)\n",
    "print(f\"Number of duplicate dates found: {len(df_duplicate)}\")\n",
    "df_duplicate.to_csv(os.path.join(logsDirpath,'duplicateDates.csv'), index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data & Filter out invalid PRiOT systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemsNameRemaining = systemsName.copy()\n",
    "for systemName in systemsName:\n",
    "    missingData = False\n",
    "    if len(systemsData[systemName]) == 0:\n",
    "        missingData = True\n",
    "        print(f\"No measures found for system {systemName}\")\n",
    "    for key in ['loc_latitude', 'loc_longitude', 'pv_kwp']:\n",
    "        if key not in metadata[systemName]['metadata']:\n",
    "            missingData = True\n",
    "            print(f\"No {key} found for {systemName}\")\n",
    "        # test that the value is a number\n",
    "        elif not isinstance(metadata[systemName]['metadata'][key], (int, float)):\n",
    "            try:\n",
    "                metadata[systemName]['metadata'][key] = int(metadata[systemName]['metadata'][key])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    metadata[systemName]['metadata'][key] = float(metadata[systemName]['metadata'][key])\n",
    "                except ValueError:\n",
    "                    missingData = True\n",
    "                    print(f\"The key-value '{key}:{metadata[systemName]['metadata'][key]}' is not a number for system {systemName}\")\n",
    "\n",
    "\n",
    "    if(len(metadata[systemName]['arrays'])==0):\n",
    "        print(f\"No PV arrays found for system {systemName}\")\n",
    "        missingData = True  \n",
    "    for array_num, arrayData in metadata[systemName]['arrays'].items():\n",
    "        for key in ['pv_tilt', 'pv_azimut', 'pv_wp', 'pv_number']:\n",
    "            if key not in arrayData:\n",
    "                missingData = True\n",
    "                print(f\"No {key} found for array {array_num} of system {systemName}\")\n",
    "            # test that the value is a number\n",
    "            elif not isinstance(arrayData[key], (int, float)):\n",
    "                try:\n",
    "                    arrayData[key] = int(arrayData[key])\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        arrayData[key] = float(arrayData[key])\n",
    "                    except ValueError:\n",
    "                        missingData = True\n",
    "                        print(f\"The key-value '{key}:{arrayData[key]}' is not a number for array {array_num} of system {systemName}\")\n",
    "\n",
    "    if missingData:\n",
    "        systemsNameRemaining.remove(systemName)\n",
    "        print(f\"-> Removing system {systemName} from the list of systems\")\n",
    "\n",
    "print(f\"Number of systems with all the necessary data: {len(systemsNameRemaining)}/{len(systemsName)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty dataframe to store the concatenated column\n",
    "columns = []\n",
    "\n",
    "# Iterate over each key-value pair in the systemsData dictionary\n",
    "for system_name, system_data in systemsData.items():\n",
    "    # Extract the 'tt_forward_active_energy_total_toDay' column from the current dataframe\n",
    "    column = system_data['tt_forward_active_energy_total_toDay']\n",
    "    \n",
    "    # Rename the column with the system name\n",
    "    column = column.rename(system_name)\n",
    "    \n",
    "    columns.append(column)\n",
    "    # Concatenate the column to the new_dataframe\n",
    "    \n",
    "new_dataframe = pd.concat(columns, axis=1)\n",
    "new_dataframe.sort_index(inplace=True)\n",
    "# Print the new_dataframe\n",
    "new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
